{
  
    
        "post0": {
            "title": "Introducing fastlinkcheck",
            "content": ". Motivation . Recently, fastai has been hard at work improving and overhauling nbdev, a literate programming environment for python. A key feature of nbdev is automated generation of documentation from Jupyter notebooks. This documentation system adds many niceties, such as the following types of hyperlinks automatically: . Links to source code on GitHub. | Links to both internal and external documentation by introspecting variable names in backticks. | . Because documentation is so easy to create and maintain in nbdev, we find ourselves and others creating much more of it! In addition to automatic hyperlinks, we often include our own links to relevant websites, blogs and videos when documenting code. For example, one of the largest nbdev generated sites, docs.fast.ai, has more than 300 external and internal links at the time of this writing. . The Solution . Due to the continued popularity of fastai and the growth of new nbdev projects, grooming these links manually became quite tedious. We investigated solutions that could verify links for us automatically, but were not satisfied with any existing solutions. These are the features we desired: . A platform independent solution that is not tied to a specific static site generator like Jekyll or Hugo. | Intelligent introspection of external links that are actually internal links. For example, if we are building the site docs.fast.ai, a link to https://docs.fast.ai/tutorial should not result in a web request, but rather introspection of the local file system for the presence of tutorial.html in the right location. | Verification of any links to assets like CSS, data, javascript or other files. | Logs that are well organized that allow us to see each broken link or reference to a non-existent path, and the pages these are found in. | Parallelism to verify links as fast as possible. | Lightweight, easy to install with minimal dependencies. | . We tried tools such as linkchecker and pylinkvalidator, but these required your site to be first be hosted. Since we wanted to check links on a static site, hosting is overhead we wanted to avoid. . This is what led us to create fastlinkcheck, which we discuss below. . Note: For Ruby users, htmlproofer apperas to provide overlapping functionality. We have not tried this library. . A tour of fastlinkcheck . For this tour we will be referring to the files in the fastlinkcheck repo. You should clone this repo in the current directory in order to follow along: . git clone https://github.com/fastai/fastlinkcheck.git cd fastlinkcheck . Cloning into &#39;fastlinkcheck&#39;... remote: Enumerating objects: 135, done. remote: Counting objects: 100% (135/135), done. remote: Compressing objects: 100% (98/98), done. remote: Total 608 (delta 69), reused 76 (delta 34), pack-reused 473 Receiving objects: 100% (608/608), 1.12 MiB | 10.47 MiB/s, done. Resolving deltas: 100% (302/302), done. . Installation . You can install fastlinkcheck with pip: . pip install fastlinkcheck . Usage . After installing fastlinkcheck, the cli command link_check is available from the command line. We can see various options with the --help flag. . link_check --help . usage: link_check [-h] [--host HOST] [--config_file CONFIG_FILE] [--pdb] [--xtra XTRA] path Check for broken links recursively in `path`. positional arguments: path Root directory searched recursively for HTML files optional arguments: -h, --help show this help message and exit --host HOST Host and path (without protocol) of web server --config_file CONFIG_FILE Location of file with urls to ignore --pdb Run in pdb debugger (default: False) --xtra XTRA Parse for additional args (default: &#39;&#39;) . From the root of fastlinkcheck repo, We can search the directory _example/broken_links recursively for broken links like this: . link_check _example/broken_links . ERROR: The Following Broken Links or Paths were found: - &#39;http://fastlinkcheck.com/test.html&#39; was found in the following pages: - `/Users/hamelsmu/github/fastlinkcheck/_example/broken_links/test.html` - &#39;http://somecdn.com/doesntexist.html&#39; was found in the following pages: - `/Users/hamelsmu/github/fastlinkcheck/_example/broken_links/test.html` - Path(&#39;/Users/hamelsmu/github/fastlinkcheck/_example/broken_links/test.js&#39;) was found in the following pages: - `/Users/hamelsmu/github/fastlinkcheck/_example/broken_links/test.html` . . Specifying the --host parameter allows you detect links that are internal by identifying links with that host name. External links are verified by making a request to the appropriate website. On the other hand, internal links are verified by inspecting the presence and content of local files. . We must be careful when using the --host argument to only pass the host (and path, if necessary) without the protocol. For example, this is how we specify the hostname if your site&#39;s url is http://fastlinkcheck.com/test.html: . link_check _example/broken_links --host fastlinkcheck.com . ERROR: The Following Broken Links or Paths were found: - &#39;http://somecdn.com/doesntexist.html&#39; was found in the following pages: - `/Users/hamelsmu/github/fastlinkcheck/_example/broken_links/test.html` - Path(&#39;/Users/hamelsmu/github/fastlinkcheck/_example/broken_links/test.js&#39;) was found in the following pages: - `/Users/hamelsmu/github/fastlinkcheck/_example/broken_links/test.html` . . We now have one less broken link as there is indeed a file named test.html in the root of the path we are searching. However, if we add a path to the end of --host , such as fastlinkcheck.com/mysite the link would again be listed as broken because _example/broken_links/mysite/test.html does not exist: . link_check _example/broken_links --host fastlinkcheck.com/mysite . ERROR: The Following Broken Links or Paths were found: - &#39;http://fastlinkcheck.com/test.html&#39; was found in the following pages: - `/Users/hamelsmu/github/fastlinkcheck/_example/broken_links/test.html` - &#39;http://somecdn.com/doesntexist.html&#39; was found in the following pages: - `/Users/hamelsmu/github/fastlinkcheck/_example/broken_links/test.html` - Path(&#39;/Users/hamelsmu/github/fastlinkcheck/_example/broken_links/test.js&#39;) was found in the following pages: - `/Users/hamelsmu/github/fastlinkcheck/_example/broken_links/test.html` . . You can ignore links by creating a text file that contains a list of urls and paths to ignore. For example, the file _example/broken_links/linkcheck.rc contains: . cat _example/broken_links/linkcheck.rc . test.js https://www.google.com . We can use this file to ignore urls and paths with the --config_file argument. This will filter out references to the broken link /test.js from our earlier results: . link_check _example/broken_links --host fastlinkcheck.com --config_file _example/broken_links/linkcheck.rc . ERROR: The Following Broken Links or Paths were found: - &#39;http://somecdn.com/doesntexist.html&#39; was found in the following pages: - `/Users/hamelsmu/github/fastlinkcheck/_example/broken_links/test.html` . . Finally, if there are no broken links, link_check will not return anything. The directory _example/no_broken_links/ does not contain any HTML files with broken links: . link_check _example/no_broken_links . No broken links found! . Python . You can also use these utilities from python instead of the terminal. Please see these docs for more information. . Using link_check in GitHub Actions . The link_check CLI utility that is installed with fastlinkcheck can be very useful in continuous integration systems like GitHub Actions. Here is an example GitHub Actions workflow that uses link_check: . name: Check Links on: [workflow_dispatch, push] jobs: check-links: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - uses: actions/setup-python@v2 - name: check for broken links run: | pip install fastlinkcheck link_check _example . We can a few more lines of code to open an issue instead when a broken link is found, using the gh cli: . ... - name: check for broken links run: | pip install fastlinkcheck link_check _example 2&gt; err || true export GITHUB_TOKEN=&quot;YOUR_TOKEN&quot; [[ -s err ]] &amp;&amp; gh issue create -t &quot;Broken links found&quot; -b &quot;$(&lt; err)&quot; -R &quot;yourusername/yourrepo&quot; . We can extend this even further to only open an issue when another issue with a specific label isn&#39;t already open: . ... - name: check for broken links run: | pip install fastlinkcheck link_check &quot;docs/_site&quot; --host &quot;docs.fast.ai&quot; 2&gt; err || true export GITHUB_TOKEN=&quot;YOUR_TOKEN&quot; if [[ -z $(gh issue list -l &quot;broken-link&quot;)) &amp;&amp; (-s err) ]]; then gh issue create -t &quot;Broken links found&quot; -b &quot;$(&lt; err)&quot; -l &quot;broken-link&quot; -R &quot;yourusername/yourrepo&quot; fi . See the GitHub Actions docs for more information. . Resources . The following resources are relevant for those interested in learning more about fastlinkcheck: . The fastlinkcheck GitHub repo | The fastlinkcheck docs | .",
            "url": "/sambaiga/fastlinkcheck/",
            "relUrl": "/fastlinkcheck/",
            "date": " • Nov 17, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "fastcore: An Underrated Python Library",
            "content": ". Background . I recently embarked on a journey to sharpen my python skills: I wanted to learn advanced patterns, idioms, and techniques. I started with reading books on advanced Python, however, the information didn&#39;t seem to stick without having somewhere to apply it. I also wanted the ability to ask questions from an expert while I was learning -- which is an arrangement that is hard to find! That&#39;s when it occurred to me: What if I could find an open source project that has fairly advanced python code and write documentation and tests? I made a bet that if I did this it would force me to learn everything very deeply, and the maintainers would be appreciative of my work and be willing to answer my questions. . And that&#39;s exactly what I did over the past month! I&#39;m pleased to report that it has been the most efficient learning experience I&#39;ve ever experienced. I&#39;ve discovered that writing documentation forced me to deeply understand not just what the code does but also why the code works the way it does, and to explore edge cases while writing tests. Most importantly, I was able to ask questions when I was stuck, and maintainers were willing to devote extra time knowing that their mentorship was in service of making their code more accessible! It turns out the library I choose, fastcore is some of the most fascinating Python I have ever encountered as its purpose and goals are fairly unique. . For the uninitiated, fastcore is a library on top of which many fast.ai projects are built on. Most importantly, fastcore extends the python programming language and strives to eliminate boilerplate and add useful functionality for common tasks. In this blog post, I&#39;m going to highlight some of my favorite tools that fastcore provides, rather than sharing what I learned about python. My goal is to pique your interest in this library, and hopefully motivate you to check out the documentation after you are done to learn more! . Why fastcore is interesting . Get exposed to ideas from other languages without leaving python: I’ve always heard that it is beneficial to learn other languages in order to become a better programmer. From a pragmatic point of view, I’ve found it difficult to learn other languages because I could never use them at work. Fastcore extends python to include patterns found in languages as diverse as Julia, Ruby and Haskell. Now that I understand these tools I am motivated to learn other languages. | You get a new set of pragmatic tools: fastcore includes utilities that will allow you to write more concise expressive code, and perhaps solve new problems. | Learn more about the Python programming language: Because fastcore extends the python programming language, many advanced concepts are exposed during the process. For the motivated, this is a great way to see how many of the internals of python work. | A whirlwind tour through fastcore . Here are some things you can do with fastcore that immediately caught my attention. . . Making **kwargs transparent . Whenever I see a function that has the argument **kwargs, I cringe a little. This is because it means the API is obfuscated and I have to read the source code to figure out what valid parameters might be. Consider the below example: . def baz(a, b=2, c =3, d=4): return a + b + c def foo(c, a, **kwargs): return c + baz(a, **kwargs) inspect.signature(foo) . &lt;Signature (c, a, **kwargs)&gt; . Without reading the source code, it might be hard for me to know that foo also accepts and additional parameters b and d. We can fix this with delegates: . def baz(a, b=2, c =3, d=4): return a + b + c @delegates(baz) # this decorator will pass down keyword arguments from baz def foo(c, a, **kwargs): return c + baz(a, **kwargs) inspect.signature(foo) . &lt;Signature (c, a, b=2, d=4)&gt; . You can customize the behavior of this decorator. For example, you can have your cake and eat it too by passing down your arguments and also keeping **kwargs: . @delegates(baz, keep=True) def foo(c, a, **kwargs): return c + baz(a, **kwargs) inspect.signature(foo) . &lt;Signature (c, a, b=2, d=4, **kwargs)&gt; . You can also exclude arguments. For example, we exclude argument d from delegation: . def basefoo(a, b=2, c =3, d=4): pass @delegates(basefoo, but= [&#39;d&#39;]) # exclude `d` def foo(c, a, **kwargs): pass inspect.signature(foo) . &lt;Signature (c, a, b=2)&gt; . You can also delegate between classes: . class BaseFoo: def __init__(self, e, c=2): pass @delegates()# since no argument was passsed here we delegate to the superclass class Foo(BaseFoo): def __init__(self, a, b=1, **kwargs): super().__init__(**kwargs) inspect.signature(Foo) . &lt;Signature (a, b=1, c=2)&gt; . For more information, read the docs on delegates. . . Avoid boilerplate when setting instance attributes . Have you ever wondered if it was possible to avoid the boilerplate involved with setting attributes in __init__? . class Test: def __init__(self, a, b ,c): self.a, self.b, self.c = a, b, c . Ouch! That was painful. Look at all the repeated variable names. Do I really have to repeat myself like this when defining a class? Not Anymore! Checkout store_attr: . class Test: def __init__(self, a, b, c): store_attr() t = Test(5,4,3) assert t.b == 4 . You can also exclude certain attributes: . class Test: def __init__(self, a, b, c): store_attr(but=[&#39;c&#39;]) t = Test(5,4,3) assert t.b == 4 assert not hasattr(t, &#39;c&#39;) . There are many more ways of customizing and using store_attr than I highlighted here. Check out the docs for more detail. . P.S. you might be thinking that Python dataclasses also allow you to avoid this boilerplate. While true in some cases, store_attr is more flexible.1 . 1. For example, store_attr does not rely on inheritance, which means you won&#39;t get stuck using multiple inheritance when using this with your own classes. Also, unlike dataclasses, store_attr does not require python 3.7 or higher. Furthermore, you can use store_attr anytime in the object lifecycle, and in any location in your class to customize the behavior of how and when variables are stored.↩ . . Avoiding subclassing boilerplate . One thing I hate about python is the __super__().__init__() boilerplate associated with subclassing. For example: . class ParentClass: def __init__(self): self.some_attr = &#39;hello&#39; class ChildClass(ParentClass): def __init__(self): super().__init__() cc = ChildClass() assert cc.some_attr == &#39;hello&#39; # only accessible b/c you used super . We can avoid this boilerplate by using the metaclass PrePostInitMeta. We define a new class called NewParent that is a wrapper around the ParentClass: . class NewParent(ParentClass, metaclass=PrePostInitMeta): def __pre_init__(self, *args, **kwargs): super().__init__() class ChildClass(NewParent): def __init__(self):pass sc = ChildClass() assert sc.some_attr == &#39;hello&#39; . . Type Dispatch . Type dispatch, or Multiple dispatch, allows you to change the way a function behaves based upon the input types it receives. This is a prominent feature in some programming languages like Julia. For example, this is a conceptual example of how multiple dispatch works in Julia, returning different values depending on the input types of x and y: . collide_with(x::Asteroid, y::Asteroid) = ... # deal with asteroid hitting asteroid collide_with(x::Asteroid, y::Spaceship) = ... # deal with asteroid hitting spaceship collide_with(x::Spaceship, y::Asteroid) = ... # deal with spaceship hitting asteroid collide_with(x::Spaceship, y::Spaceship) = ... # deal with spaceship hitting spaceship . Type dispatch can be especially useful in data science, where you might allow different input types (i.e. Numpy arrays and Pandas dataframes) to a function that processes data. Type dispatch allows you to have a common API for functions that do similar tasks. . Unfortunately, Python does not support this out-of-the box. Fortunately, there is the @typedispatch decorator to the rescue. This decorator relies upon type hints in order to route inputs the correct version of the function: . @typedispatch def f(x:str, y:str): return f&#39;{x}{y}&#39; @typedispatch def f(x:np.ndarray): return x.sum() @typedispatch def f(x:int, y:int): return x+y . Below is a demonstration of type dispatch at work for the function f: . f(&#39;Hello &#39;, &#39;World!&#39;) . &#39;Hello World!&#39; . f(2,3) . 5 . f(np.array([5,5,5,5])) . 20 . There are limitations of this feature, as well as other ways of using this functionality that you can read about here. In the process of learning about typed dispatch, I also found a python library called multipledispatch made by Mathhew Rocklin (the creator of Dask). . After using this feature, I am now motivated to learn languages like Julia to discover what other paradigms I might be missing. . . A better version of functools.partial . functools.partial is a great utility that creates functions from other functions that lets you set default values. Lets take this function for example that filters a list to only contain values &gt;= val: . test_input = [1,2,3,4,5,6] def f(arr, val): &quot;Filter a list to remove any values that are less than val.&quot; return [x for x in arr if x &gt;= val] f(test_input, 3) . [3, 4, 5, 6] . You can create a new function out of this function using partial that sets the default value to 5: . filter5 = partial(f, val=5) filter5(test_input) . [5, 6] . One problem with partial is that it removes the original docstring and replaces it with a generic docstring: . filter5.__doc__ . &#39;partial(func, *args, **keywords) - new function with partial application n of the given arguments and keywords. n&#39; . fastcore.utils.partialler fixes this, and makes sure the docstring is retained such that the new API is transparent: . filter5 = partialler(f, val=5) filter5.__doc__ . &#39;Filter a list to remove any values that are less than val.&#39; . . Composition of functions . A technique that is pervasive in functional programming languages is function composition, whereby you chain a bunch of functions together to achieve some kind of result. This is especially useful when applying various data transformations. Consider a toy example where I have three functions: (1) Removes elements of a list less than 5 (from the prior section) (2) adds 2 to each number (3) sums all the numbers: . def add(arr, val): return [x + val for x in arr] def arrsum(arr): return sum(arr) # See the previous section on partialler add2 = partialler(add, val=2) transform = compose(filter5, add2, arrsum) transform([1,2,3,4,5,6]) . 15 . But why is this useful? You might me thinking, I can accomplish the same thing with: . arrsum(add2(filter5([1,2,3,4,5,6]))) . You are not wrong! However, composition gives you a convenient interface in case you want to do something like the following: . def fit(x, transforms:list): &quot;fit a model after performing transformations&quot; x = compose(*transforms)(x) y = [np.mean(x)] * len(x) # its a dumb model. Don&#39;t judge me return y # filters out elements &lt; 5, adds 2, then predicts the mean fit(x=[1,2,3,4,5,6], transforms=[filter5, add2]) . [7.5, 7.5] . For more information about compose, read the docs. . . A more useful __repr__ . In python, __repr__ helps you get information about an object for logging and debugging. Below is what you get by default when you define a new class. (Note: we are using store_attr, which was discussed earlier). . class Test: def __init__(self, a, b=2, c=3): store_attr() # `store_attr` was discussed previously Test(1) . &lt;__main__.Test at 0x7ffcd766cee0&gt; . We can use basic_repr to quickly give us a more sensible default: . class Test: def __init__(self, a, b=2, c=3): store_attr() __repr__ = basic_repr(&#39;a,b,c&#39;) Test(2) . Test(a=2, b=2, c=3) . . Monkey Patching With A Decorator . It can be convenient to monkey patch with a decorator, which is especially helpful when you want to patch an external library you are importing. We can use the decorator @patch from fastcore.foundation along with type hints like so: . class MyClass(int): pass @patch def func(self:MyClass, a): return self+a mc = MyClass(3) . Now, MyClass has an additional method named func: . mc.func(10) . 13 . Still not convinced? I&#39;ll show you another example of this kind of patching in the next section. . . A better pathlib.Path . When you see these extensions to pathlib.path you won&#39;t ever use vanilla pathlib again! A number of additional methods have been added to pathlib, such as: . Path.readlines: same as with open(&#39;somefile&#39;, &#39;r&#39;) as f: f.readlines() | Path.read: same as with open(&#39;somefile&#39;, &#39;r&#39;) as f: f.read() | Path.save: saves file as pickle | Path.load: loads pickle file | Path.ls: shows the contents of the path as a list. | etc. | . Read more about this here. Here is a demonstration of ls: . from fastcore.utils import * from pathlib import Path p = Path(&#39;.&#39;) p.ls() # you don&#39;t get this with vanilla Pathlib.Path!! . (#7) [Path(&#39;2020-09-01-fastcore.ipynb&#39;),Path(&#39;README.md&#39;),Path(&#39;fastcore_imgs&#39;),Path(&#39;2020-02-20-test.ipynb&#39;),Path(&#39;.ipynb_checkpoints&#39;),Path(&#39;2020-02-21-introducing-fastpages.ipynb&#39;),Path(&#39;my_icons&#39;)] . Wait! What&#39;s going on here? We just imported pathlib.Path - why are we getting this new functionality? Thats because we imported the fastcore.utils module, which patches this module via the @patch decorator discussed earlier. Just to drive the point home on why the @patch decorator is useful, I&#39;ll go ahead and add another method to Path right now: . @patch def fun(self:Path): return &quot;This is fun!&quot; p.fun() . &#39;This is fun!&#39; . That is magical, right? I know! That&#39;s why I&#39;m writing about it! . . An Even More Concise Way To Create Lambdas . Self, with an uppercase S, is an even more concise way to create lambdas that are calling methods on an object. For example, let&#39;s create a lambda for taking the sum of a Numpy array: . arr=np.array([5,4,3,2,1]) f = lambda a: a.sum() assert f(arr) == 15 . You can use Self in the same way: . f = Self.sum() assert f(arr) == 15 . Let&#39;s create a lambda that does a groupby and max of a Pandas dataframe: . import pandas as pd df=pd.DataFrame({&#39;Some Column&#39;: [&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;b&#39;, ], &#39;Another Column&#39;: [5, 7, 50, 70]}) f = Self.groupby(&#39;Some Column&#39;).mean() f(df) . Another Column . Some Column . a 6 | . b 60 | . Read more about Self in the docs). . . Notebook Functions . These are simple but handy, and allow you to know whether or not code is executing in a Jupyter Notebook, Colab, or an Ipython Shell: . from fastcore.imports import in_notebook, in_colab, in_ipython in_notebook(), in_colab(), in_ipython() . (True, False, True) . This is useful if you are displaying certain types of visualizations, progress bars or animations in your code that you may want to modify or toggle depending on the environment. . . A Drop-In Replacement For List . You might be pretty happy with Python&#39;s list. This is one of those situations that you don&#39;t know you needed a better list until someone showed one to you. Enter L, a list like object with many extra goodies. . The best way I can describe L is to pretend that list and numpy had a pretty baby: . define a list (check out the nice __repr__ that shows the length of the list!) . L(1,2,3) . (#3) [1,2,3] . Shuffle a list: . p = L.range(20).shuffle() p . (#20) [8,7,5,12,14,16,2,15,19,6...] . Index into a list: . p[2,4,6] . (#3) [5,14,2] . L has sensible defaults, for example appending an element to a list: . 1 + L(2,3,4) . (#4) [1,2,3,4] . There is much more L has to offer. Read the docs to learn more. . But Wait ... There&#39;s More! . There are more things I would like to show you about fastcore, but there is no way they would reasonably fit into a blog post. Here is a list of some of my favorite things that I didn&#39;t demo in this blog post: . Utilities . The Basics section contain many shortcuts to perform common tasks or provide an additional interface to what standard python provides. . mk_class: quickly add a bunch of attributes to a class | wrap_class: add new methods to a class with a simple decorator | groupby: similar to Scala&#39;s groupby | merge: merge dicts | fasttuple: a tuple on steroids | Infinite Lists: useful for padding and testing | chunked: for batching and organizing stuff | . Multiprocessing . The Multiprocessing section extends python&#39;s multiprocessing library by offering features like: . progress bars | ability to pause to mitigate race conditions with external services | processing things in batches on each worker, ex: if you have a vectorized operation to perform in chunks | . Functional Programming . The functional programming section is my favorite part of this library. . maps: a map that also composes functions | mapped: A more robust map | using_attr: compose a function that operates on an attribute | . Transforms . Transforms is a collection of utilities for creating data transformations and associated pipelines. These transformation utilities build upon many of the building blocks discussed in this blog post. . Further Reading . It should be noted that you should read the main page of the docs first, followed by the section on tests to fully understand the documentation. . The fastcore documentation site. | The fastcore GitHub repo. | Blog post on delegation. | . Shameless plug: fastpages . This blog post was written entirely in a Jupyter Notebook, which GitHub automatically converted into to a blog post! Sound interesting? Check out fastpages. .",
            "url": "/sambaiga/fastcore/",
            "relUrl": "/fastcore/",
            "date": " • Sep 1, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "AI4EO-An Opportunity for Computation Sustainability",
            "content": "Introduction . Computational Sustainability focuses on developing computational models, methods, and tools to help policymakers design more effective solutions and policies for sustainable development. The advancement of Information and Communication Technologies (ICT), particularly Earth Observation (EO) and Artificial intelligence (AI) offer prospects of addressing sustainability challenges. A more in-depth explanation about the above project can be viewed in this video: . Earth observations (EO) are data and information about the planet’s physical, chemical, and biological systems. It involves the collection, analysis, and presentation about the status of, and changes in, the natural and human-made environment. The most common sources of EO data include drones, land stations, and satellites. While drones capture high-resolution images on a small scale, satellites generate growing amounts of multi-resolution and multi-bands imagery and other data sources for the whole Earth. These data could be used to create all kinds of different products so that businesses, scientists, policymakers, and even everyday citizens can understand the past, present, and future trends in the Earth systems. Figure below shows multiband imagery from satellites by the electromagnetic. . On the other hand, AI is an area of computer science devoted to developing systems that can learn (from data) to make decisions and predictions within specific contexts. Indeed, AI technology can extract more in-depth insights from datasets than other techniques. Lately, AI has been used with success in solving complex problems in several domains such as machine translation, computer vision, autonomous cars, to mention a few. Machine learning and particularly computer vision models provide explicitly useful and practical approaches for analyzing and extracting relevant information from EO imagery data. Deep learning models and especially Convolution Neural Networks (CNNs) have proven effective in several computer vision tasks such as object detection, classification, and video processing, image generations, and image captioning, to mention a few. These models could be applied to detect and classify objects from complex EO imagery at a larger scale. Figure 2 presents AI capability for object detection and using computer vision techniques for multiband satellite images. This image has been taken from here). . Applying these techniques to EO data will make it easy to efficiently automate the recognition of known and unknown patterns at large-scale. This is likely to reveal useful insights and opportunities for addressing sustainability challenges. For example, AI models could be applied to perform automated change detection, crop mapping, and yield estimation from high-resolution imagery in a larger-scale. The fusion of EO data and other data sources such as geo-referenced, demographics, and social-network data can be used to facilitate the more targeted developmental challenge. For instance, it has been demonstrated that the AI model can be used to predict the poverty level by analyzing satellite imagery, night lights, and demographic data. . EO data sources . There are many EO data sources made available recently. These data sources offer virtual visualization of any location on earth with resolution ranging from 5 centimeters to 120 meters depending on the instruments of satellites, airbus, or drones. The data sources are published as public or commercial data sources. . Public EO data providers . The EO puplic data providers are public service framework that allows full, free and open access to all data collected. Copernicus and Landsat are the famous and largest public satellite data providers. Landsat s one of the world’s largest satellite image providers. It is a joint program of the National Aeronautics and Space Administration (NASA) and the United States Geological Survey (USGS). It provides access to satellites of the Landsat family, which have access over the archival of 50 years of earth data. Landsat satellites collect data on the forests, farms, urban areas, and water sources, generating the longest continuous record. The freely available information is used to understand environmental change better, manage agricultural practices, allocate scarce water resources, monitor the extent and health of forests and respond to natural disasters, and more. Data can be accessed using LandsLook Viewer, USGS GloVis, Earth Explorer, Free Web-Enabled Landsat Data (WELD). More information is available here. . Copernicus is managed by the Europe Unions EO program and collect data from a constellation of 6 families of satellites, known as Sentinels. Each Sentinel mission focuses on different but interrelated aspects of EO, including Atmospheric monitoring (Sentinels 4 and 5), Marine environment monitoring (Sentinel-3), Land monitoring (Sentinel-2), Climate Change and Emergency management. Currently Copernicus produces 12 terabytes per day of data for the 6 families of satellites, known as “Sentinels.” The data are open access and can be freely downloaded using [Copernicus Open Access Hub]. A summary of Copernicus program can found in this video . Commercial data providers . The commercial satellite imagery providers provide access to data with high resolution with 3 centimeters to 10 meters. These services are paid and have good archival imagery. The most popular commercial EO imagery providers include; Planet Labs, DigitalGlobe and Airbus. . Planet Labs provides access to a wide range of satellite data. It provides access to SkySAT families and RapidEye satellites. With 120+ satellites in orbit, Planet can image anywhere on Earth’s landmass daily, at 3 - 5-meter resolution. Planet processes and delivers imagery quickly and efficiently. Planet’s platform downloads and processes 11+ TB of data daily, enabling customers to build and run analytics at scale. Users can access Planet’s data, using the paid planet API. Nevertheless, university researchers, academics, and scientists apply for free access as decribed in this link. . The DigitalGlobe is similar to Planet Labs and provides data access to a full range constellation of satellites in orbit. It provides access to EarlyBird-1, IKONOS, QuickBird, GeoEye-1, a family of WorldView satellites. It offers a high resolution of up to 30cm, showing crisp details, satellite imagery, geospatial information, and location-based intelligence. Recently, DigitalGlobe has started providing 0.4m resolution imagery today, which is one of the best in the business. . On the other hand, the Airbus, with Pleiades and SPOT missions, provide very high-resolution multispectral twin satellites with 0.5 meters and 1.5-meter resolution, respectively. These imagery data are particularly suitable for emergency response and up-to daily change detection. . AI ready EO datasets . Building ML applications for EO requires access to both EO data and their ground truth. Creating such a data-set is time-consuming and costly. As a result different organisations provide ready-to-use EO dataset which allow ML and GIS researchers and other stakeholders to build and test their ML application specific to EO. Radiant MLHub and Spacenet are the two notable EO training data providers. Radiant MLHub is an open library for geospatial training data to advance machine learning applications on EO. It hosts open training datasets generated by Radiant Earth Foundation’s team as well as other training data catalogs contributed by Radiant Earth’s partners. The data provided by Radiant MLHub are stored using a SpatioTemporal Asset Catalog (STAC) compliant catalog and exposed through a standard API. These data are open to anyone to use. It also free stores, register and share your dataset. . The Spacenet, on the other hand, provides access to high-quality geospatial data for developers, researchers, and startups with a specific focus on the four open-source key pillars: data, challenges, algorithms, and tools. It also hosts challenges that focus on applying advanced machine learning techniques to solve difficult mapping challenges. The SpaceNet Dataset is hosted as an Amazon Web Services (AWS) Public Dataset, which is open for geospatial machine learning research. The dataset consists of well-annotated and very high-resolution satellite imagery with foundational mapping features such as building footprints or road networks. . Kaggle, a world’s largest data science community with powerful tools and resources, is another source of EO training datasets which host several machine learning challenges EO imagery. This challenges includes Dstl Satellite Imagery Feature Detection, Airbus Ship Detection Challenge and Draper Satellite Image Chronology to mention a few. . . API for accessing EO data. . Despite the availability of free and commercial satellite imagery, it is somehow challenging to directly download and use these data. Accessing these data requires one to have expertise in satellite imagery. Several API solutions that make it easy to access, download, and use satellite imagery from different sources have been developed to address these challenges. Sentinel Hub API is one of the easily available data API. . Sentinel Hub API makes satellite data from Sentinel, Landsat, and other Earth observation imagery easily accessible via easy-to-integrate web services. The API allows users to integrate satellite data either into their applications. To this end, Sentinel-hub offers several plugins such as sentinelhub-python, Sentinelhub-js, Sentinel Hub QGIS and EO Browser which is is a search tool for Sentinel-2 and Landsat 5,7,8 satellite imagery. Sentinelhub-js offer seamless integration of Sentinel Hub and other similar EO web services in web or node.js. This allows web developers to access remote sensing data quickly and to integrate it with their applications. On the other hand, the sentinel hub-python enables users to seamlessly make requests from Sentinel Hub OGC web services, download, and process images within their Python scripts. The Sentinel Hub QGIS plugin allows users to configure and harness Sentinel Hub services directly in QGIS. The Sentinel Hub API is the paid services but the also offer free access for research purpose. More details could found on this link. . Users can also use sentinelsat a python API for searching, downloading and retrieving the metadata of Sentinel satellite images from the Copernicus Open Access Hub. Compared to Sentinel-hub API, this is free services limited to only Copernicus satellites. . Opportunity and Challenges of AI4EO . Machine learning, precisely computer vision, can be applied to EO imagery data for multimodal semantic segmentation, detecting objects, detecting changes from a time series satellite image or image retrieval. The computer vision model can automatically generate semantic maps of a large area from EO data [Audebert2017a]. The resulting semantic maps can be used for the cartography of urban areas or to determine land use cover at a massive scale. In change detection, machine learning models could be used to extend the semantic analysis of EO data by incorporating the multi-temporal dimension. This enables us to track changes around the globe or monitor activity in high-revisit rate acquisitions. It also plays an essential role in the production of maps depicting the evolutions of land use, urban coverage, deforestation, and other multi-temporal type analysis. The image retrieval aims to retrieve images with similar visual contents with respect to the query image from a database. . . Even though AI provides a potential application to EO, several challenges need to be addressed to successfully exploits AI potentials. This is because compared to other types of Data, EO present several challenges for machine learning algorithms. The following video discuss some of the opportunities and challenges of machine learning for EO. . First, the EO data is multimodal and high dimensional. For instance, the EO satellite data come from a variety of sensors types such as passive sensors (RBGN), active sensors (Synthetic Aperture Radar (SAR)), near-infrared sensors. The data also contain additional geo-related data like weather, geo-physical or biochemical quantities and other derived products. This data variety raises the following fundamental challenges when applied to the machine learning model: *how to combine all these data types (data fusion) since all these sources provide complementary information that should be used jointly to maximize the model’s performance. As a result, there is a need to develop novel machine learning models that match EO data taken from different sources with different imaging modalities. Modifying existing vision-based deep networks to these data is not trivial, as this requires to work with new data structures that do not share the same underlying physical and numerical properties. Other exciting topics could be investigating the transferability of deep learning networks to [EO imaging modalities] (https://ieeexplore.ieee.org/document/8113128). Among the other challenges are the sheer number of pixels and the geographic extent per image. For example, a single DigitalGlobe satellite image encompasses &gt; 64 km2 and over 250 million pixels. Also, the objects of interest are microscopic, which complicates traditional computer vision techniques. . The size of EO data is increasing at an exponential rate demanding automation, massive computing, and machine learning algorithms that are fast enough and sufficiently transferrable to be applied for the whole earth’s surface. Besides, these data contain plenty of unlabelled data, making it challenging to use well-established supervised machine learning techniques. Yet this provides an opportunity to explore the recent progress in semi-supervised learning, self-supervised and active-learning methods for EO application. Furthermore, the existence of meta-data and other geo-referenced data such as the Open-street map (OSM) provides an opportunity for creating annotated satellite imagery data for machine learning algorithms. . It should be noted that EO data are time-variable dependent as satellite guarantees continuous data acquisition for decades. For example, the sentinel-1 images the entire earth every six days. Thus machine learning algorithms for EO imagery analysis should jointly exploit both the temporal, spectral, and spatial information of these data. . The interpretability of the machine learning model applicable to EO is another exciting research opportunity. Machine learning models are useful to estimate correlations, but what about causations. Exploiting graphical models and causal discovery to learns cause and effects relations from EO data is a unique opportunity for machine learning in EO. This can be useful for hypothesis testing, model-data comparison, and understanding the causes of extreme impacts. . Conclusion . The satellite has been in the orbit of the earth for many decades, but the access to the data and applications using satellite images has recently become prominent. In this blog, we have introduced the opportunity of using Earth Observation and Artificial Intelligence to address sustainability challenges. We introduced different sources for EO data sources that include public and private satellite providers. We also presented the prominent AI-ready EO data providers and introduced Sentinel-hub, which is an API for accessing EO data from different sources. Finally, the blog highlight opportunity and challenges of applying advanced machine learning techniques such as deep learning for EO imagery data. In the upcoming blog, we will discuss how to download, process, and use EO data for machine learning applications with a specif focus on computational sustainability. Stay tuned for more! . References . Working towards AI and Earth observation | .",
            "url": "/sambaiga/machine%20learning/deep%20learning/eearth%20observation/2020/06/20/eo-blog-one.html",
            "relUrl": "/machine%20learning/deep%20learning/eearth%20observation/2020/06/20/eo-blog-one.html",
            "date": " • Jun 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Introducing fastpages",
            "content": ". We are very pleased to announce the immediate availability of fastpages. fastpages is a platform which allows you to create and host a blog for free, with no ads and many useful features, such as: . Create posts containing code, outputs of code (which can be interactive), formatted text, etc directly from Jupyter Notebooks; for instance see this great example post from Scott Hawley. Notebook posts support features such as: Interactive visualizations made with Altair remain interactive. | Hide or show cell input and output. | Collapsable code cells that are either open or closed by default. | Define the Title, Summary and other metadata via a special markdown cells | Ability to add links to Colab and GitHub automatically. | . | Create posts, including formatting and images, directly from Microsoft Word documents. | Create and edit Markdown posts entirely online using GitHub&#39;s built-in markdown editor. | Embed Twitter cards and YouTube videos. | Categorization of blog posts by user-supplied tags for discoverability. | ... and much more | . fastpages relies on Github pages for hosting, and Github Actions to automate the creation of your blog. The setup takes around three minutes, and does not require any technical knowledge or expertise. Due to built-in automation of fastpages, you don&#39;t have to fuss with conversion scripts. All you have to do is save your Jupyter notebook, Word document or markdown file into a specified directory and the rest happens automatically. Infact, this blog post is written in a Jupyter notebook, which you can see with the &quot;View on GitHub&quot; link above. . fast.ai have previously released a similar project called fast_template, which is even easier to set up, but does not support automatic creation of posts from Microsoft Word or Jupyter notebooks, including many of the features outlined above. . Because fastpages is more flexible and extensible, we recommend using it where possible. fast_template may be a better option for getting folks blogging who have no technical expertise at all, and will only be creating posts using Github&#39;s integrated online editor. . Setting Up Fastpages . The setup process of fastpages is automated with GitHub Actions, too! Upon creating a repo from the fastpages template, a pull request will automatically be opened (after ~ 30 seconds) configuring your blog so it can start working. The automated pull request will greet you with instructions like this: . . All you have to do is follow these instructions (in the PR you receive) and your new blogging site will be up and running! . Jupyter Notebooks &amp; Fastpages . In this post, we will cover special features that fastpages provides for Jupyter notebooks. You can also write your blog posts with Word documents or markdown in fastpages, which contain many, but not all the same features. . Options via FrontMatter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . All of the above settings are enabled in this post, so you can see what they look like! . the summary field (preceeded by &gt;) will be displayed under your title, and will also be used by social media to display as the description of your page. | toc: setting this to true will automatically generate a table of contents | badges: setting this to true will display Google Colab and GitHub links on your blog post. | comments: setting this to true will enable comments. See these instructions for more details. | author this will display the authors names. | categories will allow your post to be categorized on a &quot;Tags&quot; page, where readers can browse your post by categories. | . Markdown front matter is formatted similarly to notebooks. The differences between the two can be viewed on the fastpages README. . Code Folding . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . If you want to completely hide cells (not just collapse them), read these instructions. . Interactive Charts With Altair . Interactive visualizations made with Altair remain interactive! . We leave this below cell unhidden so you can enjoy a preview of syntax highlighting in fastpages, which uses the Dracula theme. . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;IMDB_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget IMDB_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | 6.1 | . 1 First Love, Last Rites | 10876.0 | 300000.0 | 6.9 | . 2 I Married a Strange Person | 203134.0 | 250000.0 | 6.8 | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | NaN | . 4 Slam | 1087521.0 | 1000000.0 | 3.4 | . Other Features . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Images w/Captions . You can include markdown images with captions like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Of course, the caption is optional. . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . More Examples . This tutorial contains more examples of what you can do with notebooks. . How fastpages Converts Notebooks to Blog Posts . fastpages uses nbdev to power the conversion process of Jupyter Notebooks to blog posts. When you save a notebook into the /_notebooks folder of your repository, GitHub Actions applies nbdev against those notebooks automatically. The same process occurs when you save Word documents or markdown files into the _word or _posts directory, respectively. . We will discuss how GitHub Actions work in a follow up blog post. . Resources &amp; Next Steps . We highly encourage you to start blogging with fastpages! Some resources that may be helpful: . fastpages repo - this is where you can go to create your own fastpages blog! | Fastai forums - nbdev &amp; blogging category. You can ask questions about fastpages here, as well as suggest new features. | nbdev: this project powers the conversion of Jupyter notebooks to blog posts. | . If you end up writing a blog post using fastpages, please let us know on Twitter: @jeremyphoward, @HamelHusain. .",
            "url": "/sambaiga/fastpages/jupyter/2020/02/21/introducing-fastpages.html",
            "relUrl": "/fastpages/jupyter/2020/02/21/introducing-fastpages.html",
            "date": " • Feb 21, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "/sambaiga/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Microsoft Word Example Post",
            "content": "When writing a blog post with Microsoft Word – the filename becomes the title. In this case the file name is “2020-01-01-Microsoft-Word-Example-Post.docx”. . There is minimal support for Word documents in fastpages compared to Jupyter notebooks. Some known limitations: . alt text in Word documents are not yet supported by fastpages, and will break links to images. . | You can only specify front matter for Word documents globally. See the README for more details. . | . For greater control over the content produced from Word documents, you will need to convert Word to markdown files manually. You can follow the steps in this blog post, which walk you through how to use pandoc to do the conversion. Note: If you wish to customize your Word generated blog post in markdown, make sure you delete your Word document from the _word directory so your markdown file doesn’t get overwritten! . If your primary method of writing blog posts is Word documents, and you plan on always manually editing Word generated markdown files, you are probably better off using fast_template instead of fastpages. . The material below is a reproduction of this blog post, and serves as an illustrative example. . Maintaining a healthy open source project can entail a huge amount of toil. Popular projects often have orders of magnitude more users and episodic contributors opening issues and PRs than core maintainers capable of handling these issues. . Consider this graphic prepared by the NumFOCUS foundation showing the number of maintainers for three widely used scientific computing projects: . . We can see that across these three projects, there is a very low ratio maintainers to users. Fixing this problem is not an easy task and likely requires innovative solutions to address the economics as well as tools. . Due to its recent momentum and popularity, Kubeflow suffers from a similar fate as illustrated by the growth of new issues opened: . . Source: “TensorFlow World 2019, Automating Your Developer Workflow With ML” . Coincidentally, while building out end to end machine learning examples for Kubeflow, we built two examples using publicly available GitHub data: GitHub Issue Summarization and Code Search. While these tutorials were useful for demonstrating components of Kubeflow, we realized that we could take this a step further and build concrete data products that reduce toil for maintainers. . This is why we started the project kubeflow/code-intelligence, with the goals of increasing project velocity and health using data driven tools. Below are two projects we are currently experimenting with : . Issue Label Bot: This is a bot that automatically labels GitHub issues using Machine Learning. This bot is a GitHub App that was originally built for Kubeflow but is now also used by several large open source projects. The current version of this bot only applies a very limited set of labels, however we are currently A/B testing new models that allow personalized labels. Here is a blog post discussing this project in more detail. . | Issue Triage GitHub Action: to compliment the Issue Label Bot, we created a GitHub Action that automatically adds / removes Issues to the Kubeflow project board tracking issues needing triage. . | Together these projects allow us to reduce the toil of triaging issues. The GitHub Action makes it much easier for the Kubeflow maintainers to track issues needing triage. With the label bot we have taken the first steps in using ML to replace human intervention. We plan on using features extracted by ML to automate more steps in the triage process to further reduce toil. . Building Solutions with GitHub Actions . One of the premises of Kubeflow is that a barrier to building data driven, ML powered solutions is getting models into production and integrated into a solution. In the case of building models to improve OSS project health, that often means integrating with GitHub where the project is hosted. . We are really excited by GitHub’s newly released feature GitHub Actions because we think it will make integrating ML with GitHub much easier. . For simple scripts, like the issue triage script, GitHub actions make it easy to automate executing the script in response to GitHub events without having to build and host a GitHub app. . To automate adding/removing issues needing triage to a Kanban board we wrote a simple python script that interfaces with GitHub’s GraphQL API to modify issues. . As we continue to iterate on ML Models to further reduce toil, GitHub Actions will make it easy to leverage Kubeflow to put our models into production faster. A number of prebuilt GitHub Actions make it easy to create Kubernetes resources in response to GitHub events. For example, we have created GitHub Actions to launch Argo Workflows. This means once we have a Kubernetes job or workflow to perform inference we can easily integrate the model with GitHub and have the full power of Kubeflow and Kubernetes (eg. GPUs). We expect this will allow us to iterate much faster compared to building and maintaining GitHub Apps. . Call To Action . We have a lot more work to do in order to achieve our goal of reducing the amount of toil involved in maintaining OSS projects. If your interested in helping out here’s a couple of issues to get started: . Help us create reports that pull and visualize key performance indicators (KPI). https://github.com/kubeflow/code-intelligence/issues/71 . We have defined our KPI here: issue #19 | . | Combine repo specific and non-repo specific label predictions: https://github.com/kubeflow/code-intelligence/issues/70 . | . In addition to the aforementioned issues we welcome contributions for these other issues in our repo. .",
            "url": "/sambaiga/2020/01/01/Microsoft-Word-Example-Post.html",
            "relUrl": "/2020/01/01/Microsoft-Word-Example-Post.html",
            "date": " • Jan 1, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Introduction to Machine Learning - Classification.",
            "content": "Introduction . Previously we learned how to predict continuous-valued quantities as a linear function of input values. This post will describe a classification problem where the goal is to learn a mapping from inputs $x$ to target $t$ such that $t in {1 ldots C }$ with $C$ being the number of classes.If $C = 2$, this is called binary classification (in which case we often assume $y in {0, 1}$; if $C &gt; 2$, this is called multiclass classification. . We will first consider binary classification problem in which the target classes $t$ will be generated from 2 class distributions: blue ($t=1$) and red ($t=0$). Samples from both classes are sampled from their respective distributions. These samples are plotted in the figure below. . Note that $X$ is a $N times 2$ matrix of individual input samples $ mathbf{x}_i$, and that $ mathbf{t}$ is a corresponding $N times 1$ vector of target values $t_i$. . Logistic Regression . With logistic regression the goal is to predict the target class $t$ from the input values $x$. The network is defined as having an input $ mathbf{x} = [x_1, x_2]$ which gets transformed by the weights $ mathbf{w} = [w_1, w_2]$ to generate the probability that sample $ mathbf{x}$ belongs to class $t=1$$ This probability $P(t=1 mid mathbf{x}, mathbf{w})$ is represented by the output $y$ of the network computed as $y = sigma( mathbf{x} * mathbf{w}^T)$. $ sigma$ is the logistic function and is defined as: . σ(z)=11+e−z sigma(z) = frac{1}{1+e^{-z}}σ(z)=1+e−z1​ . which squashes the predictions to be between 0 and 1 such that: . P(t=1∣x,w)=y(σ(z))P(t=0∣x,w)=1−P(t=1∣x,w)=1−y(σ(z)) begin{aligned} P(t=1| mathbf{x}, mathbf{w}) &amp;= y( sigma(z))P(t=0 mid mathbf{x}, mathbf{w}) &amp;= 1 - P(t=1 mid mathbf{x}, mathbf{w}) = 1 - y( sigma(z)) end{aligned}P(t=1∣x,w)​=y(σ(z))P(t=0∣x,w)=1−P(t=1∣x,w)=1−y(σ(z))​ . The loss function for logistic function is called crossentropy and defined as: . LCE(y,t)={−log⁡yif t=1−log⁡(1−y)if t=0 mathcal{L}_{CE}(y,t)= begin{cases} - log y quad text{if } t = 1 - log (1-y) quad text{if } t = 0 end{cases}LCE​(y,t)={−logyif t=1−log(1−y)if t=0​ . The crossentropy can be written in other form as: . LCE(y,t)=−tlog⁡y−(1−t)log⁡(1−y) mathcal{L}_{CE}(y,t)= -t log y -(1-t) log(1-y)LCE​(y,t)=−tlogy−(1−t)log(1−y) . When we combine the logistic activation function with cross-entropy loss, we get logistic regression: . z=wTx+b y=σ(z) LCE(y,t)=−tlog⁡y−(1−t)log⁡(1−y) begin{aligned} z &amp; = mathbf{w^Tx + b} y &amp; = sigma(z) mathcal{L}_{CE}(y,t) &amp;= -t log y -(1-t) log(1-y) end{aligned}z y LCE​(y,t)​=wTx+b=σ(z)=−tlogy−(1−t)log(1−y)​ . The cost function with respect to the model parameters θ thetaθ (i.e. the weights and bias) is therefore: . εθ=1N∑i=1NLCE(y,t) =1N∑i=1N(−t(i)log⁡y(i)−(1−t(i))log⁡(1−y(i))) begin{aligned} varepsilon_{ theta} &amp; = frac{1}{N} sum_{i=1}^N mathcal{L}_{CE}(y,t) &amp; = frac{1}{N} sum_{i=1}^N left(-t^{(i)} log y^{(i)} -(1-t^{(i)}) log(1-y^{(i)}) right) end{aligned}εθ​ ​=N1​i=1∑N​LCE​(y,t)=N1​i=1∑N​(−t(i)logy(i)−(1−t(i))log(1−y(i)))​ . which can be implemented in python as follows: . # Define the cost function def cost(x, w, t): N, D = np.shape(x) z = z_value(x,w) y = y_value(z) result = np.sum(np.multiply(t, np.log(y)) + np.multiply((1-t), np.log(1-y)))/float(N) return -result . Gradient Descent for Logistic Function . To derive the gradient descent updates, we’ll need the partial derivatives of the cost function. We’ll do this by applying the Chain Rule twice: first to compute ∂LCE∂z frac{ partial mathcal{L}_{CE}}{ partial z}∂z∂LCE​​ and then again to compute $ frac{ partial mathcal{L}_{CE}}{ partial w_j}$ But first, let’s find $ frac{ partial y}{ partial z}$. . ∂y∂z=e−z(1+e−z)2=y(1−y) frac{ partial y}{ partial z} = frac{e^{-z}}{(1 + e^{-z})^2}= y(1-y)∂z∂y​=(1+e−z)2e−z​=y(1−y) . Now for the Chain Rule: . ∂LCE∂z=∂LCE∂y∂y∂z =(−ty+1−t1−y)y(1−y) =y−t begin{aligned} frac{ partial mathcal{L}_{CE}}{ partial z} &amp; = frac{ partial mathcal{L}_{CE}}{ partial y} frac{ partial y}{ partial z} &amp; = left( frac{-t}{y} + frac{1-t}{1-y} right) y(1-y) &amp;= y - t end{aligned}∂z∂LCE​​  ​=∂y∂LCE​​∂z∂y​=(y−t​+1−y1−t​)y(1−y)=y−t​ . Similary: . ∂LCE∂wj=∂LCE∂z∂z∂wj =∂LCE∂zxj =(y−t)xj begin{aligned} frac{ partial mathcal{L}_{CE}}{ partial w_j} &amp; = frac{ partial mathcal{L}_{CE}}{ partial z} frac{ partial z}{ partial w_j} &amp; = frac{ partial mathcal{L}_{CE}}{ partial z} x_j &amp;= (y - t)x_j end{aligned}∂wj​∂LCE​​  ​=∂z∂LCE​​∂wj​∂z​=∂z∂LCE​​xj​=(y−t)xj​​ . We can also obtain ∂LCE∂b frac{ partial mathcal{L}_{CE}}{ partial b}∂b∂LCE​​ as follows: . ∂LCE∂b=∂LCE∂z∂z∂b=(y−t) begin{aligned} frac{ partial mathcal{L}_{CE}}{ partial b} &amp;= frac{ partial mathcal{L}_{CE}}{ partial z} frac{ partial z}{ partial b} &amp; = (y-t) end{aligned}∂b∂LCE​​​=∂z∂LCE​​∂b∂z​=(y−t)​ . The gradient descent algorithm works by taking the derivative of the cost function εθ varepsilon_{ theta}εθ​ with respect to the parameters, and updates the parameters in the direction of the negative gradient.The parameter w mathbf{w}w is iteratively updated by taking steps proportional to the negative of the gradient: . wk+1=wk−α∂ε∂w mathbf{w_{k+1}} = mathbf{ w_k }- alpha frac{ partial mathbf{ varepsilon}}{ partial mathbf{w}}wk+1​=wk​−α∂w∂ε​ . where: . ∂LCE∂ε=∂ε∂LCE⋅∂LCE∂w=1NxT(y−t) begin{aligned} frac{ partial mathcal{L}_{CE}}{ partial varepsilon} &amp;= frac{ partial varepsilon }{ partial mathcal{L}_{CE}} cdot frac{ partial mathcal{L}_{CE}}{ partial mathbf{w}} &amp;= frac{1}{N} mathbf{x^T(y - t)} end{aligned}∂ε∂LCE​​​=∂LCE​∂ε​⋅∂w∂LCE​​=N1​xT(y−t)​ . which can be implemented in python as follows: . #gradient def gradient(x, w, t): z = z_value(x,w) y = y_value(z) error = y-t dw = x.T.dot(error) return dw.T def solve_gradient(x, t, alpha=0.1, tolerance=1e-2): N, D = np.shape(x) w = np.zeros([D]) iterations = 1 w_cost = [(w, cost(x,w, t))] while True: dw = gradient(x, w, t) w_k = w - alpha * dw w_cost.append((w, cost(x, w, t))) # Stopping Condition if np.sum(abs(w_k - w)) &lt; tolerance: print (&quot;Converged.&quot;) break if iterations % 100 == 0: print (&quot;Iteration: %d - cost: %.4f&quot; %(iterations, cost(x, w, t))) iterations += 1 w = w_k return w . Let us apply the above concept in the following example. Consider the case we want to predict whether a student with a specific pass mark can be admitted or not. . # load dataset admission = pd.read_csv(&#39;data/admission.csv&#39;, names = [&quot;grade1&quot;, &quot;grade2&quot;, &quot;remark&quot;]) admission.head() . The data-preprosessing is done using the following python code: . features = [&#39;grade1&#39;, &#39;grade2&#39;] target = [&#39;remark&#39;] targetVal = admission[target] featureVal = admission[features] y = np.array(targetVal) # Standardize the features for i in range(2): featureVal.iloc[:,i] = (featureVal.iloc[:,i] / featureVal.iloc[:,i].max()) # Add bias term to feature data b = np.ones((featureVal.shape[0], 1)) X = np.hstack((b, featureVal)) # randomly separate data into training and test data from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=50) . We use the solve_gradient function defined before to find the parameter for logistic regression. . w_g = solve_gradient(X_train, y_train, alpha=0.05, tolerance = 1e-9) . Now that you learned the parameters of the model, you can use the model to predict whether a particular student will be admitted. . Let define the prediction function that only 1 or 0 depending on the predicted class. . def predict(x,w): z = z_value(x,w) y = y_value(z) return np.around(y) . To find the accuracy of the model: . p_test = predict(X_test, w_g) p_train = predict(X_train, w_g) print (&#39;Test Accuracy: %f&#39; % ((y_test[np.where(p_test == y_test)].size / float(y_test.size)) * 100.0)) print (&#39;Train Accuracy: %f&#39; % ((y_train[np.where(p_train == y_train)].size / float(y_train.size)) * 100.0)) . After running the above codes, we found that our model performs a training accuracy of 91.2591.2591.25 and a test accuracy of 858585 percents. . Multiclass classification . So far, we’ve talked about binary classification, but most classification problems involve more than two categories. Fortunately, this doesn’t require any new ideas: everything pretty much works by analogy with the binary case. The first question is how to represent the targets. We could describe them as integers, but it’s convenient to use indicator vectors or a one-of-K encoding. . Since there are $K$ outputs and DDD inputs, the linear function requires $K times D$ matrix as well as $K$ dimensional bias vector. We use softmax function which is the multivariate generalization given as: . yk=softmax(z1…zk)=ezk∑kezky_k = softmax(z_1 ldots z_k) = frac{e^{z_k}}{ sum_k e^{z_k}}yk​=softmax(z1​…zk​)=∑k​ezk​ezk​​ . and can be implemented in python as . def softmax(x,w): z = z_value(x,w) e_x = np.exp(x - np.max(x)) y = np.exp(z - max(z)) / np.sum(np.exp(z - max(z))) return y.reshape(len(y), 1) . Finally, the loss function (cross-entropy) for multiple-output case can be generalized as follows: . LCE(y,t)=−∑k=1Ktklog⁡yk=−tTlog⁡y begin{aligned} mathcal{L}_{CE}(y,t) &amp;= - sum_{k=1}^K t_k log y_k &amp;= - mathbf{t^T} log mathbf{y} end{aligned}LCE​(y,t)​=−k=1∑K​tk​logyk​=−tTlogy​ . Combining these things together, we get multiclass logistic regression: . z=wx+by=softmax(z)LCE(y,t)=−tTlog⁡y begin{aligned} mathbf{z} &amp;= mathbf{wx + b} mathbf{y} &amp;= softmax( mathbf{z}) mathcal{L}_{CE}(y,t) &amp;=- mathbf{t^T} log mathbf{y} end{aligned}zyLCE​(y,t)​=wx+b=softmax(z)=−tTlogy​ . Gradient Descent for Multiclass Logistic Regression for Multiclass logistic regression: . Let consider the derivative with respect to the loss: . ∂LCE∂wkj=∂∂wkj(−∑ltllog⁡(yl))=−∑ltlyl∂yl∂wkj begin{aligned} frac{ partial { mathcal L}_ text{CE}}{ partial w_{kj}} &amp;= frac{ partial }{ partial w_{kj}} left(- sum_l t_l log(y_l) right) &amp;= - sum_l frac{t_l}{y_l} frac{ partial y_l}{ partial w_{kj}} end{aligned}∂wkj​∂LCE​​​=∂wkj​∂​(−l∑​tl​log(yl​))=−l∑​yl​tl​​∂wkj​∂yl​​​ . Normally in calculus we have the rule: . ∂yl∂wkj=∑m∂yl∂zm∂zm∂wkj begin{aligned} frac{ partial y_l}{ partial w_{kj}} &amp;= sum_m frac{ partial y_l}{ partial z_m} frac{ partial z_m}{ partial w_{kj}} end{aligned}∂wkj​∂yl​​​=m∑​∂zm​∂yl​​∂wkj​∂zm​​​ . But wkjw_{kj}wkj​ is independent of zmz_mzm​ for m≠km ne km​=k, so . ∂yl∂wkj=∂yl∂zk∂zk∂wkj begin{aligned} frac{ partial y_l}{ partial w_{kj}} &amp;= frac{ partial y_l}{ partial z_k} frac{ partial z_k}{ partial w_{kj}} end{aligned}∂wkj​∂yl​​​=∂zk​∂yl​​∂wkj​∂zk​​​ . AND . ∂zk∂wkj=xj frac{ partial z_k}{ partial w_{kj}} = x_j∂wkj​∂zk​​=xj​ . Thus . ∂LCE∂wkj=−∑ltlyl∂yl∂zk∂zk∂wkj=−∑ltlyl∂yl∂zkxj=xj(−∑ltlyl∂yl∂zk)=xj∂LCE∂zk begin{aligned} frac{ partial { mathcal L}_ text{CE}}{ partial w_{kj}} &amp;= - sum_l frac{t_l}{y_l} frac{ partial y_l}{ partial z_k} frac{ partial z_k}{ partial w_{kj}} &amp;= - sum_l frac{t_l}{y_l} frac{ partial y_l}{ partial z_k} x_j &amp;= x_j (- sum_l frac{t_l}{y_l} frac{ partial y_l}{ partial z_k}) &amp;= x_j frac{ partial { mathcal L}_ text{CE}}{ partial z_k} end{aligned}∂wkj​∂LCE​​​=−l∑​yl​tl​​∂zk​∂yl​​∂wkj​∂zk​​=−l∑​yl​tl​​∂zk​∂yl​​xj​=xj​(−l∑​yl​tl​​∂zk​∂yl​​)=xj​∂zk​∂LCE​​​ . Now consider derivative with respect to $z_k$ we can show (onboard) that. . ∂yl∂zk=yk(Ik,l−yl) frac{ partial y_l}{ partial z_k} = y_k (I_{k,l} - y_l)∂zk​∂yl​​=yk​(Ik,l​−yl​) . Where $I_{k,l} = 1$ if $k=l$ and $0$ otherwise. . Therefore . ∂LCE∂zk=−∑ltlyl(yk(Ik,l−yl))=−tkykyk(1−yk)−∑l≠ktlyl(−ykyl)=−tk(1−yk)+∑l≠ktlyk=−tk+tkyk+∑l≠ktlyk=−tk+∑ltlyk=−tk+yk∑ltl=−tk+yk=yk−tk begin{aligned} frac{ partial { mathcal L}_ text{CE}}{ partial z_k} &amp;= - sum_l frac{t_l}{y_l} (y_k (I_{k,l} - y_l)) &amp;=- frac{t_k}{y_k} y_k(1 - y_k) - sum_{l ne k} frac{t_l}{y_l} (-y_k y_l) &amp;= - t_k(1 - y_k) + sum_{l ne k} t_l y_k &amp;= -t_k + t_k y_k + sum_{l ne k} t_l y_k &amp;= -t_k + sum_{l} t_l y_k &amp;= -t_k + y_k sum_{l} t_l &amp;= -t_k + y_k &amp;= y_k - t_k end{aligned}∂zk​∂LCE​​​=−l∑​yl​tl​​(yk​(Ik,l​−yl​))=−yk​tk​​yk​(1−yk​)−l​=k∑​yl​tl​​(−yk​yl​)=−tk​(1−yk​)+l​=k∑​tl​yk​=−tk​+tk​yk​+l​=k∑​tl​yk​=−tk​+l∑​tl​yk​=−tk​+yk​l∑​tl​=−tk​+yk​=yk​−tk​​ . Putting it all together . ∂LCE∂wkj=xj(yk−tk) begin{aligned} frac{ partial { mathcal L}_ text{CE}}{ partial w_{kj}} &amp;= x_j (y_k - t_k) end{aligned}∂wkj​∂LCE​​​=xj​(yk​−tk​)​ . In vectorization form it become: . ∂LCE∂W=(y−t)xT begin{aligned} frac{ partial mathcal {L}_{CE}}{ partial { mathbf W}} = ( mathbf{y} - mathbf{t}) mathbf{x}^T end{aligned}∂W∂LCE​​=(y−t)xT​ . Cross-entropy cost function . The cross entropy cost function for multiclass classification is given with respect to the model parameters θ thetaθ (i.e. the weights and bias) is therefore: . εθ=1N∑i=1NLCE(y,t)=−1N∑i=1N∑k=1Ktklog⁡yk begin{aligned} varepsilon_{ theta} &amp; = frac{1}{N} sum_{i=1}^N mathcal{L}_{CE}(y,t) &amp; = frac{-1}{N} sum_{i=1}^N sum_{k=1}^K t_k log y_k end{aligned}εθ​​=N1​i=1∑N​LCE​(y,t)=N−1​i=1∑N​k=1∑K​tk​logyk​​ . The gradient descent algorithm will be: wk+1=wk−α∂ε∂w mathbf{w_{k+1}} = mathbf{ w_k }- alpha frac{ partial mathbf{ varepsilon}}{ partial mathbf{w}}wk+1​=wk​−α∂w∂ε​ . where: . ∂LCE∂ε=∂ε∂LCE⋅∂LCE∂w=1NxT(y−t) begin{aligned} frac{ partial mathcal{L}_{CE}}{ partial varepsilon} &amp;= frac{ partial varepsilon }{ partial mathcal{L}_{CE}} cdot frac{ partial mathcal{L}_{CE}}{ partial mathbf{w}} &amp;= frac{1}{N} mathbf{x^T(y - t)} end{aligned}∂ε∂LCE​​​=∂LCE​∂ε​⋅∂w∂LCE​​=N1​xT(y−t)​ . References . CSC321 Intro to Neural Networks and Machine Learning | Supervised and Unsupervised Machine Learning Algorithms | .",
            "url": "/sambaiga/machine%20learning/2017/07/02/ml-classification.html",
            "relUrl": "/machine%20learning/2017/07/02/ml-classification.html",
            "date": " • Jul 2, 2017"
        }
        
    
  
    
        ,"post7": {
            "title": "Learning HMM parameters for Continous Density Models",
            "content": "Introduction . In the previous post, we considered a scenario where observation sequences YYY are discrete symbols. However, for many practical problems, the observation symbols are continuous vectors. As a result, the continuous probability density function (pdf) is used to model the space of the observation signal associated with each state. The most commonly used emission distribution is gaussian distribution and the gaussian mixture models. . Gaussian Distribution and the Gaussian Mixture Models . It is popular to represent the randomness of continuous-valued using the multivariate Gaussian distribution. A vector-valued random variable x mathbf{x}x is said to have a multivariate normal (or Gaussian) distribution with mean μ=E[x] mu= mathop{ mathbf{E[x]}}μ=E[x] and covariance matrix Σ=cov[x] Sigma= mathbf{cov[x]}Σ=cov[x] if: P(x;μ,Σ)=N(x∣μ,Σ)=1(2π)D/2∣Σ∣12exp⁡(−12[x−μ]Σ−1[x−μ]T)P( mathbf{x}; mu, Sigma) = mathcal{N( mathbf{x} mid mu, Sigma)}= frac{1}{(2 pi)^{D/2} | Sigma|^ frac{1}{2}} quad exp Big(- frac{1}{2}[ mathbf{x} - mu] Sigma^{-1}[ mathbf{x} - mu]^ mathsf{T} Big)P(x;μ,Σ)=N(x∣μ,Σ)=(2π)D/2∣Σ∣21​1​exp(−21​[x−μ]Σ−1[x−μ]T) where DDD is the dimensionality of x mathbf{x}x. The μ muμ represents the location where samples are most likely to be generated, and the Σ SigmaΣ indicates the level to which two variables vary together. . However, a single Gaussian distribution is insufficient to represent the state-dependent observation space for an HMM state st=is_t=ist​=i. This is because there are large amounts of training data collected from various appliance instances with different modes, distortions, background noises, etc which are used to train the parameters of individual HMM states. In this case, a Gaussian mixture model (GMM) is adopted to represent the state-dependent observation space. . A mixture model is a probabilistic model for density estimation using a mixture distribution and can be regarded as a type of unsupervised learning or clustering. They provide a method of describing more complex probability distributions by combining several probability distributions. The following equation gives a multivariate Gaussian mixture distribution: P(x)=∑k=1KωkN(x∣μk,Σk)P( mathbf{x}) = displaystyle sum_{k=1}^{K} omega_k mathcal{N( mathbf{x} mid mu_k, Sigma_k)}P(x)=k=1∑K​ωk​N(x∣μk​,Σk​) The parameters ωk omega_kωk​ are called mixing coefficients, which must fulfill ∑k=1Kωk=1 displaystyle sum_{k=1}^{K} omega_k =1k=1∑K​ωk​=1 and given N(x∣μk,Σk)≥0 mathcal{N( mathbf{x} mid mu_k, Sigma_k)} geq 0N(x∣μk​,Σk​)≥0 and P(x)≥0P( mathbf{x}) geq 0P(x)≥0 we also have that 0≤ωk≥10 leq omega_k geq 10≤ωk​≥1. Each Gaussian density N(x∣μk,Σk) mathcal{N( mathbf{x} mid mu_k, Sigma_k)}N(x∣μk​,Σk​) is called a component of the mixture and has its own mean μk mu_kμk​ and covariance Σk Sigma_kΣk​. . HMM with Gaussian emission distribution . If the observations are continuous, it is common for the emission probabilities to be a conditional Gaussian such that: P(yt∣st=i)=N(yt∣μi,Σi)P( mathbb{y_t} mid s_t =i) = mathcal{N( mathbf{y_t} mid mu_i, Sigma_i)}P(yt​∣st​=i)=N(yt​∣μi​,Σi​) where μi mu_iμi​ and Σi Sigma_iΣi​ are mean vector and covariance matrix associated with state iii. The re-estimation formula for the mean vector and covariance matrix of a state gausian pdf can be derived as: μ^i=∑t=1Tγt(i)y(t)∑t=1Tγt(i)Σ^i=∑t=1Tγt(i)[y(t)−μ^i]⋅[y(t)−μ^i]T∑t=1Tγt(i) begin{aligned} hat{ mu}_i &amp; = frac{ displaystyle sum_{t=1}^{T} gamma_t(i) mathbb{y(t)}}{ displaystyle sum_{t=1}^{T} gamma _t(i)} hat{ Sigma}_i &amp; = frac{ displaystyle sum_{t=1}^{T} gamma_t(i) [ mathbf{y(t)}- hat{ mu}_i] cdot[ mathbf{y(t)}- hat{ mu}_i]^T}{ displaystyle sum_{t=1}^{T} gamma_t(i)} end{aligned}μ^​i​Σ^i​​=t=1∑T​γt​(i)t=1∑T​γt​(i)y(t)​=t=1∑T​γt​(i)t=1∑T​γt​(i)[y(t)−μ^​i​]⋅[y(t)−μ^​i​]T​​ . HMMs with Gaussian Mixture Model . In HMMs with Gaussian mixture pdf, the emission probabilities is given by P(yt∣st=i)=∑k=1Mω_ikN(yt∣μik,Σik)P( mathbb{y_t} mid s_t =i) = displaystyle sum_{k=1}^{M} omega _{ik} mathcal{N( mathbb{y_t} mid mu_{ik}, Sigma_{ik})}P(yt​∣st​=i)=k=1∑M​ω_ikN(yt​∣μik​,Σik​) where ωik omega_{ik}ωik​ is the prior probability of the kthk^{th}kth component of the mixture. The posterior probability of state st=is_t=ist​=i at time ttt and state st+1=js_{t+1}=jst+1​=j at time t+1t+1t+1 given the model λ lambdaλ and the observation sequence YYY is γt(i,j)=P(st=i,st+1=j∣Y,λ)=αt(i)aij[∑k=1MωikN(yt∣μik,Σik)]βt+1(j)∑i=1NαT(i) begin{aligned} gamma_t(i,j)&amp; =P(s_t=i, s_{t+1}=j mid Y, lambda) &amp; = frac{ alpha_t(i)a_{ij} Big[ displaystyle sum_{k=1}^{M} omega_{ik} mathcal{N( mathbf{y_t} mid mu_{ik}, Sigma_{ik})} Big] beta_{t+1}(j)}{ displaystyle sum_{i=1}^{N} alpha_T(i)} end{aligned}γt​(i,j)​=P(st​=i,st+1​=j∣Y,λ)=i=1∑N​αT​(i)αt​(i)aij​[k=1∑M​ωik​N(yt​∣μik​,Σik​)]βt+1​(j)​​ . and the posterior probability of state st=is_t=ist​=i at time ttt given the model λ lambdaλ and observation YYY is γt(i)=αt(i)βt(i)∑i=1NαT(i) gamma_t(i) = frac{ alpha_t(i) beta_t(i)}{ displaystyle sum_{i=1}^{N} alpha _T(i)}γt​(i)=i=1∑N​αT​(i)αt​(i)βt​(i)​ Let define the joint posterior probability of the state sis_isi​ and the kthk^{th}kth gaussian component pdf of state iii at time ttt . ξ(i,k)=P(St=si,m(t)=k∣Y,λ)=∑j=1Nαt(j)aijωikN(yt∣μik,Σik)βt+1(j)∑i=1NαT(i) begin{aligned} xi(i,k) &amp;= P(S_t=s_i, m(t)=k mid Y, lambda) &amp;= frac{ displaystyle sum_{j=1}^{N} alpha_t(j) a_{ij} omega_{ik} mathcal{N( mathbf{y_t} mid mu_{ik}, Sigma_{ik})} beta_{t+1}(j)}{ displaystyle sum_{i=1}^{N} alpha _T(i)} end{aligned}ξ(i,k)​=P(St​=si​,m(t)=k∣Y,λ)=i=1∑N​αT​(i)j=1∑N​αt​(j)aij​ωik​N(yt​∣μik​,Σik​)βt+1​(j)​​ . The re-estimation formula for the mixture coefficients, the mean vectors and the covariance matrices of the state mixture gaussian pdf as . ω^ik=∑t=1Tξt(i,k)∑_t=0Tγt(i)μ^ik=∑ t=1Tξ t(i,k)yt∑t=1Tξt(i,k)Σ^ik=∑t=1Tξt(i,k)[yt−μ^ik]⋅[yt−μ^ik]T∑t=1Tξt(i,k) begin{aligned} hat{ omega}_{ik} &amp;= frac{ displaystyle sum_{t=1}^{T} xi_t(i,k)}{ displaystyle sum _{t=0}^{T} gamma_t(i)} hat{ mu}_{ik} &amp;= frac{ displaystyle sum _{t=1}^{T} xi _t(i,k) mathbf{y_t}}{ displaystyle sum_{t=1}^{T} xi_t(i,k)} hat{ Sigma}_{ik}&amp;= frac{ displaystyle sum_{t=1}^{T} xi_t(i,k)[ mathbf{y_t}- hat{ mu}_{ik}] cdot[ mathbf{y_t}- hat{ mu}_{ik}]^T}{ displaystyle sum_{t=1}^{T} xi_t(i,k)} end{aligned}ω^ik​μ^​ik​Σ^ik​​=∑_t=0Tγt​(i)t=1∑T​ξt​(i,k)​=t=1∑T​ξt​(i,k)∑ t=1T​ξ t​(i,k)yt​​=t=1∑T​ξt​(i,k)t=1∑T​ξt​(i,k)[yt​−μ^​ik​]⋅[yt​−μ^​ik​]T​​ . Limitation of Baum–Welch algorithm . When applying the Baum–Welch algorithm in real data, we need to consider some heuristics in the ML EM algorithm. . How to provide initial parameter values. This is always an important question, and it is usually resolved by using a simple algorithm (e.g., K-means clustering or random initialization). | How to avoid instability in the parameter estimation (especially covariance parameter estimation) due to data sparseness. For example, some mixture components or hidden states cannot have sufficient data assigned in the Viterbi or forward-backward algorithm. This can be heuristically avoided by setting a threshold to update these parameters or setting minimum threshold values for covariance parameters. | Bayesian approaches can solve the above two problems. . References . Saeed V. Vaseghi, Advanced Digital Signal Processing, and Noise Reduction. John Wiley &amp; Sons, 2008. | Kevin P. Murphy, Machine Learning: A Probabilistic Perspective. The MIT Press Cambridge, Massachusetts, 2012. |",
            "url": "/sambaiga/machine%20learning/2017/06/06/hmm-gausian.html",
            "relUrl": "/machine%20learning/2017/06/06/hmm-gausian.html",
            "date": " • Jun 6, 2017"
        }
        
    
  
    
        ,"post8": {
            "title": "Introduction to Machine Learning",
            "content": "Introduction . Machine learning is a set of algorithms that automatically detect patterns in data and use the uncovered pattern to make inferences or predictions. It is a subfield of artificial intelligence that aims to enable computers to learn on their own. Any machine learning algorithms involve the necessary three steps: first, you identify a pattern from data, build (train) model that best explains the pattern and the world (unseen data), and lastly, use the model to predict or make an inference. Model training (building) can be seen as a learning process where the model is exposed to new, unfamiliar data step by step. . Machine learning is an exciting and fast-moving field of computer science with many new applications. Applications where machine learning algorithms are regularly deployed includes: . Computer vision: Object Classification in Photograph, image captioning. | Speech recognition, Automatic Machine Translation. | Detecting anomalies (e.g. Security, credit card fraud) | Speech recognition. | Communication systemsref | Robots learning complex behaviors | Recommendations services like in Amazo or Netflix where intelligent machine learning algorithms analyze your activity and compare it to the millions of other users to determine what you might like to buy or binge watch nextref. | . Machine learning algorithms that learn to recognize what they see have been the heart of Apple, Google, Amazon, Facebook, Netflix, Microsoft, etc. . Why Machine learning . For many problems such as recognizing people and objects and understanding human speech, it’s difficult to program the correct behavior by hand. However, with machine learning, these tasks are easier. Other reasons we might want to use machine learning to solve a given problem: . A system might need to adapt to a changing environment. For instance, spammers are always trying to figure out ways to trick our e-mail spam classifiers, so the classification algorithms will need to adapt continually. | A learning algorithm might be able to perform better than its human programmers. Learning algorithms have become world champions at a variety of games, from checkers to chess to Go. This would be impossible if the programs were only doing what they were explicitly told to do. | We may want an algorithm to behave autonomously for privacy or fairness reasons, such as with ranking search results or targeting ads. | . Types of Machine Learning . Machine learning is usually divided into three major types: Supervised Learning, Unsupervised Learning and . Supervised Learning: Supervised learning is where you have input variables x and an output variable y, and use an algorithm to learn the mapping function from the input to the outputref. For instance, if we’re trying to train a machine-learning algorithm to distinguish cars and trucks, we would collect car and truck images and label each one as a car or a truck. Supervised learning problems can be further grouped into regression and classification problems. . A regression problem: is when the output variable is a real value, such as “dollars” or “weight” e.g Linear regression and Random forest. | Classification: A classification problem is when the output variable is a category, such as “red” or “blue” or “disease” and “no disease”, e.g. Support vector machines, random forest, and logistic regression. Some famous examples of supervised machine learning algorithms are: | . Unsupervised Learning : Unsupervised learning is where you only have input data (X) and no corresponding output variables. We just have a bunch of data and want to look for patterns in the data. For instance, maybe we have lots of examples of patients with autism and want to identify different subtypes of the condition. The most important types of unsupervised learning include: . Distribution modeling where one has an unlabeled dataset (such as a collection of images or sentences), and the goal is to learn a probability distribution that matches the dataset as closely as possible. | Clustering where the aim is to discover the inherent groupings in the data, such as grouping customers by purchasing behavior. | . Reinforcement Learning: is learning best actions based on reward or punishment. It involves learning what actions to take in a given situation, based on rewards and penalties. For example, a robot takes a big step forward, then falls. The next time, it takes a smaller stage and is able to hold its balance. The robot tries variations like this many times; eventually, it learns the right size of steps to take and walks steadily. It has succeeded. . There are three basic concepts in reinforcement learning: state, action, and reward. The state describes the current situation. Action is what an agent can do in each state. When a robot takes action in a state, it receives a reward, feedback from the environment. A reward can be positive or negative (penalties). . Typical ML task: Linear Regression . In regression, we are interested in predicting a scalar-valued target, such as the price of a stock. By linear, we mean that the target must be predicted as a linear function of the inputs. This is a kind of supervised learning algorithm; recall that, in supervised learning, we have a collection of training examples labeled with the correct outputs. Example applications of linear regression include weather forecasting, house pricing prediction, student performance (GPA) prediction, just to mention a few. . Linear Regression: Formulating a learning problem . To formulate a learning problem mathematically, we need to define two things: a model (hypothesis)** and a *loss function. After defining model and loss function, we solve an optimization problem with the aim to find the model parameters that best fit the data. . Model (Hypothesis): It is the set of allowable hypotheses or functions that compute predictions from the inputs. In the case of linear regression, the model simply consists of linear functions given by: . y=∑jwjxj+by = sum_j w_jx_j + by=j∑​wj​xj​+b . where www is the weights, and bbb is an intercept term, which we’ll call the bias. These two terms are called model parameters denoted as θ thetaθ. . Loss function: It defines how well the model fit the data and thus show how far off the prediction yyy is from the target ttt and given as: . L(y,t)=12(y−t)2 mathcal{L(y,t)} = frac{1}{2}(y - t)^2L(y,t)=21​(y−t)2 . Since the loss function show how far off the prediction is from the target for one data point. We also need to define a cost function. The cost function is simply the loss, averaged over all the training examples. . J(w1…wD,b)=1N∑i=1NL(y(i),t(i))=12N∑i=1N(y(i)−t(i))2=12N∑i=1N(∑jwjxj(i)+b−t(i)) begin{aligned} J (w_1 ldots w_D,b) &amp; = frac{1}{N} sum_{i=1}^N mathcal{L}(y^{(i)},t^{(i)}) &amp; = frac{1}{2N} sum_{i=1}^N (y^{(i)} - t^{(i)})^2 &amp;= frac{1}{2N} sum_{i=1}^N left( sum_j w_jx_j^{(i)} + b -t^{(i)} right) end{aligned}J(w1​…wD​,b)​=N1​i=1∑N​L(y(i),t(i))=2N1​i=1∑N​(y(i)−t(i))2=2N1​i=1∑N​(j∑​wj​xj(i)​+b−t(i))​ . In vectorized form: . J=12N∥y−t∥2=12N(y−t)T(y−t)wherey=wTx mathbf{J} = frac{1}{2N} lVert mathbf{y-t} lVert^2 = frac{1}{2N} mathbf{(y - t)^T(y-t)} quad text{where} quad mathbf{y = w^Tx}J=2N1​∥y−t∥2=2N1​(y−t)T(y−t)wherey=wTx . The python implementation of the cost function (vectorized) is shown below. . def loss(x, w, t): N, D = np.shape(x) y = np.matmul(x,w.T) loss = (y - t) return loss . def cost(x,w, t): &#39;&#39;&#39; Evaluate the cost function in a vectorized manner for inputs `x` and targets `t`, at weights `w1`, `w2` and `b`. N, D = np.shape(x) return (loss(x, w,t) **2).sum() / (2.0 * N) . Combine our model and loss function, we get an optimization problem, where we are trying to minimize a cost function concerning the model parameters θ thetaθ (i.e. the weights and bias). . Solving the optimization problem . We now want to find the choice of model parameters θw1…wD,b theta _{w_1 ldots w_D,b}θw1​…wD​,b​ that minimizes J(w1…wD,b)J (w_1 ldots w_D,b)J(w1​…wD​,b) as given in the cost function above.There are two methods that we can use: direct solution and gradient descent. . Direct Solution . One way to compute the minimum of a function is to set the partial derivatives to zero. For simplicity, let’s assume the model doesn’t have a bias term, as shown in the equation below. . Jθ=12N∑i=1N(∑jwjxj(i)−t(i))J_ theta = frac{1}{2N} sum_{i=1}^N left( sum_j w_jx_j^{(i)} -t^{(i)} right)Jθ​=2N1​i=1∑N​(j∑​wj​xj(i)​−t(i)) . In vectorized form . J=12N∥y−t∥212N(y−t)T(y−t)wherey=wx mathbf{J} = frac{1}{2N} lVert mathbf{y-t} rVert ^2 frac{1}{2N} mathbf{(y - t)^T(y-t)} quad text{where} quad mathbf{y = wx}J=2N1​∥y−t∥22N1​(y−t)T(y−t)wherey=wx . For matrix differentiation we need the following results: . ∂Ax∂x=AT∂(xTAx)∂x=2ATx begin{aligned} frac{ partial mathbf{Ax}}{ partial mathbf{x}} &amp; = mathbf{A}^T frac{ partial ( mathbf{x}^T mathbf{Ax})}{ partial mathbf{x}} &amp; = 2 mathbf{A}^T mathbf{x} end{aligned}∂x∂Ax​​=AT∂x∂(xTAx)​=2ATx​ . Setting the partial derivatives of cost function in vectorized form to zero we obtain: . ∂J∂w=12N∂(wTxTxw−2tTwx+tTt)∂w=12N(2xTxw−2xTt)w=(xTx)−1xTt begin{aligned} frac{ partial mathbf{J}}{ partial mathbf{w}} &amp; = frac{1}{2N} frac{ partial left( mathbf{w^Tx^Tx w} -2 mathbf{t^Twx} + mathbf{t^Tt} right)}{ partial mathbf{w}} &amp;= frac{1}{2N} left(2 mathbf{x}^T mathbf{xw} -2 mathbf{x}^T mathbf{t} right) mathbf{w} &amp;= ( mathbf{x^Tx})^{-1} mathbf{x^Tt} end{aligned}∂w∂J​w​=2N1​∂w∂(wTxTxw−2tTwx+tTt)​=2N1​(2xTxw−2xTt)=(xTx)−1xTt​ . In python, this result can be implemented as follows: . def direct method(x, t): &#39;&#39;&#39; Solve linear regression exactly. (fully vectorized) Given `x` - NxD matrix of inputs `t` - target outputs Returns the optimal weights as a D-dimensional vector &#39;&#39;&#39; N, D = np.shape(x) A = np.matmul(x.T, x) c = np.dot(x.T, t) return np.matmul(linalg.inv(A), c) . Gradient Descent . The optimization algorithm commonly used to train machine learning is the gradient descent algorithm. It works by taking the derivative of the cost function JJJ with respect to the parameters at a specific position on this cost function and updates the parameters in the direction of the negative gradient. The entries of the gradient vector are simply the partial derivatives with respect to each of the variables: . ∂J∂w=(∂J∂w1⋮∂J∂wD) frac{ partial mathbf{J}}{ partial mathbf{w}} = begin{pmatrix} frac{ partial J}{ partial w_1} vdots frac{ partial J}{ partial w_D} end{pmatrix}∂w∂J​=⎝⎜⎜⎛​∂w1​∂J​⋮∂wD​∂J​​⎠⎟⎟⎞​ . The parameter w mathbf{w}w is iteratively updated by taking steps proportional to the negative of the gradient: . wt+1=wt−α∂J∂w=wt−αNxT(y−t) mathbf{w_{t+1}} = mathbf{ w_t }- alpha frac{ partial mathbf{J}}{ partial mathbf{w}} = mathbf{w_t} - mathbf{ frac{ alpha}{N}x^T(y-t)}wt+1​=wt​−α∂w∂J​=wt​−Nα​xT(y−t) . In coordinate systems this is equivalent to: . wt+1=wt−α1N∑i=1Nxt(y(i)−t(i))w_{t+1} = w_t - alpha frac{1}{N} sum_{i=1}^{N} x_t (y^{(i)}-t^{(i)})wt+1​=wt​−αN1​i=1∑N​xt​(y(i)−t(i)) . The python implementation of gradient descent is shown below: . def getGradient(x, w, t): N, D = np.shape(x) gradient = (1.0/ float(N)) * np.matmul(np.transpose(x), loss(x,w,t)) return gradient . def gradientDescentMethod(x, t, alpha=0.1, tolerance=1e-2): N, D = np.shape(x) #w = np.random.randn(D) w = np.zeros([D]) # Perform Gradient Descent iterations = 1 w_cost = [(w, cost(x,w, t))] while True: dw = getGradient(x, w, t) w_k = w - alpha * dw w_cost.append((w, cost(x, w, t))) # Stopping Condition if np.sum(abs(w_k - w)) &lt; tolerance: print (&quot;Converged.&quot;) break if iterations % 100 == 0: print (&quot;Iteration: %d - cost: %.4f&quot; %(iterations, cost(x, w, t))) iterations += 1 w = w_k return w, w_cost . Generalization . The goal of a learning algorithm is not only to make correct predictions on the training examples but also to be generalized to patterns not seen before. The average squared error on new examples is known as the generalization error, and we’d like this to be as small as possible. In practice, we normally tune model parameters by partitioning the dataset into three different subsets: . The training set is used to train the model. | The validation set is used to estimate the generalization error of each hyperparameter setting. | The test set is used at the very end, to estimate the generalization error of the final model, once all hyperparameters have been chosen. | .",
            "url": "/sambaiga/machine%20learning/2017/06/01/ml-introduction.html",
            "relUrl": "/machine%20learning/2017/06/01/ml-introduction.html",
            "date": " • Jun 1, 2017"
        }
        
    
  
    
        ,"post9": {
            "title": "Learning HMM parameters with Discrete Observation Models",
            "content": "Introduction . In the previous post, we discussed the basics of HMM modeling given model parameters λ lambdaλ and compute the likelihood values etc., efficiently based on the forward, backward, and Viterbi algorithms. In the like manner, we can efficiently train the HMM to obtain the model parameter λ^ hat{ lambda}λ^ from data. In this post, we will discuss different methods for training HMM models. . This is the solution to Problem 3, which involves determining a method to learn model parameters λ^ hat{ lambda}λ^ given the sequence of observation variables YYY. Given the observation sequences YYY as training data, there is no optimal way of estimating the model parameters. However, using iterative procedure we can choose λ^=(A^,B^,π^) hat{ lambda} = ( hat{A}, hat{B}, hat{ pi})λ^=(A^,B^,π^) such that P(Y∣λ)P(Y mid lambda)P(Y∣λ) is locally maximized.The most common procedure which has been employed to his problem is the Baum-Welch method. . Baum-Welch Methods . This method assumes an initial model parameter of λ lambdaλ, which should be adjusted to increase P(Y∣λ)P(Y mid lambda)P(Y∣λ). The initial parametrs can be constructed in any way or employ the first five procedure of the Segmental K-means algorithm. The optimazation criteria is called the maximum likelihood criteria.The function P(Y∣λ)P(Y mid lambda)P(Y∣λ) is called the likelihood function. . The E-M Auxilliary Function . Let λ lambdaλ represent the current model and λ^ hat{ lambda}λ^ represent the candidate models. The learning objective is to make: P(Y∣λ^)≥P(Y∣λ)P(Y mid hat{ lambda}) geq P(Y mid lambda)P(Y∣λ^)≥P(Y∣λ) which is equivalently to log⁡[P(Y∣λ^)]≥log⁡[P(Y∣λ)] log[P(Y mid hat{ lambda})] geq log [P(Y mid lambda)]log[P(Y∣λ^)]≥log[P(Y∣λ)] . Let also define the auxilliary function Q(λ^∣λ)Q( hat{ lambda} mid lambda)Q(λ^∣λ) such that: Q(λ^∣λ)=E[log⁡P(Y,S∣λ^)∣Y,λ]=∑sP(S∣Y,λ)⋅log⁡[P(Y,S∣λ^)] begin{aligned} Q( hat{ lambda} mid lambda) &amp; = mathbb{E} Big[ log P(Y,S mid hat{ lambda}) mid Y, lambda Big] &amp; = sum_s P(S mid Y, lambda) cdot log [P(Y,S mid hat{ lambda})] end{aligned}Q(λ^∣λ)​=E[logP(Y,S∣λ^)∣Y,λ]=s∑​P(S∣Y,λ)⋅log[P(Y,S∣λ^)]​ . The Maximum Likelihood Estimation (MLE) of the model parameter λ lambdaλ for complete data YYY and hidden state SSS is; . λ^=arg⁡max⁡λ∑sP(Y,S∣λ) hat{ lambda} = arg max _{ lambda} sum_s P(Y, S mid lambda)λ^=argλmax​s∑​P(Y,S∣λ) . However due to the presence of several stochatsic constraints it turns out to be easier to mximize uxilliary function Q(λ^∣λ)Q( hat{ lambda} mid lambda)Q(λ^∣λ) rather than directly maximize P(Y∣λ^)P(Y mid hat{ lambda})P(Y∣λ^). Thus the MLE of the model parameter λ lambdaλ for complete data YYY and hidden state SSS become: . λ^=arg⁡max⁡λQ(λ^∣λ) hat{ lambda} = arg max _{ lambda} Q( hat{ lambda} mid lambda)λ^=argλmax​Q(λ^∣λ) . It can be shown that the parameter estimated by the EM procedure, Q(λ^∣λ)Q( hat{ lambda} mid lambda)Q(λ^∣λ), always increases the likelihood value. You may concert reference 2 chapter 3 for details on the prove. . Expectation step . To find ML estimates of HMM parameters, we first expand the auxiliary function rewrite it by substituting the joint distribution of complete data likelihood. . Q(λ^∣λ)=E[log⁡P(Y,S∣λ^)∣Y,λ]=∑sP(S∣Y,λ)⋅log⁡[P(Y,S∣λ^)]=∑sP(S∣Y,λ)⋅[log⁡π^1+log⁡b^1(y1)+∑t=2T(log⁡a^ij+log⁡b^i(yt))] begin{aligned} Q( hat{ lambda} mid lambda) &amp; = mathbf{E} Big[ log P(Y,S mid hat{ lambda}) mid Y, lambda Big] &amp; = sum_s P(S mid Y, lambda) cdot log [P(Y,S mid hat{ lambda})] &amp; = sum_s P(S mid Y, lambda) cdot Big[ log hat{ pi}_1 + log hat{b}_1(y_1) + sum _{t=2}^T big( log hat{a} _{ij} + log hat{b}_i({y_t}) big) Big] end{aligned}Q(λ^∣λ)​=E[logP(Y,S∣λ^)∣Y,λ]=s∑​P(S∣Y,λ)⋅log[P(Y,S∣λ^)]=s∑​P(S∣Y,λ)⋅[logπ^1​+logb^1​(y1​)+t=2∑T​(loga^ij​+logb^i​(yt​))]​ . We have three term to solve: . The initial probability π^ hat{ pi}π^ , | State transition probability A^=a^ij hat{A} = hat{a}_{ij}A^=a^ij​ and | Emission probability B^=b^i(yt) hat{B} = hat{b}_i(y_t)B^=b^i​(yt​). | . Let first define important parameters that we will use. For t=1,2...Tt = 1,2...Tt=1,2...T, 1≤i≥N1 leq i geq N1≤i≥N and 1≤j≥N1 leq j geq N1≤j≥N, we define: . ξt(i,j)=P(st=i,st+1=j∣Y,λ) xi_t(i,j)=P(s_t=i, s_{t+1}=j mid Y, lambda)ξt​(i,j)=P(st​=i,st+1​=j∣Y,λ) . an expected transition probability from st=is_t=ist​=i to , st+1=js_{t+1}=jst+1​=j. The probability of being in state sis_isi​ at time ttt and state sjs_jsj​ at time t+1t+1t+1 given the model λ lambdaλ and observation sequences YYY. . ξt(i,j) xi_t(i,j)ξt​(i,j) can be written in terms of forward αt(i) alpha_t(i)αt​(i) and backward βt+1(j) beta_{t+1}(j)βt+1​(j) variables as: . ξt(i,j)=αt(i)aijbi(yt+1)βt+1(j)P(Y∣λ)=αt(i)aijbi(yt+1)βt+1(i)∑i=1N∑j=1Nαt(i)aijbj(yt+1)βt+1(j) begin{aligned} xi_t(i,j) &amp;= frac{ alpha_t(i)a_{ij}b_i(y_{t+1}) beta_{t+1}(j)}{P(Y mid lambda)} &amp;= frac{ alpha_t(i)a_{ij}b_i(y_{t+1}) beta_{t+1}(i)}{ displaystyle sum_{i=1}^{N} displaystyle sum_{j=1}^{N} alpha_t(i)a_{ij}b_j(y_{t+1}) beta_{t+1}(j)} end{aligned}ξt​(i,j)​=P(Y∣λ)αt​(i)aij​bi​(yt+1​)βt+1​(j)​=i=1∑N​j=1∑N​αt​(i)aij​bj​(yt+1​)βt+1​(j)αt​(i)aij​bi​(yt+1​)βt+1​(i)​​ . where the numerator term is just P(St=si,St+1=sj∣Y,λ)P(S_t=s_i, S_{t+1}=s_j mid Y, lambda)P(St​=si​,St+1​=sj​∣Y,λ) and the division by P(Y∣λ)P(Y mid lambda)P(Y∣λ) gives the desire probability measures. . We have previosly difined γt(i)=αt(i)βt(i)P(Y∣λ) gamma_t(i) = frac{ alpha_t(i) beta_t(i)}{P(Y mid lambda)}γt​(i)=P(Y∣λ)αt​(i)βt​(i)​ as the probability of being in state sis_isi​ at time ttt given the observation sequence and model parameter. γt(i) gamma_t(i)γt​(i) relate to ξt(i,j) xi_t(i,j)ξt​(i,j) as follows: . γt(i)=∑j=1Nξt(i,j) gamma_t(i) = displaystyle sum_{j=1}^{N} xi_t(i,j)γt​(i)=j=1∑N​ξt​(i,j) . It follows that: . ∑t=1T−1γt(i)= displaystyle sum_{t=1}^{T-1} gamma_t(i)=t=1∑T−1​γt​(i)= Expected number of transitions from state iii . . ∑t=1T−1ξt(i,j)= displaystyle sum_{t=1}^{T-1} xi_t(i,j)=t=1∑T−1​ξt​(i,j)= Expected number of transitions from state iii to state jjj. . We provide a solution for each term. Considering the first term Q(π^∣π)Q( hat{ pi} mid pi)Q(π^∣π) we define the following auxiliary function for πi pi _iπi​ as: . Q(π^∣π)=∑sP(S∣Y,λ)⋅log⁡π^s1Q( hat{ pi} mid pi) = sum_s P(S mid Y, lambda) cdot log hat{ pi}_{s_1}Q(π^∣π)=s∑​P(S∣Y,λ)⋅logπ^s1​​ . Since π^s1 hat{ pi}_{s_1}π^s1​​ only depends on s1s_1s1​, it clear that: . P(S∣Y,λ)=P(s1∣Y,λ)P(S mid Y, lambda) = P(s_1 mid Y, lambda)P(S∣Y,λ)=P(s1​∣Y,λ) . Therefore Q(π^∣pi)Q( hat{ pi} mid pi)Q(π^∣pi) can be rewritten as: . Q(π^∣π)=∑s1P(s1∣Y,λ)⋅log⁡π^s1=∑i=1NP(s1=i∣Y,λ)⋅log⁡π^i=∑i=1Nγt(i)log⁡π^i begin{aligned} Q( hat{ pi} mid pi) &amp;= sum_{s_1}P(s_1 mid Y, lambda) cdot log hat{ pi}_{s_1} &amp;= sum_{i=1}^N P(s_1=i mid Y, lambda) cdot log hat{ pi}_{i} &amp; = sum_{i=1}^N gamma_t(i) log hat{ pi}_{i} end{aligned}Q(π^∣π)​=s1​∑​P(s1​∣Y,λ)⋅logπ^s1​​=i=1∑N​P(s1​=i∣Y,λ)⋅logπ^i​=i=1∑N​γt​(i)logπ^i​​ . Next, we focus on the second term Q(A^∣A)Q( hat{A} mid A)Q(A^∣A) . Q(A^∣A)=∑sP(S∣Y,λ)⋅∑t=2Tlog⁡a^st,st+1Q( hat{A} mid A) = sum_s P(S mid Y, lambda) cdot sum _{t=2}^T log hat{a}_{s_t,s_{t+1}}Q(A^∣A)=s∑​P(S∣Y,λ)⋅t=2∑T​loga^st​,st+1​​ . Similar to Q(π^∣π)Q( hat{ pi} mid pi)Q(π^∣π) , we obtain P(S∣Y,λ)=P(s1∣Y,λ)=P(st,st+1∣Y,λ)P(S mid Y, lambda) = P(s_1 mid Y, lambda) = P(s_t,s_{t+1} mid Y, lambda)P(S∣Y,λ)=P(s1​∣Y,λ)=P(st​,st+1​∣Y,λ) . Therefore . Q(A^∣A)=∑t=1T−1∑sP(st,st+1∣Y,λ)log⁡a^st,st+1=∑t=1T−1∑i=1N∑j=1NP(st=i,st+1=j∣Y,λ)log⁡a^ij=∑t=1T−1∑i=1N∑j=1Nξt(i,j)log⁡a^ij begin{aligned} Q( hat{A} mid A) &amp; = sum _{t=1}^{T-1} sum_s P(s_t,s_{t+1} mid Y, lambda) log hat{a}_{s_t,s_{t+1}} &amp; = sum _{t=1}^{T-1} sum_{i=1}^N sum_{j=1}^N P(s_t=i,s_{t+1}=j mid Y, lambda) log hat{a}_{ij} &amp; = sum _{t=1}^{T-1} sum_{i=1}^N sum_{j=1}^N xi_t(i,j) log hat{a}_{ij} end{aligned}Q(A^∣A)​=t=1∑T−1​s∑​P(st​,st+1​∣Y,λ)loga^st​,st+1​​=t=1∑T−1​i=1∑N​j=1∑N​P(st​=i,st+1​=j∣Y,λ)loga^ij​=t=1∑T−1​i=1∑N​j=1∑N​ξt​(i,j)loga^ij​​ . Finally, we focus on the last term Q(B^∣B)Q( hat{B} mid B)Q(B^∣B) . Q(B^∣B)=∑sP(S∣Y,λ)⋅∑t=1Tlog⁡b^i(yt)Q( hat{B} mid B) = sum_s P(S mid Y, lambda) cdot sum _{t=1}^T log hat{b}_{i}(y_t)Q(B^∣B)=s∑​P(S∣Y,λ)⋅t=1∑T​logb^i​(yt​) . Similary P(S∣Y,λ)=P(st=i∣Y,λ)P(S mid Y, lambda) = P(s_t = i mid Y, lambda)P(S∣Y,λ)=P(st​=i∣Y,λ). Therefore . Q(B^∣B)=∑t=1T∑sP(st=i∣Y,λ)log⁡b^i(yt)=∑t=1T∑i=1Nγt(i)log⁡b^i(yt) begin{aligned} Q( hat{B} mid B) &amp;= sum _{t=1}^T sum_s P(s_t = i mid Y, lambda) log hat{b}_{i}(y_t) &amp; = sum _{t=1}^T sum_{i=1}^N gamma_t(i) log hat{b}_{i}(y_t) end{aligned}Q(B^∣B)​=t=1∑T​s∑​P(st​=i∣Y,λ)logb^i​(yt​)=t=1∑T​i=1∑N​γt​(i)logb^i​(yt​)​ . Thus, we summarize the auxiliary function. . Q(λ^∣λ)=Q(π^∣π)+Q(A^∣A)+Q(B^∣B)Q( hat{ lambda} mid lambda)= Q( hat{ pi} mid pi)+ Q( hat{A} mid A) + Q( hat{B} mid B)Q(λ^∣λ)=Q(π^∣π)+Q(A^∣A)+Q(B^∣B) . Maximization step . In the maximization step, we aim to maximize Q(π^∣π)Q( hat{ pi} mid pi)Q(π^∣π), Q(A^∣A)Q( hat{A} mid A)Q(A^∣A) and Q(B^∣B)Q( hat{B} mid B)Q(B^∣B) with respect to π^ hat{ pi}π^, A^ hat{A}A^ and B^ hat{B}B^ under the following constraints. . ∑_i=1Nπ^=1, and ∑i=1NA^=1 sum _{i=1}^N hat{ pi} = 1, text{ and } sum_{i=1}^N hat{A} = 1∑_i=1Nπ^=1, and i=1∑N​A^=1 . Considering the estimation of initial state probabilities π^=π^i mathbf{ hat{ pi}} = { hat{ pi}_i}π^=π^i​ , we construct a Lagrange function (or Lagrangian): . Q∗(π^∣π)=∑i=1Nγ1(i)log⁡π^i+η(∑i=1Nπ^−1)Q^*( hat{ pi} mid pi) = sum_{i=1}^N gamma_1(i) log hat{ pi}_{i} + eta left( sum_{i=1}^N hat{ pi} - 1 right)Q∗(π^∣π)=i=1∑N​γ1​(i)logπ^i​+η(i=1∑N​π^−1) . Differentiating this Lagrangian with respect to individual probability parameter π^i hat{ pi}_iπ^i​ and set it to zero we obtain. . ∂Q∗(π^∣π)∂π^i=γ1(i)1π^i+η=0π^i=−1ηγ1(i) begin{aligned} frac{ partial Q^*( hat{ pi} mid pi)}{ partial hat{ pi}_i } &amp; = gamma_1(i) frac{1}{ hat{ pi}_i} + eta = 0 hat{ pi}_i &amp;= - frac{1}{ eta} gamma_1(i) end{aligned}∂π^i​∂Q∗(π^∣π)​π^i​​=γ1​(i)π^i​1​+η=0=−η1​γ1​(i)​ . Substituting the above equation into ∑i=1Nπ^=1 sum_{i=1}^N hat{ pi} = 1∑i=1N​π^=1 constraint, we obtain: . ∑i=1Nπ^=∑i=1N−1ηγ1(i)=1⇒η=−∑i=1Nγ1(i) begin{aligned} sum_{i=1}^N hat{ pi} &amp;= sum_{i=1}^N - frac{1}{ eta} gamma_1(i) = 1 Rightarrow eta &amp;= - sum_{i=1}^N gamma_1(i) end{aligned}i=1∑N​π^⇒η​=i=1∑N​−η1​γ1​(i)=1=−i=1∑N​γ1​(i)​ . The ML estimate of new initial state probability is obtained by substituting the above equation into π^i=−1ηγ1(i) hat{ pi}_i = - frac{1}{ eta} gamma_1(i)π^i​=−η1​γ1​(i): . π^i=γ1(i)∑i=1Nγ1(i)=γ1(i) hat{ pi}_i = frac{ gamma_1(i)}{ sum _{i=1}^N gamma_1(i)} = gamma_1(i)π^i​=∑i=1N​γ1​(i)γ1​(i)​=γ1​(i) . In the same manner, we can derive the ML estimates of new state transition probability and new emission probability, which can be shown to be: . a^ij=∑t=1T−1ξt(i,j)∑t=1T−1γt(i) hat{a}_{ij} = frac{ displaystyle sum_{t=1}^{T-1} xi_t(i,j)}{ displaystyle sum_{t=1}^{T-1} gamma_t(i)}a^ij​=t=1∑T−1​γt​(i)t=1∑T−1​ξt​(i,j)​ . And . b^i(k)=∑t=1Tτγt(i)∑t=1Tγt(i) hat{b}_i(k) = frac{ displaystyle sum_{t=1}^{T} tau gamma_t(i)}{ displaystyle sum_{t=1}^{T} gamma_t(i)}b^i​(k)=t=1∑T​γt​(i)t=1∑T​τγt​(i)​ . where . τ={1 if yt=k,0 otherwise  tau = begin{cases} 1 text{ if } y_t = k, 0 text{ otherwise } end{cases}τ={1 if yt​=k,0 otherwise ​ . If we denote the initial model λ{ lambda}λ and the re-estimation model by λ^=(π^i,a^ij,b^j(k)) hat{ lambda}=( hat{ pi}_i, hat{a}_{ij}, hat{b}_j(k))λ^=(π^i​,a^ij​,b^j​(k)). Then i t can be shown that either: . The initial model λ lambdaλ is a critical point of the likelihood in which case λ^=λ hat{ lambda}= lambdaλ^=λ or | P(Y∣λ^)≤P(Y∣λ)P(Y mid hat lambda) leq P(Y mid lambda)P(Y∣λ^)≤P(Y∣λ), i.e we have find the better model from which the observation sequence Y=y1,…YTY=y_1, ldots Y_TY=y1​,…YT​ is more likely to be produced. | Hence we can go on iteractively computing until P(Y∣λ^)P(Y mid hat{ lambda})P(Y∣λ^) is maximazed. . The Baum-Welch Algorithm can be summarized as: . Require: λ←λinit lambda leftarrow lambda ^{init}λ←λinit . repeat | Compute the forward variable αt(i) alpha _t(i)αt​(i) from the forward algorithm | Compute the backward variable βt(i) beta _t(i)βt​(i) from the backward algorithm | Compute the occupation probabilities γt(i) gamma _t(i)γt​(i), and ξt(i,j) xi _t(i,j)ξt​(i,j) | Estimate the new HMM parameters λ^ hat{ lambda}λ^ | Update the HMM parameters λ←λ^ lambda leftarrow hat{ lambda}λ←λ^ | until Convergence | References . L. R. Rabiner, A tutorial on hidden Markov models and selected applications in speech recognition, Proceedings of the IEEE, Vol. 77, No. 2, February 1989. | Shinji Watanabe, Jen-Tzung Chien, Bayesian Speech and Language Processing, Cambridge University Press, 2015. | Viterbi Algorithm in Speech Enhancement and HMM | Nikolai Shokhirev, Hidden Markov Models |",
            "url": "/sambaiga/machine%20learning/2017/05/29/hmm-discrete.html",
            "relUrl": "/machine%20learning/2017/05/29/hmm-discrete.html",
            "date": " • May 29, 2017"
        }
        
    
  
    
        ,"post10": {
            "title": "The Basic of Hidden Markov Model",
            "content": "Introduction . HMM is a Markov model whose states are not directly observed; instead, each state is characterized by a probability distribution function. The probability distribution model the observation corresponding to that state. HMM has been extensively used in temporal pattern recognition such as speech, handwriting, gesture recognition, robotics, biological sequences, and recently in energy disaggregation. This tutorial will introduce the basic concept of HMM. . There are two variables in HMM: observed variables and hidden variables. The sequences of hidden variables form a Markov process, as shown in the figure below. In the context of NILM, the hidden variables are used to model states(ON, OFF, standby etc) of individual appliances, and the observed variables are used to model the electric usage. HMMs have been widely used in most of the recently proposed NILM approach. This is because HMM represents well the individual appliance internal states which are not directly observed in the targeted energy consumption. . A typical HMM is characterised by the following: . The finite set of hidden states SSS (e.g ON, stand-by, OFF, etc.) of an appliance, S={s1,s2....,sN}S = {s_1, s_2....,s_N }S={s1​,s2​....,sN​}. | The finite set of MMM observable symbol YYY per states (power consumption) observed in each state, Y={y1,y2....,yM}Y = {y_1, y_2....,y_M }Y={y1​,y2​....,yM​}. The observable symbol YYY can be discrete or a continuous set. | The transition matrix A={aij,1≤i,j≥N} mathbf{A}= {a_{ij},1 leq i,j geq N }A={aij​,1≤i,j≥N} represents the probability of moving from state st−1=is_{t-1}=ist−1​=i to st=js_t =jst​=j such that: aij=P(st=j∣st−1=i)a_{ij} = P(s_{t} =j mid s_{t-1}=i)aij​=P(st​=j∣st−1​=i), with aij≤0a_{ij} leq 0aij​≤0 and where sts_tst​ denotes the state occupied by the system at time ttt. The matrix A mathbf{A}A is NxNN x NNxN. | The emission matrix B={bj(k)} mathbf{B} = {b_j(k) }B={bj​(k)} representing the probability of emission of symbol kkk ϵ epsilonϵ YYY when system state is st=js_t=jst​=j such that: bj(k)=p(yt=k∣st=j)b_j(k) = p(y_t = k mid s_t=j)bj​(k)=p(yt​=k∣st​=j) The matrix B mathbf{B}B is an NxMN x MNxM. The emission probability can be discrete or continous distribution. If the emission is descrete a multinomial distribution is used and multivariate Gaussian distribution is usually used for continous emission. | And the initial state probability distribution π={πi} mathbf{ pi} = { pi_i }π={πi​} indicating the probability of each state of the hidden variable at t=1t = 1t=1 such that, πi=P(q1=si),1≤i≥N pi _i = P(q_1 = s_i), 1 leq i geq Nπi​=P(q1​=si​),1≤i≥N. | . For brief introduction of optuna, you can watch this video . The complete HMM specification requires; . Finite set of hidden states NNN and observation symbols MMM | Length of observation seqences TTT and | Specification of three probability measures A,B mathbf{A}, mathbf{B}A,B and π mathbf{ pi}π | The set of all HMM model parameters is represented by λ=(π,A,B) mathbf{ lambda} =( pi, A, B)λ=(π,A,B). . Since $S$ is not observed, the likelihood function of YYY is given by the joint distribution of $Y$ and $S$ over all possible state. . P(Y∣λ)=∑P(Y,S∣λ)P(Y mid lambda) = sum P(Y, S mid lambda)P(Y∣λ)=∑P(Y,S∣λ) . where . P(Y,S∣λ)=P(Y∣S,λ)P(S∣λ)P(Y,S mid lambda) = P(Y mid S, lambda)P(S mid lambda)P(Y,S∣λ)=P(Y∣S,λ)P(S∣λ) . Note that yty_tyt​ is independent and identically distributed given state sequence S={s1,s2....,sN}S = {s_1, s_2....,s_N }S={s1​,s2​....,sN​}. Also each state at time ttt depend on the state at its previous time t−1t-1t−1. Then . P(Y∣S,λ)=∏t=1TP(yt∣st)P(Y mid S, lambda) = prod_{t=1}^T P(y_t mid s_t)P(Y∣S,λ)=t=1∏T​P(yt​∣st​) . Similary . P(S∣λ)=πs1∏t=2TaijP(S mid lambda) = pi _{s_1} prod _{t=2}^T a_{ij}P(S∣λ)=πs1​​t=2∏T​aij​ . The joint probability is therefore: . P(Y∣λ)=πs1P(y1∣s1)∑∏t=2TaijP(yt∣st)P(Y mid lambda) = pi _{s_1}P(y_1 mid s_1) sum prod_{t=2}^T a_{ij} P(y_t mid s_t)P(Y∣λ)=πs1​​P(y1​∣s1​)∑t=2∏T​aij​P(yt​∣st​) . Three main problems in HMMs . When applying HMM to a real-world problem, three crucial issues must be solved. . Evaluation Problem: Given HMM parameters λ lambdaλ and the observation sequence Y={Y1,Y2....,YM}Y = {Y_1, Y_2....,Y_M }Y={Y1​,Y2​....,YM​}, find P(Y∣λ)P(Y mid lambda)P(Y∣λ) the likelihood of the observation sequence YYY given the model λ lambdaλ. This problem gives a score on how well a given model matches a given observation and allows you to choose the model that best matches the observation. | Decoding Problem: Given HMM parameters λ lambdaλ and the observation seqence Y={Y1,Y2....,YM}Y = {Y_1, Y_2....,Y_M }Y={Y1​,Y2​....,YM​}, find an optimal state sequense S={S1,S2....,SN}S = {S_1, S_2....,S_N }S={S1​,S2​....,SN​} which best explain the observation.This problem attempt to cover the hidden part of the model. | Learning Problem: Given the obseravtion seqence Y={Y1,Y2....,YM}Y = {Y_1, Y_2....,Y_M }Y={Y1​,Y2​....,YM​}, find the model parameters λ lambdaλ that maximize P(Y∣λ)P(Y mid lambda)P(Y∣λ).This problem attempt to optimize the model parameters so as to describe the model. | The first and the second problem can be solved by the dynamic programming algorithms known as the Viterbi algorithm and the Forward-Backward algorithm, respectively. The last one can be solved by an iterative Expectation-Maximization (EM) algorithm, known as the Baum-Welch algorithm. We will discuss the first and the second problem in this post. . Solution to Problem 1 . A straight forward way to solve this problem is to find P(Y∣S,λ)P(Y mid S, lambda)P(Y∣S,λ) for fixed state sequences S={s1,...sT}S = {s_1,...s_T }S={s1​,...sT​} and then sum up over all possible states. This is generally infeasible since it requires about 2TNT2TN^T2TNT multiplications. Nevertheless, this problem can be efficiently solved by using the forward algorithm as follows: . The forward-backward Algorithm . Let us define the forward variable . αt(i)=P(y1,…yt,st=i∣λ) alpha _t(i)=P(y_1, ldots y_t, s_t=i mid lambda)αt​(i)=P(y1​,…yt​,st​=i∣λ) . the probability of the partial observation sequences y1…yty_1 ldots y_ty1​…yt​ up to time ttt and the state st=is_t =ist​=i at time ttt given the model λ{ lambda}λ. We also define an emission probability given HMM state iii at time ttt as bi(yt)b_i(y_t)bi​(yt​). . Forward-Algorithm . Initialization . Let . α1(i)=P(y1,s1=i∣λ)=P(y1∣s1=i,λ)P(s1=i∣λ)=πibi(y1) for 1≤i≥N begin{aligned} alpha _1(i)&amp;=P(y_1, s_1=i mid lambda) &amp; = P(y_1 mid s_1=i, lambda)P(s_1=i mid lambda) &amp;= pi _i b_i(y_1) text{ for } 1 leq i geq N end{aligned}α1​(i)​=P(y1​,s1​=i∣λ)=P(y1​∣s1​=i,λ)P(s1​=i∣λ)=πi​bi​(y1​) for 1≤i≥N​ . Induction . For t=2,3...Tt=2,3...Tt=2,3...T and 1≤i≥N1 leq i geq N1≤i≥N, compute: . αt(i)=P(y1…yt,st=i∣λ)=∑j=1NP(y1…yt,st−1=j,st=i∣λ)=∑j=1NP(yt∣st=i,y1,…yt−1,st−1=j,λ)×P(st=i∣y1…yt−1…,st−1=j,λ)×P(y1…yt−1,st−1=j,λ)=P(yt∣st=i,λ)∑j=1NP(st=i∣st−1=j)⋅P(y1,…yt−1,st−1)=bi(yt)∑j=1Nαt−1(i)aij begin{aligned} alpha _{t}(i) &amp; = P(y_1 ldots y_t, s_t=i mid lambda) &amp;= displaystyle sum_{j=1}^{N} P(y_1 ldots y_{t}, s_{t-1}=j,s_t=i mid lambda) &amp;= displaystyle sum_{j=1}^{N} P(y_t mid s_t=i, y_1, ldots y_{t-1}, s_{t-1}=j, lambda) &amp; times P(s_t=i mid y_1 ldots y_{t-1} ldots , s_{t-1}=j, lambda) &amp; times P(y_1 ldots y_{t-1}, s_{t-1}=j, lambda) &amp; = P(y_t mid s_t=i, lambda) displaystyle sum_{j=1}^{N} P(s_t=i mid s_{t-1}=j) cdot P(y_1, ldots y_{t-1}, s_{t-1}) &amp; = b_i(y_{t}) displaystyle sum_{j=1}^{N} alpha _{t-1}(i)a_{ij} end{aligned}αt​(i)​=P(y1​…yt​,st​=i∣λ)=j=1∑N​P(y1​…yt​,st−1​=j,st​=i∣λ)=j=1∑N​P(yt​∣st​=i,y1​,…yt−1​,st−1​=j,λ)×P(st​=i∣y1​…yt−1​…,st−1​=j,λ)×P(y1​…yt−1​,st−1​=j,λ)=P(yt​∣st​=i,λ)j=1∑N​P(st​=i∣st−1​=j)⋅P(y1​,…yt−1​,st−1​)=bi​(yt​)j=1∑N​αt−1​(i)aij​​ . Termination . From αt(i)=P(y1,...yt,st=i∣λ) alpha _t(i)=P(y_1,...y_t, s_t=i mid lambda)αt​(i)=P(y1​,...yt​,st​=i∣λ), it cear that: . P(Y∣λ)=∑i=1NP(y1,…yT,sT=i∣λ)=∑i=1NαT(i) begin{aligned} P(Y mid lambda) &amp;= displaystyle sum_{i=1}^{N} P(y_1, ldots y_T, s_T = i mid lambda) &amp;= displaystyle sum_{i=1}^{N} alpha _T(i) end{aligned}P(Y∣λ)​=i=1∑N​P(y1​,…yT​,sT​=i∣λ)=i=1∑N​αT​(i)​ . The forward algorithm only requires about N2TN^2TN2T multiplications and is it can be implemented in Python as follows. . def forward(obs_seq): T = len(obs_seq) N = A.shape[0] alpha = np.zeros((T, N)) alpha[0] = pi*B[:,obs_seq[0]] for t in range(1, T): alpha[t] = alpha[t-1].dot(A) * B[:, obs_seq[t]] return alpha def likelihood(obs_seq): # returns log P(Y mid model) # using the forward part of the forward-backward algorithm return forward(obs_seq)[-1].sum() . Backward Algorithm . This is the same as the forward algorithm discussed in the previous sectionexcept that it start at the end and works backward toward the beginning. We first define the backward variable βt(i)=P(yt+1,yt+2…yT∣st=i,λ) beta_t(i)=P(y_{t+1},y_{t+2} ldots y_{T} mid s_t=i, { lambda})βt​(i)=P(yt+1​,yt+2​…yT​∣st​=i,λ): probability of the partial observed sequence from t+1t+1t+1 to the end at TTT given state iii at time ttt and the model λ lambdaλ. . Then βt(i) beta_t(i)βt​(i) can be recursively computed as follows. . Initialization . Let βT(i)=1 beta_{T}(i)= 1βT​(i)=1, for 1≤i≥N1 leq i geq N1≤i≥N . Induction . For t=T−1,T−2,…1t =T-1, T-2, ldots1t=T−1,T−2,…1 for 1≤i≥N1 leq i geq N1≤i≥N and by using the sum and product rules, we can rewrite βt(j) beta_t(j)βt​(j) as: . βt(i)=P(yt+1,…yT∣st=j,λ)=∑i=1NP(yt+1…yT,st+1=i∣st=j,λ)=∑i=1NP(yt+1…yT,st+1=i,st=j,λ)⋅P(st+1=i∣st=j)=∑i=1NP(yt+2…yT,st+1=i,λ)⋅P(yt+1∣st+1=i,λ)⋅P(st+1=i∣st=j)=∑i=1Naijbi(yt+1)βt+1(i) begin{aligned} beta_t(i)&amp;=P(y_{t+1}, ldots y_{T} mid s_t=j, { lambda}) &amp;= displaystyle sum_{i=1}^{N} P(y_{t+1} ldots y_T, s_{t+1}=i mid s_t=j, lambda) &amp; = displaystyle sum_{i=1}^{N} P(y_{t+1} ldots y_T, s_{t+1}=i, s_t=j, lambda) cdot P(s_{t+1}=i mid s_t=j) &amp;= displaystyle sum_{i=1}^{N} P(y_{t+2} ldots y_T, s_{t+1}=i, lambda) cdot P(y_{t+1} mid s_{t + 1}=i, lambda) cdot P(s_{t+1}=i mid s_t=j) &amp; = displaystyle sum_{i=1}^{N} a_{ij}b_i(y_{t+1}) beta _{t+1}(i) end{aligned}βt​(i)​=P(yt+1​,…yT​∣st​=j,λ)=i=1∑N​P(yt+1​…yT​,st+1​=i∣st​=j,λ)=i=1∑N​P(yt+1​…yT​,st+1​=i,st​=j,λ)⋅P(st+1​=i∣st​=j)=i=1∑N​P(yt+2​…yT​,st+1​=i,λ)⋅P(yt+1​∣st+1​=i,λ)⋅P(st+1​=i∣st​=j)=i=1∑N​aij​bi​(yt+1​)βt+1​(i)​ . Termination . β0=P(Y∣λ)=∑i=1NP(y1,…yT,s1=i)=∑i=1NP(y1,…yT∣s1=i)⋅P(s1=i)=∑i=1NP(y1∣s1=i)⋅P(y2,…yT∣s1=i)⋅P(s1=i)=∑i=1Nπibi(y1)β1(i) begin{aligned} beta_{0} &amp; = P(Y mid lambda) &amp; = displaystyle sum_{i=1}^{N} P(y_1, ldots y_T, s_1=i) &amp;= displaystyle sum_{i=1}^{N} P(y_1, ldots y_T mid s_1=i) cdot P(s_1=i) &amp; = displaystyle sum_{i=1}^{N} P(y_1 mid s_1=i) cdot P(y_2, ldots y_T mid s_1=i) cdot P(s_1=i) &amp; = displaystyle sum_{i=1}^{N} pi _i b_i(y_1) beta _1(i) end{aligned}β0​​=P(Y∣λ)=i=1∑N​P(y1​,…yT​,s1​=i)=i=1∑N​P(y1​,…yT​∣s1​=i)⋅P(s1​=i)=i=1∑N​P(y1​∣s1​=i)⋅P(y2​,…yT​∣s1​=i)⋅P(s1​=i)=i=1∑N​πi​bi​(y1​)β1​(i)​ . Python implementation of the forward algorithm is as shown below; . def backward(obs_seq): N = A.shape[0] T = len(obs_seq) beta = np.zeros((N,T)) beta[:,-1:] = 1 for t in reversed(range(T-1)): for n in range(N): beta[n,t] = np.sum(beta[:,t+1] * A[n,:] * B[:, obs_seq[t+1]]) return beta . Posterior Probability . The forward variable αt(i) alpha _t(i)αt​(i) and backward variable βt(i) beta _t(i)βt​(i) are used to calculate the posterior probability of a specific case. Now for t=1...Tt=1...Tt=1...T and i=1..Ni=1..Ni=1..N, let define posterior probability γt(i)=P(st=i∣Y,λ) gamma_t(i)=P(s_t=i mid Y, lambda)γt​(i)=P(st​=i∣Y,λ) the probability of being in state st=is_t = ist​=i at time ttt given the observation YYY and the model λ lambdaλ. . γt(i)=P(st=1,Y∣λ)P(Y∣λ)=P(y1,…yt,st=1,∣λ)P(Y∣λ) begin{aligned} gamma_t(i) &amp; = frac{P(s_t=1, Y mid lambda)}{P(Y mid lambda)} &amp;= frac{P(y_1, ldots y_t, s_t=1, mid lambda)}{P(Y mid lambda)} end{aligned}γt​(i)​=P(Y∣λ)P(st​=1,Y∣λ)​=P(Y∣λ)P(y1​,…yt​,st​=1,∣λ)​​ . Consider: . P(y1,…yt,st=1,∣λ)=P(y1,…yt∣st=1,λ)⋅P(yt+1,…yT∣st=1,λ)⋅P(st=i∣λ)=αt(i)⋅βt(i) begin{aligned} P(y_1, ldots y_t, s_t=1, mid lambda) &amp; = P(y_1, ldots y_t mid s_t=1, lambda) cdot P(y_{t+1}, ldots y_T mid s_t=1, lambda) cdot P(s_t =i mid lambda) &amp; = alpha _t(i) cdot beta _t(i) end{aligned}P(y1​,…yt​,st​=1,∣λ)​=P(y1​,…yt​∣st​=1,λ)⋅P(yt+1​,…yT​∣st​=1,λ)⋅P(st​=i∣λ)=αt​(i)⋅βt​(i)​ . Thus . γt(i)=αt(i)⋅βt(i)P(Y∣λ) gamma_t(i) = frac{ alpha _t(i) cdot beta _t(i)}{P(Y mid lambda)}γt​(i)=P(Y∣λ)αt​(i)⋅βt​(i)​ . where . P(Y∣λ)=∑i=1NαT(i)P(Y mid { lambda}) = displaystyle sum_{i=1}^{N} alpha _T(i)P(Y∣λ)=i=1∑N​αT​(i) . In python: . def gamma(obs_seq): alpha = forward(obs_seq) beta = backward(obs_seq) obs_prob = likelihood(obs_seq) return (np.multiply(alpha,beta.T) / obs_prob) . We can use γt(i) gamma_t(i)γt​(i) to find the most likely state at time ttt which is the state st=is_t=ist​=i for which γt(i) gamma_t(i)γt​(i) is maximum. This algorithm works fine in the case when HMM is ergodic i.e., there is the transition from any state to any other state. If applied to an HMM of another architecture, this approach could give a sequence that may not be a legitimate path because some transitions are not permitted. To avoid this problem, Viterbi algorithm is the most common decoding algorithm used. . Viterbi Algorithm . Viterbi is a kind of dynamic programming algorithm that makes uses of a dynamic programming trellis. . The virtebi algorithm offer an efficient way of finding the single best state sequence.Let define the highest probability along a single path, at time ttt, which accounts for the first ttt observations and ends in state jjj using a new notation: . δt(i)=max⁡s1,…st−1P(s1,…st=1,y1,…yt∣λ) begin{aligned} delta_t(i) &amp; = max_{s_1, ldots s_{t-1}} P(s_1, ldots s_t =1, y_1, ldots y_t mid lambda) end{aligned}δt​(i)​=s1​,…st−1​max​P(s1​,…st​=1,y1​,…yt​∣λ)​ . By induction, a recursive formula of δt+1(i) delta_{t+1}(i)δt+1​(i) from δt(i) delta_t(i)δt​(i) is derived to calculate this probability as follows: . Consider the joint distribution appearing in δt+1(i) delta_{t+1}(i)δt+1​(i), which can be rewritten when st+1=is_{t+1}=ist+1​=i and st=js_t = jst​=j as: . P(s1,…,st=j,st+1=i,y1,…yt,yt+1∣λ)=P(s1…st=j,y1,…yt∣λ)×P(st+1=i,yt+1∣s1,…st,y1,…yt,λ)=P(s1…st=j,y1,…yt∣λ)⋅P(st+1∣st,λ)×P(yt+1∣st+1,λ)=P(s1…st=j,y1,…yt∣λ)⋅aijbi(yt+1) begin{aligned} P(s_1, ldots, s_t=j,s_{t+1}=i, y_1, ldots y_t, y_{t+1} mid lambda) &amp; = P(s_1 ldots s_t=j, y_1, ldots y_t mid lambda) &amp; times P(s_{t+1}=i,y_{t+1} mid s_1, ldots s_t, y_1, ldots y_t, lambda) &amp; = P(s_1 ldots s_t=j, y_1, ldots y_t mid lambda) cdot P(s_{t+1} mid s_t, lambda) &amp; times P(y_{t+1} mid s_{t+1}, lambda) &amp; = P(s_1 ldots s_t=j, y_1, ldots y_t mid lambda) cdot a_{ij}b_i(y_{t+1}) end{aligned}P(s1​,…,st​=j,st+1​=i,y1​,…yt​,yt+1​∣λ)​=P(s1​…st​=j,y1​,…yt​∣λ)×P(st+1​=i,yt+1​∣s1​,…st​,y1​,…yt​,λ)=P(s1​…st​=j,y1​,…yt​∣λ)⋅P(st+1​∣st​,λ)×P(yt+1​∣st+1​,λ)=P(s1​…st​=j,y1​,…yt​∣λ)⋅aij​bi​(yt+1​)​ . Thus δt+1(i) delta_{t+1}(i)δt+1​(i) is computed recursively from δt+1(j) delta_{t+1}(j)δt+1​(j) as: . δt+1(i)=max⁡s1,…st=jP(s1…st=j,y1,…yt∣λ)⋅aijbi(yt+1)=max⁡j[δt(j)aij]⋅bi(yt+1) begin{aligned} delta_{t+1}(i) &amp;= max_{s_1, ldots s_{t}=j} P(s_1 ldots s_t=j, y_1, ldots y_t mid lambda) cdot a_{ij}b_i(y_{t+1}) &amp; = max_{j} Big[ delta_t(j) a_{ij} Big] cdot b_i(y_{t+1}) end{aligned}δt+1​(i)​=s1​,…st​=jmax​P(s1​…st​=j,y1​,…yt​∣λ)⋅aij​bi​(yt+1​)=jmax​[δt​(j)aij​]⋅bi​(yt+1​)​ . Therefore, we need to keep track of the state that maximizes the above equation to backtrack to the single best state sequence in the following Viterbi algorithm: . Initialization . For 1≤i≥N1 leq i geq N1≤i≥N, let: . δ1(i)=πsibi(y1)Θ1(i)=0 begin{aligned} delta _1(i)&amp;= pi _{s_i}b_i(y_1) Theta _1(i)&amp;=0 end{aligned}δ1​(i)Θ1​(i)​=πsi​​bi​(y1​)=0​ . Recursion . Calculate the ML (maximum likelihood) state sequences and their probabilities. For t=2,3,...Tt=2,3,...Tt=2,3,...T and 1≤i≥N1 leq i geq N1≤i≥N . δt(i)=max⁡jϵ1,..N[δt−1(j)aij]⋅bi(yt)Θt(i)=arg⁡max⁡j[δt−1(j)aij] begin{aligned} delta_t(i) &amp; = displaystyle max_{j epsilon{1,..N}} Big[ delta_{t-1}(j)a_{ij} Big] cdot b_i(y_t) Theta_t(i) &amp; = arg max_j Big[ delta_{t-1}(j)a_{ij} Big] end{aligned}δt​(i)Θt​(i)​=jϵ1,..Nmax​[δt−1​(j)aij​]⋅bi​(yt​)=argjmax​[δt−1​(j)aij​]​ . Termination: . Retrieve the most likely final state . P^=max⁡jϵ1,..N[δT(j)]S^T=arg⁡max⁡j[δT(j)] begin{aligned} hat{P} &amp;= displaystyle max_{j epsilon{1,..N}}[ delta_T(j)] hat{S}_T &amp; = arg max_j [ delta_T(j)] end{aligned}P^S^T​​=jϵ1,..Nmax​[δT​(j)]=argjmax​[δT​(j)]​ . State sequence backtracking: . Retrieve the most likely state sequences (Viterbi path) . S^t=Θt+1(S^t+1), where t=T−1,T−2,…1 hat{S}_t = Theta_{t+1}( hat{S}_{t+1}) text{, where } t=T-1,T-2, ldots1S^t​=Θt+1​(S^t+1​), where t=T−1,T−2,…1 . The Viterbi algorithm uses the same schema as the Forward algorithm except for two differences: . It uses maximization in place of summation at the recursion and termination steps. | It keeps track of the arguments that maximize δt(i) delta_t(i)δt​(i) for each ttt and iii, storing them in the N by T matrix Θ ThetaΘ. This matrix is used to retrieve the optimal state sequence at the backtracking step. | Python implementation of virtebi algorithm . def viterbi(obs_seq): # returns the most likely state sequence given observed sequence x # using the Viterbi algorithm T = len(obs_seq) N = A.shape[0] delta = np.zeros((T, N)) psi = np.zeros((T, N)) delta[0] = pi*B[:,obs_seq[0]] for t in range(1, T): for j in range(N): delta[t,j] = np.max(delta[t-1]*A[:,j]) * B[j, obs_seq[t]] psi[t,j] = np.argmax(delta[t-1]*A[:,j]) # backtrack states = np.zeros(T, dtype=np.int32) states[T-1] = np.argmax(delta[T-1]) for t in range(T-2, -1, -1): states[t] = psi[t+1, states[t+1]] return states . To summarize, we can compute the following from HMM: . The marginalized likelihood function P(Y∣λ)P(Y mid lambda)P(Y∣λ) from the forward or backward algorithm. | The posterior probability γt(i)=P(st=i∣Y,λ) gamma_t(i) = P(s_t=i mid Y, lambda)γt​(i)=P(st​=i∣Y,λ) from the forward–backward algorithm. | The optimal state sequence S^=max⁡sP(S∣Y,λ)=max⁡sP(S,Y∣λ) hat{S} = max_{s} P(S mid Y, lambda) = max_{s} P(S, Y mid lambda)S^=maxs​P(S∣Y,λ)=maxs​P(S,Y∣λ)from the Viterbi algorithm. | The segmental joint likelihood function P(S^,Y∣λ)P( hat{S},Y mid lambda)P(S^,Y∣λ) from the Viterbi algorithm. | These values are used in the decoding step, and the training step of estimating model parameters λ lambdaλ. . Example 1 . Consider the Bob-Alice example as described here. Two friends, Alice and Bob, who live far apart and talk together daily over the telephone about what they did that day. Bob is only interested in three activities: walking in the park, shopping, and cleaning his apartment. The choice of what to do is determined exclusively by the weather on a given day. Alice has no specific information about the weather where Bob lives, but she knows general trends. Based on what Bob tells her he did each day, Alice tries to guess what the weather must have been. . Alice believes that the weather operates as a discrete Markov chain. There are two states, “Rainy” and “Sunny”, but she cannot observe them directly; that is, they are hidden from her. On each day, there is a pure chance that Bob will perform one of the following activities, depending on the weather: “walk”, “shop”, or “clean”. Since Bob tells Alice about his actions, those are the observations. . states = (&#39;Rainy&#39;, &#39;Sunny&#39;) observations = (&#39;walk&#39;, &#39;shop&#39;, &#39;clean&#39;) pi = np.array([0.6, 0.4]) #initial probability A = np.array([[0.7, 0.3],[0.4, 0.6]]) #Transmission probability B = np.array([[0.1, 0.4, 0.5],[0.6, 0.3, 0.1]]) #Emission probability . Suppose Bob says walk, clean, shop, shop, clean, walk. What will Alice hears. . bob_says = np.array([0, 2, 1, 1, 2, 0]) alice_hears=viterbi(bob_says) print(&quot;Bob says:&quot;, &quot;, &quot;,list(map(lambda y: observ_bob[y], bob_says))) print(&quot;Alice hears:&quot;, &quot;, &quot;, list(map(lambda s: states_bob[s], alice_hears))) . (&#39;Bob says:&#39;, &#39;walk, clean, shop, shop, clean, walk&#39;) (&#39;Alice hears:&#39;, &#39;Sunny, Rainy, Rainy, Rainy, Rainy, Sunny&#39;) The notebook with codes for the above example can be found in here . References . L. R. Rabiner, A tutorial on hidden Markov models and selected applications in speech recognition, Proceedings of the IEEE, Vol. 77, No. 2, February 1989. | Shinji Watanabe, Jen-Tzung Chien, Bayesian Speech and Language Processing, Cambridge University Press, 2015. | Viterbi Algorithm in Speech Enhancement and HMM | Nikolai Shokhirev, Hidden Markov Models |",
            "url": "/sambaiga/machine%20learning/2017/05/03/hmm-intro.html",
            "relUrl": "/machine%20learning/2017/05/03/hmm-intro.html",
            "date": " • May 3, 2017"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "Portfolio",
          "content": "I am a data scientist and machine learning researcher with over five years of successful experience in applying data science and machine learning techniques to practical problems. I am interested in using machine learning, deep learning, data science, and signal processing to develop computational models, methods, and tools to help industries, organisations and policymakers, design more effective solutions and policies for sustainable development. I hold a B.sc. Degree in Electronics Science and Communication from the University of Dar es Salaam, Tanzania (2009), and a M.sc. Degree in Telecommunications Engineering from the University of Dodoma, Tanzania, in 2012. . Since graduating in 2012, I have been working in research in both academia and industry. Between 2012 and 2017 I worked as an assistant lecturer at the University of Dodoma, Tanzania,where I was involved in a number of research projects within the context of ICT for development (ICT4D). In 2017, I joined IDLab, imec research group of the University of Ghent, in Belgium as a Machine learning researcher focusing on machine learning techniques applied to energy smart-meter data. I was also involved in the development of machine learning models that analyse data monitored from the internet of things (IoT) devices to detect and classify activities in the smart-homes environment. This opportunity has allowed me to drastically expand my research, data analytics, and machine learning skills. Since Feb 2020, I have been working with Dr. Lucas Pereira of Instituto Superior Técnicoon robust machine learning techniques for energy-systems and their value-proposition in smart-grid. . Presently, I am working as a Data Scientist and Machine learning researcher at CeADAR (UCD), Dublin, Ireland, where I devises and implement data analytics and Artificial Intelligence technical solutions for various application domains. I have recently completed a six-month research project that explores how Satellite imagery data can be combined with geospatial data to automate the process of generating training datasets for building AI models. During this time, I successfully led the team to develop a flexible end-to-end pipeline that combines satellite imagery and geo-referenced data to create annotated datasets and build machine learning models. I am also a key member of the CeADAR team working on the AIREO (AI-Ready Earth Observation training datasets) project in partnership with the European Space Agency (ESA) and ICHEC (Ireland’s Centre for High End Computing) to investigate specifications and best practices for developing Earth-Observation (EO) datasets for AI applications. Currently, I am leading a project on a partnership with utility companies in Ireland on Machine learning for Green Energy. The project aims to develop and test novel machine learning approaches to extract relevant insights from smart meter data and create value-added services that contribute to higher energy efficiency levels. . Although I am a person who takes the initiative, I enjoy working as part of a team. I possess a strong team-work spirit with experience of working in a highly international environment. I have good critical and creative thinking, problem-solving, leadership, and project management skills with excellent scientific writing and presentation skills. .",
          "url": "/sambaiga/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "Blogs",
          "content": "",
          "url": "/sambaiga/post/",
          "relUrl": "/post/",
          "date": ""
      }
      
  

  

  
      ,"page4": {
          "title": "Projects",
          "content": "Projects . Journal Papers and Proceedings . Machine Learning for Green Energy, Creating Value from Smart-meter Data. Description The rollout of smart meters is expected to produce significant energy consumption data at an unprecedented rate. Applying Machine Learning (ML) techniques to this massive data will enable the development of intelligent systems that convert energy metering data into easily understandable insights. This is likely to create value-added services to both consumers and utility companies and contribute to higher energy efficiency levels. This project&#39;s envisaged goal is to investigate, design, and validate data analytics and machine-learning techniques for smart-meter energy consumption data. AI-ready EO training datasets (AIREO) Dataset specifications and Best-practices Project link Description This project aim to establish community-driven dataset specifications, a collection of best-practices and a set of benchmark EO dataset for AI-ready training datasets (AIREO) for applications of AI in EO. It is a partnership between CeADAR, Irish Centre for High-End Computing (ICHEC) and the European Space Agency (ESA). AI for Earth Observation Description Machine learning-based computer vision models have been emerging as the primary tool to analyze and extract essential insights from Earth Observation (EO) imagery data. However, applying such models to EO imagery requires access to large annotated training datasets. Several recent studies have confirmed that existing geo-referenced data sources such as OpenStreetMap (OSM) can effectively be used as a source of ground truth for EO imagery data. Yet, integrating these geo-referenced annotation sources with EO data requires expertise in satellite imagery. On the other hand, building a computer vision model requires relevant machine learning skills, making it difficult for researchers, scientists, and companies to develop or test their use-cases without this blend of skills. This project aims to address this challenge by automating the process of creating and evaluating deep learning models for EO applications. The project&#39;s envisioned goal is to make it easy for companies and businesses without the extensive experience of developing AI models and EO for their specific use-cases. Specifically, the project investigates the possibility of generating an annotated dataset by leveraging satellite imagery and other geo-referenced data such as OSM. It further describes the process of how to apply deep learning models for object detection on EO imagery through experimentation. VIDEO Robust Machine learning methods for Non-Intrusive Load Monitoring (NILM) Description Energy use is in residential buildings is rapidly increasing across most parts of the world. This is the growing concern due to energy and sustainability challenges facing society. Therefore, there is a need for reducing energy consumption in residential buildings. Recently, large-scale deployments of smart meters have sparked the interest towards developing effective non-intrusive load monitoring (NILM) solutions for reducing energy consumption in buildings. NILM uses smart meter data to infer what end-appliances running in the building and estimate their respective power consumption. This project is expected to accomplish three main objectives: Investigate and develop robust feature representation for appliance recognition in NILM | Explore multilabel-learning for appliance recognition in NILM. | Develop end-to-end NILM and investigate its value propositions in smart-grid. | Adverse Reaction e-Reporting System (ADR) Description Through a user centered and agile software development methods, this project has developed an Adverse Reaction Reporting System (ADR). The ADR system provides features (mobile and web-based) for healthcare professionals and consumers to voluntarily report issues regarding quality of medical drugs, medication errors and adverse reactions. Furthermore the system allows TFDA to receive and perform causality assessment on the reported cases. The ADR system has also implemented the data exchange standard provided by the WHO to automate the submission of the ADR reports from TFDA to WHO. The ADR Reporting System can be downloaded at Google Play Store as [TFDA ADR Reporting Tool](https://play.google.com/store/apps/details?id=com.cive.HakikiDawaADR&amp;hl=en) and installed on android smart phone. The web-based application can be accessed at [here](http://www.tfda.go.tz/adr/). Applying Mobile Technology for Medical Drugs Verification in Tanzania Description Through the financial support of [Tanzania Communications Regulatory Authority (TCRA)](https://www.tcra.go.tz/), we embarked on a three-year research on Applying Mobile Technology for Drugs Verification in Tanzania. The main objective of the research was to design, develop, implement and support a mobile technology-based system to secure the Tanzanian health sector by enabling medical drugs verification. As one of the main output of the project, Drugs Verification System (DVS) prototype, which is a mobile technology-based system to track, trace and authenticate medical drugs, was developed and tested. DVS is a comprehensive system designed to secure pharmaceutical supply chain and enables: medical drugs consumers and other stakeholders of the pharmaceutical supply chain to perform medical drugs verification and access relevant information such as: health facility profiling and search, pharmacy maping and search, medical drug profile etc. It furher provides electronic tracking and tracing of medical drugs. This allows key stakeholders to more precisely track and trace drug products through the supply chain Water Resources Governance System (WaGoSy) Description The project developed innovative and integrated solutions for Governance of Water Resources within Lake Victoria Basin named as Water Resources Governance System (WaGoSy). WaGoSy is an integrated and innovative ICT system designed to enhance participation,transparency, accountability and awareness among LVB water resources stakeholders, which are typical indicators of good governance. The system provides effective, efficient and timely means for communication, knowledge creation. and sharing, reporting and feedback mechanisms. I lead the team that developed Wireless Sensors and Mobile Sensing Platform for Governance of Water Resources within Lake Victoria Basin. It consists of Water Quality Reporter (WaGoSy-WQR) which capture and send water quality data to a central database via mobile phones, WSN which gives the WaGoSy ability to test water quality parameters at selected sensitive sites continuously. Field testing of the system was conducted in Nkokonjero, Uganda and Mwanza, verified the functionalities of the system and its practical application in actual environment.",
          "url": "/sambaiga/projects/",
          "relUrl": "/projects/",
          "date": ""
      }
      
  

  
      ,"page5": {
          "title": "Publications",
          "content": "Publications . Journal Papers and Proceedings . Watt’s up at Home? Smart Meter Data Analytics from a Consumer-Centric Perspective A. Faustine, Völker, B.; Reinhardt, A.; Pereira, L. Energies 14(3),719 (2021) PDFLINK ABSTRACT The key advantage of smart meters over traditional metering devices is their ability to transfer consumption information to remote data processing systems. Besides enabling the automated collection of a customer’s electricity consumption for billing purposes, the data collected by these devices makes the realization of many novel use cases possible. However, the large majority of such services are tailored to improve the power grid’s operation as a whole. For example, forecasts of household energy consumption or photovoltaic production allow for improved power plant generation scheduling. Similarly, the detection of anomalous consumption patterns can indicate electricity theft and serve as a trigger for corresponding investigations. Even though customers can directly influence their electrical energy consumption, the range of use cases to the users’ benefit remains much smaller than those that benefit the grid in general. In this work, we thus review the range of services tailored to the needs of end-customers. By briefly discussing their technological foundations and their potential impact on future developments, we highlight the great potentials of utilizing smart meter data from a user-centric perspective. Several open research challenges in this domain, arising from the shortcomings of state-of-the-art data communication and processing methods, are furthermore given. We expect their investigation to lead to significant advancements in data processing services and ultimately raise the customer experience of operating smart meters. Adaptive Weighted Recurrence Graphs for Appliance Recognition in Non-Intrusive Load Monitoring A. Faustine, L. Pereira and C. Klemenjak IEEE Transactions on Smart Grid 1949-3061 (2021) PDFLINKCODE BIB ABSTRACT To this day, hyperparameter tuning remains a cumbersome task in Non-Intrusive Load Monitoring (NILM) research, as researchers and practitioners are forced to invest a considerable amount of time in this task. This paper proposes adaptive weighted recurrence graph blocks (AWRG) for appliance feature representation in event-based NILM. An AWRG block can be combined with traditional deep neural network architectures such as Convolutional Neural Networks for appliance recognition. Our approach transforms one cycle per activation current into an weighted recurrence graph and treats the associated hyper-parameters as learn-able parameters. We evaluate our technique on two energy datasets, the industrial dataset LILACD and the residential PLAID dataset. The outcome of our experiments shows that transforming current waveforms into weighted recurrence graphs provides a better feature representation and thus, improved classification results. It is concluded that our approach can guarantee uniqueness of appliance features, leading to enhanced generalisation abilities when compared to the widely researched V-I image features. Furthermore, we show that the initialisation parameters of the AWRG’s have a significant impact on the performance and training convergence. Leveraging Machine learning for Sustainable and Self-sufficient Energy Communities A. Faustine, L. Pereira, D. Ngondya, L. Benabbou NeurIPS 2020 Workshop Tackling Climate Change with Machine Learning 1949-3061 (2020) PDF BIB ABSTRACT Community Energies (CEs) are the next-generation energy management techniques that empowers citizens to interact with the energy market as self-consumers or prosumers actively. Successful implementation of CEs will promote sustainable energy production and consumption practices; thus, contributing to affordable and clean energy (SDG7) and climate action (SDG 13). Despite the potential of CEs, managing the overall power production and demand is challenging. This is because power is generated, distributed and controlled by several producers, each of which with different, and potentially conflicting, objectives. Thus, this project will investigate the role of machine learning approaches in smartening CEs, increasing energy awareness and enabling distributed energy resources planning and management. The project implementation will be centered around proof of concept development and capacity development in Africa. UNet-NILM: A Deep Neural Network for Multi-tasks Appliances State Detection and Power Estimation in NILM A. Faustine, L. Pereira H, Bousbiat and S. Kulkarni 5th International Workshop on Non-Intrusive Load Monitoring (NILM), co-located with ACM BuildSys 2020 and jointly organized with the EU NILM Workshop (2020) PDFLINKCODE BIB ABSTRACT Over the years, an enormous amount of research has been exploring Deep Neural Networks (DNN), particularly Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) for estimating the energy consumption of appliances from a single point source such as smart meters - Non-Intrusive Load Monitoring (NILM). However, most of the existing DNNs models for NILM use a single-task learning approach in which a neural network is trained exclusively for each appliance. This strategy is computationally expensive and ignores the fact that multiple appliances can be active simultaneously and dependencies between them. In this work, we propose UNet-NILM for multi-task appliances&#39; state detection and power estimation, applying a multi-label learning strategy and multi-target quantile regression. The UNet-NILM is a one-dimensional CNN based on the U-Net architecture initially proposed for image segmentation. Empirical evaluation on the UK-DALE dataset suggests promising performance against traditional single-task learning. Multi-Label Learning for Appliance Recognition in NILM Using Fryze-Current Decomposition and Convolutional Neural Network A. Faustine and L. Pereira Energies 13(16)-4154 (2020) PDFLINKCODE BIB ABSTRACT The advance in energy-sensing and smart-meter technologies have motivated the use of a Non-Intrusive Load Monitoring (NILM), a data-driven technique that recognizes active end-use appliances by analyzing the data streams coming from these devices. NILM offers an electricity consumption pattern of individual loads at consumer premises, which is crucial in the design of energy efficiency and energy demand management strategies in buildings. Appliance classification, also known as load identification is an essential sub-task for identifying the type and status of an unknown load from appliance features extracted from the aggregate power signal. Most of the existing work for appliance recognition in NILM uses a single-label learning strategy which, assumes only one appliance is active at a time. This assumption ignores the fact that multiple devices can be active simultaneously and requires a perfect event detector to recognize the appliance. In this paper proposes the Convolutional Neural Network (CNN)-based multi-label learning approach, which links multiple loads to an observed aggregate current signal. Our approach applies the Fryze power theory to decompose the current features into active and non-active components and use the Euclidean distance similarity function to transform the decomposed current into an image-like representation which, is used as input to the CNN. Experimental results suggest that the proposed approach is sufficient for recognizing multiple appliances from aggregated measurements. Improved Appliance Classification in Non-Intrusive Load Monitoring Using Weighted Recurrence Graph and Convolutional Neural Networks A. Faustine and L. Pereira Energies 13-3374 (2020) PDFLINKCODE BIB ABSTRACT Appliance recognition is one of the vital sub-tasks of NILM in which a machine learning classier is used to detect and recognize active appliances from power measurements. The performance of the appliance classifier highly depends on the signal features used to characterize the loads. Recently, different appliance features derived from the voltage–current (V–I) waveforms have been extensively used to describe appliances. However, the performance of V–I-based approaches is still unsatisfactory as it is still not distinctive enough to recognize devices that fall into the same category. Instead, we propose an appliance recognition method utilizing the recurrence graph (RG) technique and convolutional neural networks (CNNs). We introduce the weighted recurrent graph (WRG) generation that, given one-cycle current and voltage, produces an image-like representation with more values than the binary output created by RG. Experimental results on three different sub-metered datasets show that the proposed WRG-based image representation provides superior feature representation and, therefore, improves classification performance compared to V–I-based features. A Survey on Non-Intrusive Load Monitoring Methodies and Techniques for Energy Disaggregation Problem A. Faustine, N. Henry Mvungi, S. Kaijage, K. Michael arXiv preprint arXiv:1703.00785 (2017) PDFLINK BIB ABSTRACT The rapid urbanization of developing countries coupled with explosion in construction of high rising buildings and the high power usage in them calls for conservation and efficient energy program. Such a program require monitoring of end-use appliances energy consumption in real-time. The worldwide recent adoption of smart-meter in smart-grid, has led to the rise of Non-Intrusive Load Monitoring (NILM); which enables estimation of appliance-specific power consumption from building&#39;s aggregate power consumption reading. NILM provides households with cost-effective real-time monitoring of end-use appliances to help them understand their consumption pattern and become part and parcel of energy conservation strategy. This paper presents an up to date overview of NILM system and its associated methods and techniques for energy disaggregation problem. This is followed by the review of the state-of-the art NILM algorithms. Furthermore, we review several performance metrics used by NILM researcher to evaluate NILM algorithms and discuss existing benchmarking framework for direct comparison of the state of the art NILM algorithms. Finally, the paper discuss potential NILM use-cases, presents an overview of the public available dataset and highlight challenges and future research directions. Wireless Sensor Networks for Water Quality Monitoring and Control within Lake Victoria Basin: Prototype Development A. Faustine and A. Mvuma Wireless Sensor Network 6,12,281-290 (2015) PDFLINK BIB ABSTRACT The need for effective and efficient monitoring, evaluation and control of water quality in Lake Victoria Basin (LVB) has become more demanding in this era of urbanization, population growth and climate change and variability. Traditional methods that rely on collecting water samples, testing and analyses in water laboratories are not only costly but also lack capability for real-time data capture, analyses and fast dissemination of information to relevant stakeholders for making timely and informed decisions. In this paper, a Water Sensor Network (WSN) system prototype developed for water quality monitoring in LVB is presented. The development was preceded by evaluation of prevailing environment including availability of cellular network coverage at the site of operation. The system consists of an Arduino microcontroller, water quality sensors, and a wireless network connection module. It detects water temperature, dissolved oxygen, pH, and electrical conductivity in real-time and disseminates the information in graphical and tabular formats to relevant stakeholders through a web-based portal and mobile phone platforms. The experimental results show that the system has great prospect and can be used to operate in real world environment for optimum control and protection of water resources by providing key actors with relevant and timely information to facilitate quick action taking.",
          "url": "/sambaiga/publications/",
          "relUrl": "/publications/",
          "date": ""
      }
      
  

  
  

  
  

  

  
      ,"page9": {
          "title": "Talks",
          "content": "Talks . {% if site.data.conference_talks %} . Conference Presentation . {% for publi in site.data.conference_talks %} {{ publi.title }} {{ publi.authors | replace_first: &#39;A. Faustine&#39;, &#39;A. Faustine&#39;}} {{ publi.conf }} ({{ publi.year }}) {% if publi.url %} slides{% endif %} {% if publi.link %} link {% endif %} {% if publi.youtube %} video {% endif %} {% if publi.youtube %} {% endif %} | {% endfor %} . {% endif %} . {% if site.data.invited_talks %} . Invited Talks and Workshop . {% for publi in site.data.invited_talks %} {{ publi.title }} {{ publi.authors | replace_first: &#39;A. Faustine&#39;, &#39;A. Faustine&#39;}} {{ publi.conf }} ({{ publi.year }}) {% if publi.url %} slides{% endif %} {% if publi.link %} link {% endif %} {% if publi.youtube %} video {% endif %} {% if publi.youtube %} {% endif %} | {% endfor %} . {% endif %} .",
          "url": "/sambaiga/talks/",
          "relUrl": "/talks/",
          "date": ""
      }
      
  

  
  

  
  

  
  

  
      ,"page13": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "/sambaiga/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}