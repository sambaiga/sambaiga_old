{
  
    
        "post0": {
            "title": "Intro to Probabilistic Programming with Pyro",
            "content": "Intro to Pyro . Pyro is a universal probabilistic programming language (PPL) written in Python and supported by PyTorch on the backend. It enables flexible and expressive deep probabilistic modeling, unifying the best of modern deep learning and Bayesian modeling. . Models and Probability distributions . Models are the basic unit of probabilistic programs in pyro, they represent simplified or abstract descriptions of a process by which data are generated. Models in pyro are expressed as stochastic functions which implies that models can be composed, reused, imported, and serialized just like regular Python callables. Probability distributions (pimitive stochastic functions) are important class of models (stochastic functions) used explicitly to compute the probability of the outputs given the inputs. Pyro uses PyTorch‚Äôs distribution library which contains parameterizable probability distributions and sampling functions. This allows the construction of stochastic computation graphs and stochastic gradient estimators for optimization. Each probability distributions are equipped with several methods such as: . prob(): $ log p( mathbf{x} mid theta ^{*})$ | mean: $ mathbb{E}_{p( mathbf{x} mid theta ^{*})}[ mathbf{x}]$ | sample: $ mathbf{x}^{*} sim {p( mathbf{x} mid theta ^{*})}$ | . You can also create custom distributions using transforms. . Example 1: Let define the unit normal distribution $ mathcal{N}(0,1)$, draw sample $x$ and compute the log probability according to the distribution. . import torch import pyro import pyro.distributions as dist from torch.distributions import constraints import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns pyro.set_rng_seed(101) torch.manual_seed(101) torch.set_printoptions(precision=3) %matplotlib inline . mu = 0 sigma = 1 normal=dist.Normal(mu, sigma) x = normal.rsample() # draw a sample from N(1,1) print(&quot;sample&quot;, x.item()) #To compute the log probability according to the distribution print(&quot;prob&quot;, torch.exp(normal.log_prob(x)).item()) # score the sample from N(1,1) . sample -1.3905061483383179 prob 0.15172401070594788 . Sample and Param statements . Pyro simplifies the process of sampling from distributions with the use of pyro.sample statement. The pyro.sample statement call stochastic functions or models with a unique name as identifier. Pyro‚Äôs backend uses these names to uniquely identify sample statements and change their behavior at runtime depending on how the enclosing stochastic function is being used. Using pyro.sample statement, Pyro can implement various manipulations that underlie inference algorithms. . x = pyro.sample(&quot;name&quot;, fn, obs) &quot;&quot;&quot; name ‚Äì name of sample fn ‚Äì distribution class or function obs ‚Äì observed datum (optional; should only be used in context of inference) optionally specified in kwargs &quot;&quot;&quot; . Example 2: Let sample from previous normal distribution created in example 1. . mu = 0 sigma = 1 x = pyro.sample(&quot;my_sample&quot;, dist.Normal(mu, sigma)) print(x) . tensor(-0.815) . The above code generate a random value and records it in the Pyro runtime. . data=2 x = pyro.sample(&quot;my_sample&quot;, dist.Normal(mu, sigma), obs=data) print(x) . 2 . /opt/miniconda3/lib/python3.7/site-packages/pyro/primitives.py:86: RuntimeWarning: trying to observe a value outside of inference at my_sample RuntimeWarning) . The above code conditions a stochatsic function on observed data. This should run on inference. . Pyro use pyro.param statement to saves the variable as a parameter in the param store. To interact with the param store. The pyro.param statement is used by pyro to declares a learnable parameter. . x = pyro.param(&quot;name&quot;, init_value, constraints) &quot;&quot;&quot; name ‚Äì name of param init_value ‚Äì initial value constraint ‚Äì torch constraint &quot;&quot;&quot; . Example 3: Let create theta parameter . theta = pyro.param(&quot;theta&quot;, torch.tensor(1.0), constraint=dist.constraints.positive) . Simple PPL model . Consider the following Poison Regression model begin{align} y(t) &amp; sim lambda exp(- lambda) lambda &amp; sim exp(c + m(t)) c &amp; sim mathcal{N}(1, 1) m &amp; sim mathcal{N}(0, 1) end{align} . def model(y): slope = pyro.sample(&quot;slope&quot;, dist.Normal(0, 0.1)) intercept = pyro.sample(&quot;intercept&quot;, dist.Normal(0, 1)) for t in range(len(y)): rate = torch.exp(intercept + slope * t) y[t] = pyro.sample(&quot;count_{}&quot;.format(t), dist.Poisson(rate), obs=y[t]) return slope, intercept, y . Given a pyro model. We can . Generate data from model | Learn parameters of the model from data | Use the model to predict future observation. | Generate data from model . Running a Pyro model will generate a sample from the prior. . pyro.set_rng_seed(0) # We pass counts = [None, ..., None] to indicate time duration. true_slope, true_intercept, true_counts = model([None] * 50) fig, ax = plt.subplots(figsize=(6,4)) ax = sns.lineplot(x=np.arange(len(true_counts)),y=[c.item() for c in true_counts]) . Learn parameters of the model from data . To learn model parameters we pass the model to an inference algorithm and let the algorithm guess what the model is doing based on observed data. Inference algorithms in Pyro us arbitrary stochastic functions as approximate posterior distributions. that s. These functions are called guide functions or guides and contains pyro.sample and pyro.param statement. It is a stochastic function that represents a probability distribution over the latent (unobserved) variables. The guide can be arbitrary python code just like the model, but with a few requirements: . All unobserved sample statements that appear in the model appear in the guide. | The guide has the same input signature as the model (i.e. takes the same arguments). | There are no pyro.sample statements with the obs keyword in the guide. These are exclusive to the model. | There are pyro.param statements, which are exclusive to the guide. These provide differentiation for the inputs to the pay_probs sample in the guide vs. the model. | For example if the model contains a random variable z_1 . def model(): pyro.sample(&quot;z_1&quot;, ...) . then the guide needs to have a matching sample statement . def guide(): pyro.sample(&quot;z_1&quot;, ...) . Once a guide has been specified, we can then perform learning and inference which is an optimization problem of maximizing the evidence lower bound (ELBO). The ELBO, is a function of both $ theta$ and $ phi$, defined as an expectation w.r.t. to samples from the guide: . $${ rm ELBO} equiv mathbb{E}_{q_{ phi}({ bf z})} left [ log p_{ theta}({ bf x}, { bf z}) - log q_{ phi}({ bf z}) right]$$The SVI class is unified interface for stochastic variational inference in Pyro. To use this class you need to provide: . the model, | the guide, and an | optimizer which is a wrapper a for a PyTorch optimizer as discusseced in below | . from pyro.infer import SVI, Trace_ELBO svi = SVI(model, guide, optimizer, loss=Trace_ELBO()) . The SVI object provides two methods, step() and evaluate_loss(), . The method step() takes a single gradient step and returns an estimate of the loss (i.e. minus the ELBO). | The method evaluate_loss() returns an estimate of the loss without taking a gradient step. | . Both of these methods accept an optional argument: num_particles, which denotes the number of samples used to compute the loss and gradient. . The module pyro.optim provides support for optimization in Pyro. In particular it provides PyroOptim, which is used to wrap PyTorch optimizers and manage optimizers for dynamically generated parameters. PyroOptim takes two arguments: . a constructor for PyTorch optimizers optim_constructor and | a specification of the optimizer arguments optim_args | . from pyro.optim import Adam adam_params = {&quot;lr&quot;: 0.005, &quot;betas&quot;: (0.95, 0.999)} optimizer = Adam(adam_params) . Thus to learn model parameters we pass the model to an inference algorithm and let the algorithm guess what the model is doing based on observed data (here true_counts). . For the above example we will use Autoguide pyro inference algorithm: . AutoLaplaceApproximation:Laplace approximation (quadratic approximation) approximates the posterior logùëù(ùëß|ùë•) by a multivariate normal distribution in the unconstrained space. | Autodelta: This implementation of AutoGuide uses Delta distributions to construct a MAP guide over the entire latent space. | . from pyro.infer.autoguide import AutoDelta from pyro.infer import SVI, Trace_ELBO from pyro.optim import Adam guide = AutoDelta(model) svi = SVI(model, guide, Adam({&quot;lr&quot;: 0.1}), Trace_ELBO()) for i in range(101): loss = svi.step(true_counts) # true_counts is passed as argument to model() if i % 10 == 0: print(&quot;loss = {}&quot;.format(loss)) . loss = 87295.88946688175 loss = 64525.8595520854 loss = 80838.8460238576 loss = 33014.93229973316 loss = 13704.865498423576 loss = 6232.828522503376 loss = 2017.9879159331322 loss = 631.3558134436607 loss = 170.10323333740234 loss = 198.57187271118164 loss = 207.4590385556221 . print(&quot;true_slope = {}&quot;.format(true_slope)) print(&quot;true_intercept = {}&quot;.format(true_intercept)) guess = guide() print(&quot;guess = {}&quot;.format(guess)) . true_slope = 0.15409961342811584 true_intercept = -0.293428897857666 guess = {&#39;slope&#39;: tensor(0.147, grad_fn=&lt;ExpandBackward&gt;), &#39;intercept&#39;: tensor(-0.054, grad_fn=&lt;ExpandBackward&gt;)} . Use model to predict future observation . A third way to use a Pyro model is to predict new observed data by guiding the model. This uses two of Pyro&#39;s effects: . trace records guesses made by the guide, and | replay conditions the model on those guesses, allowing the model to generate conditional samples. | . Traces are directed graphs whose nodes represent primitive calls or input/output, and whose edges represent conditional dependence relationships between those primitive calls. It return a handler that records the inputs and outputs of primitive calls and their dependencies. . We can record its execution using trace and use the resulting data structure to compute the log-joint probability of all of the sample sites in the execution or extract all parameters. . trace = pyro.poutine.trace(model).get_trace([]) pprint({ name: { &#39;value&#39;: props[&#39;value&#39;], &#39;prob&#39;: props[&#39;fn&#39;].log_prob(props[&#39;value&#39;]).exp() } for (name, props) in trace.nodes.items() if props[&#39;type&#39;] == &#39;sample&#39; }) . {&#39;intercept&#39;: {&#39;prob&#39;: tensor(0.250), &#39;value&#39;: tensor(-0.966)}, &#39;slope&#39;: {&#39;prob&#39;: tensor(2.818), &#39;value&#39;: tensor(0.083)}} . print(trace.log_prob_sum().exp()) . tensor(0.705) . Here, the trace feature will collect values every time they are sampled with sample and store them with the corresponding string name (that‚Äôs why we give each sample a name). With a little cleanup, we can print out the value and probability of each random variable‚Äôs value, along with the joint probability of the entire trace. . Replay return a callable that runs the original, reusing the values at sites in trace at those sites in the new trace. makes sample statements behave as if they had sampled the values at the corresponding sites in the trace . from pyro import poutine def forecast(forecast_steps=10): counts = true_counts + [None] * forecast_steps # observed data + blanks to fill in guide_trace = poutine.trace(guide).get_trace(counts) _, _, counts = poutine.replay(model, guide_trace)(counts) return counts . We can now call forecast() multiple times to generate samples. . for _ in range(1): full_counts = forecast(10) forecast_counts = full_counts[len(true_counts):] plt.plot([c.item() for c in full_counts], &quot;r&quot;, label=None if _ else &quot;forecast&quot;, alpha=0.3) plt.plot([c.item() for c in true_counts], &quot;k-&quot;, label=&quot;truth&quot;) plt.legend(); . References . Pyro-ducomentation | PPL models for timeseries forecasting |",
            "url": "https://sambaiga.github.io/sambaiga/jupyter/2020/03/01/ppl-pyro-intro.html",
            "relUrl": "/jupyter/2020/03/01/ppl-pyro-intro.html",
            "date": " ‚Ä¢ Mar 1, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Introduction to Machine Learning",
            "content": "Machine Learning . Introduction . Machine learning is a set of algorithms that automatically detect patterns in data and use the uncovered pattern to make inferences or predictions. It is a subfield of artificial intelligence that aims to enable computers to learn on their own. Any machine learning algorithms involve the baisc three steps: first you identify pattern from data, then you build (train) model that best explain the pattern and the world (unseen data) and lastly use the model to predict or do inference. The process of training (building) a model can be seen as a learning process where the model is exposed to new, unfamiliar data step by step. . Machine learning is an exciting and fast-moving field of computer science with many recent applications. Important applications where machine learning algorithms are regularly deployed includes: . Computer vision: Object Classification in Photograph, image captioning. | Speech recognition, Automatic Machine Translation. | Detecting anomalies (e.g. Security, credit card fraud) | Speech recognition. | Communication systemsref | Robots learning complex behaviors | Recommendations services like in Amazo or Netflix where intelligent machine learning algorithms analyze your activity and compare it to the millions of other users to determine what you might like to buy or binge watch nextref. | . Machine learning algorithms that learn to recognise what they see and hear are at the heart of Apple, Google, Amazon, Facebook, Netflix, Microsoft, etc. . Why Machine learning . For many problems such as recognizing people and objects and understanding human speech it‚Äôs difcult to program the correct behavior by hand. However with machine learning these taks are easier. Other reasons we might want to use machine learning to solve a given problem: . A system might need to adapt to a changing environment. For instance, spammers are constantly trying to figure out ways to trick our e-mail spam classifers, so the classifcation algorithms will need to constantly adapt. | A learning algorithm might be able to perform better than its human programmers. Learning algorithms have become world champions at a variety of games, from checkers to chess to Go. This would be impossible if the programs were only doing what they were explicitly told to. | We may want an algorithm to behave autonomously for privacy or fairness reasons, such as with ranking search results or targeting ads. | . Types of Machine Learning . Machine learning is usually divide into three major types: Supervised Learning, Unspervised Learning and . Supervised Learning: Supervised learning is where you have input variables x and an output variable y and you use an algorithm to learn the mapping function from the input to the outputref. For instance, if we‚Äôre trying to train a machine leearning algorithm to distinguish cars and trucks, we would collect images of cars and trucks, and label each one as a car or a truck. Supervised learning problems can be further grouped into regression and classification problems. . A regression problem: is when the output variable is a real value, such as ‚Äúdollars‚Äù or ‚Äúweight‚Äù e.g Linear regression and Random forest. | Classification: A classification problem is when the output variable is a category, such as ‚Äúred‚Äù or ‚Äúblue‚Äù or ‚Äúdisease‚Äù and ‚Äúno disease‚Äù e.g Support vector machines, Random forest and logistic regression. Some popular examples of supervised machine learning algorithms are: | . Unspervised Learning :Unsupervised learning is where you only have input data (X) and no corresponding output variables.We just have a bunch of data, and want to look for patterns in the data. For instance, maybe we have lots of examples of patients with autism, and want to identify different subtypes of the condition.The most important types of unsupervised learning includes: . Distribution modeling where one has an unlabeled dataset (such as a collection of images or sentences), and the goal is to learn a probability distribution which matches the dataset as closely as possible. | Clustering where the aim is to discover the inherent groupings in the data, such as grouping customers by purchasing behavior. | . Reiforcement Learning: is learning best actions based on reward or punishment. It involves learning what actions to take in a given situation, based on rewards and penalties. Example a robot takes a big step forward, then falls. The next time, it takes a smaller step and is able to hold its balance. The robot tries variations like this many times; eventually, it learns the right size of steps to take and walks steadily. It has succeeded. . There are three basic concepts in reinforcement learning: state, action, and reward. The state describes the current situation. Action is what an agent can do in each state. When a robot takes an action in a state, it receives a reward, a feedback from the environment. A reward can be positive or negative (penalties). . Typical ML task: Linear Regression . In regression, we are interested in predicting a scalar-valued target, such as the price of a stock. By linear, we mean that the target must be predicted as a linear function of the inputs. This is a kind of supervised learning algorithm; recall that, in supervised learning, we have a collection of training examples labeled with the correct outputs. Example applications of linear regression include weather forecasting, house pricing prediction, student performance (GPA) prediction just to mention a few. . Linear Regression: Formulating a learning problem . In order to formulate a learning problem mathematically, we need to define two things: a model (hypothesis) and a loss function. After defining model and loss function we solve an optimisation problem with the aim to find the model parameters that best fit the data. . Model (Hypothesis) : It is the set of allowable hypotheses, or functions that compute predictions from the inputs. In the case of linear regression, the model simply consists of linear functions given by: . y=‚àëjwjxj+by = sum_j w_jx_j + by=j‚àë‚Äãwj‚Äãxj‚Äã+b . where $w$ is the weights, and $b$ is an intercept term, which we‚Äôll call the bias. These two terms are called model parameters denoted as $ theta$. . Loss function: It defines how well the model fit the data and thus show how far off the prediction $y$ is from the target $t$ and given as: . L(y,t)=12(y‚àít)2 mathcal{L(y,t)} = frac{1}{2}(y - t)^2L(y,t)=21‚Äã(y‚àít)2 . Since the loss function show how far off the prediction is from the target for one data point. We also need to define a cost function. The cost function is simply the loss, averaged over all the training examples. . J(w1‚Ä¶wD,b)=1N‚àëi=1NL(y(i),t(i))=12N‚àëi=1N(y(i)‚àít(i))2=12N‚àëi=1N(‚àëjwjxj(i)+b‚àít(i)) begin{aligned} J (w_1 ldots w_D,b) &amp; = frac{1}{N} sum_{i=1}^N mathcal{L}(y^{(i)},t^{(i)}) &amp; = frac{1}{2N} sum_{i=1}^N (y^{(i)} - t^{(i)})^2 &amp;= frac{1}{2N} sum_{i=1}^N left( sum_j w_jx_j^{(i)} + b -t^{(i)} right) end{aligned}J(w1‚Äã‚Ä¶wD‚Äã,b)‚Äã=N1‚Äãi=1‚àëN‚ÄãL(y(i),t(i))=2N1‚Äãi=1‚àëN‚Äã(y(i)‚àít(i))2=2N1‚Äãi=1‚àëN‚Äã(j‚àë‚Äãwj‚Äãxj(i)‚Äã+b‚àít(i))‚Äã . In vectorized form: . J=12N‚à•y‚àít‚à•2=12N(y‚àít)T(y‚àít)wherey=wTx mathbf{J} = frac{1}{2N} lVert mathbf{y-t} lVert^2 = frac{1}{2N} mathbf{(y - t)^T(y-t)} quad text{where} quad mathbf{y = w^Tx}J=2N1‚Äã‚à•y‚àít‚à•2=2N1‚Äã(y‚àít)T(y‚àít)wherey=wTx . The python implementation of the cost function (vectorized) is shown below. . def loss(x, w, t): N, D = np.shape(x) y = np.matmul(x,w.T) loss = (y - t) return loss def cost(x,w, t): &#39;&#39;&#39; Evaluate the cost function in a vectorized manner for inputs `x` and targets `t`, at weights `w1`, `w2` and `b`. &#39;&#39;&#39; N, D = np.shape(x) return (loss(x, w,t) **2).sum() / (2.0 * N) . Combine our model and loss function, we get an optimization problem, where we are trying to minimize a cost function with respect to the model parameters $ theta$ (i.e. the weights and bias). . Solving the optimization problem . We now want to find the choice of model parameters $ theta _{w_1 ldots w_D,b}$ that minimizes $J (w_1 ldots w_D,b)$ as given in the cost function above.There are two methods which we can use: direct solution and gradient descent. . Direct Solution . One way to compute the minimum of a function is to set the partial derivatives to zero.For simplicity, let‚Äôs assume the model doesn‚Äôt have a bias term as shown in the equation below. . JŒ∏=12N‚àëi=1N(‚àëjwjxj(i)‚àít(i))J_ theta = frac{1}{2N} sum_{i=1}^N left( sum_j w_jx_j^{(i)} -t^{(i)} right)JŒ∏‚Äã=2N1‚Äãi=1‚àëN‚Äã(j‚àë‚Äãwj‚Äãxj(i)‚Äã‚àít(i)) . In vectorized form . J=12N‚à•y‚àít‚à•212N(y‚àít)T(y‚àít)wherey=wx mathbf{J} = frac{1}{2N} lVert mathbf{y-t} rVert ^2 frac{1}{2N} mathbf{(y - t)^T(y-t)} quad text{where} quad mathbf{y = wx}J=2N1‚Äã‚à•y‚àít‚à•22N1‚Äã(y‚àít)T(y‚àít)wherey=wx . For matrix differentiation we need the following results: . ‚àÇAx‚àÇx=AT‚àÇ(xTAx)‚àÇx=2ATx begin{aligned} frac{ partial mathbf{Ax}}{ partial mathbf{x}} &amp; = mathbf{A}^T frac{ partial ( mathbf{x}^T mathbf{Ax})}{ partial mathbf{x}} &amp; = 2 mathbf{A}^T mathbf{x} end{aligned}‚àÇx‚àÇAx‚Äã‚Äã=AT‚àÇx‚àÇ(xTAx)‚Äã=2ATx‚Äã . Setting the partial derivatives of cost function in vectorized form to zero we obtain: . ‚àÇJ‚àÇw=12N‚àÇ(wTxTxw‚àí2tTwx+tTt)‚àÇw=12N(2xTxw‚àí2xTt)w=(xTx)‚àí1xTt begin{aligned} frac{ partial mathbf{J}}{ partial mathbf{w}} &amp; = frac{1}{2N} frac{ partial left( mathbf{w^Tx^Tx w} -2 mathbf{t^Twx} + mathbf{t^Tt} right)}{ partial mathbf{w}} &amp;= frac{1}{2N} left(2 mathbf{x}^T mathbf{xw} -2 mathbf{x}^T mathbf{t} right) mathbf{w} &amp;= ( mathbf{x^Tx})^{-1} mathbf{x^Tt} end{aligned}‚àÇw‚àÇJ‚Äãw‚Äã=2N1‚Äã‚àÇw‚àÇ(wTxTxw‚àí2tTwx+tTt)‚Äã=2N1‚Äã(2xTxw‚àí2xTt)=(xTx)‚àí1xTt‚Äã . In python this result can be implemented as follows: . def directMethod(x, t): &#39;&#39;&#39; Solve linear regression exactly. (fully vectorized) Given `x` - NxD matrix of inputs `t` - target outputs Returns the optimal weights as a D-dimensional vector &#39;&#39;&#39; N, D = np.shape(x) A = np.matmul(x.T, x) c = np.dot(x.T, t) return np.matmul(linalg.inv(A), c) . Gradient Descent . The optimization algorithm commonly used to train machine learning is the gradient descent algorithm. It works by taking the derivative of the cost function JJJ with respect to the parameters at a specific position on this cost function, and updates the parameters in the direction of the negative gradient. The entries of the gradient vector are simply the partial derivatives with respect to each of the variables: . ‚àÇJ‚àÇw=(‚àÇJ‚àÇw1‚ãÆ‚àÇJ‚àÇwD) frac{ partial mathbf{J}}{ partial mathbf{w}} = begin{pmatrix} frac{ partial J}{ partial w_1} vdots frac{ partial J}{ partial w_D} end{pmatrix}‚àÇw‚àÇJ‚Äã=‚éù‚éú‚éú‚éõ‚Äã‚àÇw1‚Äã‚àÇJ‚Äã‚ãÆ‚àÇwD‚Äã‚àÇJ‚Äã‚Äã‚é†‚éü‚éü‚éû‚Äã . The parameter $ mathbf{w}$ is iteratively updated by taking steps proportional to the negative of the gradient: . wt+1=wt‚àíŒ±‚àÇJ‚àÇw=wt‚àíŒ±NxT(y‚àít) mathbf{w_{t+1}} = mathbf{ w_t }- alpha frac{ partial mathbf{J}}{ partial mathbf{w}} = mathbf{w_t} - mathbf{ frac{ alpha}{N}x^T(y-t)}wt+1‚Äã=wt‚Äã‚àíŒ±‚àÇw‚àÇJ‚Äã=wt‚Äã‚àíNŒ±‚ÄãxT(y‚àít) . In coordinate systems this is equivalent to: . wt+1=wt‚àíŒ±1N‚àëi=1Nxt(y(i)‚àít(i))w_{t+1} = w_t - alpha frac{1}{N} sum_{i=1}^{N} x_t (y^{(i)}-t^{(i)})wt+1‚Äã=wt‚Äã‚àíŒ±N1‚Äãi=1‚àëN‚Äãxt‚Äã(y(i)‚àít(i)) . The python implementation of gradient descent is shown below: . def getGradient(x, w, t): N, D = np.shape(x) gradient = (1.0/ float(N)) * np.matmul(np.transpose(x), loss(x,w,t)) return gradient def gradientDescentMethod(x, t, alpha=0.1, tolerance=1e-2): N, D = np.shape(x) #w = np.random.randn(D) w = np.zeros([D]) # Perform Gradient Descent iterations = 1 w_cost = [(w, cost(x,w, t))] while True: dw = getGradient(x, w, t) w_k = w - alpha * dw w_cost.append((w, cost(x, w, t))) # Stopping Condition if np.sum(abs(w_k - w)) &lt; tolerance: print (&quot;Converged.&quot;) break if iterations % 100 == 0: print (&quot;Iteration: %d - cost: %.4f&quot; %(iterations, cost(x, w, t))) iterations += 1 w = w_k return w, w_cost . Generalization . The goal of a learning algorithm is not to only to make correct predictions on the training examples; but it should be generalized to examples not seen seen before. The average squared error on novel examples is known as the generalization error, and we‚Äôd like this to be as small as possible. In practice, we nor- mally tune model parameters by partitioning the dataset into three different subsets: . The training set is used to train the model. | The validation set is used to estimate the generalization error of each hyperparameter setting. | The test set is used at the very end, to estimate the generalization error of the final model, once all hyperparameters have been chosen. | .",
            "url": "https://sambaiga.github.io/sambaiga/machine/learning/2017/09/20/ml-intro.html",
            "relUrl": "/machine/learning/2017/09/20/ml-intro.html",
            "date": " ‚Ä¢ Sep 20, 2017"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": ". Anthony Faustine is a Data Scientist at CeADAR (UCD), Dublin, Ireland with over four years of successful experience in data analytics and Artificial Intelligence techniques for multiple applications. He effectively researches techniques for novel approaches to problems and develops prototypes to assess their viability. Although Anthony is a person who takes the initiative, he has a strong team-work spirit with experience of working in a highly international environment. . At CeADER, Anthony is devising and implementing data analytics/AI technical solutions for multiple application domains. He is also involved in the research and development of the applicability of Artificial Intelligence for Earth Observation (AI4EO). . Mr Faustine, received the B.sc. Degree in Electronics Science and Communication from the University of Dar es Salaam, Tanzania, and the M.sc. Degree in Telecommunications Engineering from the University of Dodoma, Tanzania, in 2010. From 2010 to 2017, he worked as an assistant lecturer at the University of Dodoma, Tanzania, where he was involved in several research projects within the context of ICT4D. . In 2017, Anthony joined IDLab, imec research group of the University of Ghent, in Belgium as a Ph.D. Machine learning researcher advised by Tom Dhaene and Dirk Deschrijver. His research focused on machine learning techniques applied to energy smart-meter data. He develops methods to identify active appliances and extract their corresponding power consumption from aggregate power (energy-disaggregation) in residential and industrial buildings. . His research interests lie in the intersections between Computational Sustainability and Artificial Intelligence. He works towards bridging the gap between laboratory and real-world applicability of machine learning for sustainable development. .",
          "url": "https://sambaiga.github.io/sambaiga/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}