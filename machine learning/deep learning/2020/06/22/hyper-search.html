<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <title>Super-charge Deep learning hyper-paramater search with Optuna | 
  sambaiga
</title>
  

  
  <meta name="description" content="
  
">
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Super-charge Deep learning hyper-paramater search with Optuna | sambaiga</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Super-charge Deep learning hyper-paramater search with Optuna" />
<meta name="author" content="Anthony Faustine" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Learn how to perform hyper-paramater search using Optuna" />
<meta property="og:description" content="Learn how to perform hyper-paramater search using Optuna" />
<link rel="canonical" href="https://sambaiga.github.io/sambaiga/machine%20learning/deep%20learning/2020/06/22/hyper-search.html" />
<meta property="og:url" content="https://sambaiga.github.io/sambaiga/machine%20learning/deep%20learning/2020/06/22/hyper-search.html" />
<meta property="og:site_name" content="sambaiga" />
<meta property="og:image" content="https://sambaiga.github.io/sambaiga/images/post/search.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-22T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Anthony Faustine"},"description":"Learn how to perform hyper-paramater search using Optuna","headline":"Super-charge Deep learning hyper-paramater search with Optuna","dateModified":"2020-06-22T00:00:00-05:00","datePublished":"2020-06-22T00:00:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://sambaiga.github.io/sambaiga/machine%20learning/deep%20learning/2020/06/22/hyper-search.html"},"image":"https://sambaiga.github.io/sambaiga/images/post/search.jpg","url":"https://sambaiga.github.io/sambaiga/machine%20learning/deep%20learning/2020/06/22/hyper-search.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/sambaiga/assets/css/style.css">
  <link rel="stylesheet" href="/sambaiga/assets/css/main.css">
  <link rel="canonical" href="https://sambaiga.github.io/sambaiga/machine%20learning/deep%20learning/2020/06/22/hyper-search.html"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Super-charge Deep learning hyper-paramater search with Optuna | sambaiga</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Super-charge Deep learning hyper-paramater search with Optuna" />
<meta name="author" content="Anthony Faustine" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Learn how to perform hyper-paramater search using Optuna" />
<meta property="og:description" content="Learn how to perform hyper-paramater search using Optuna" />
<link rel="canonical" href="https://sambaiga.github.io/sambaiga/machine%20learning/deep%20learning/2020/06/22/hyper-search.html" />
<meta property="og:url" content="https://sambaiga.github.io/sambaiga/machine%20learning/deep%20learning/2020/06/22/hyper-search.html" />
<meta property="og:site_name" content="sambaiga" />
<meta property="og:image" content="https://sambaiga.github.io/sambaiga/images/post/search.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-22T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Anthony Faustine"},"description":"Learn how to perform hyper-paramater search using Optuna","headline":"Super-charge Deep learning hyper-paramater search with Optuna","dateModified":"2020-06-22T00:00:00-05:00","datePublished":"2020-06-22T00:00:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://sambaiga.github.io/sambaiga/machine%20learning/deep%20learning/2020/06/22/hyper-search.html"},"image":"https://sambaiga.github.io/sambaiga/images/post/search.jpg","url":"https://sambaiga.github.io/sambaiga/machine%20learning/deep%20learning/2020/06/22/hyper-search.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/sambaiga/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://sambaiga.github.io/sambaiga/feed.xml" title="sambaiga" />

  

  

  

  <link rel="shortcut icon" type="image/x-icon" href="/sambaiga/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Super-charge Deep learning hyper-paramater search with Optuna | sambaiga</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Super-charge Deep learning hyper-paramater search with Optuna" />
<meta name="author" content="Anthony Faustine" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Learn how to perform hyper-paramater search using Optuna" />
<meta property="og:description" content="Learn how to perform hyper-paramater search using Optuna" />
<link rel="canonical" href="https://sambaiga.github.io/sambaiga/machine%20learning/deep%20learning/2020/06/22/hyper-search.html" />
<meta property="og:url" content="https://sambaiga.github.io/sambaiga/machine%20learning/deep%20learning/2020/06/22/hyper-search.html" />
<meta property="og:site_name" content="sambaiga" />
<meta property="og:image" content="https://sambaiga.github.io/sambaiga/images/post/search.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-22T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Anthony Faustine"},"description":"Learn how to perform hyper-paramater search using Optuna","headline":"Super-charge Deep learning hyper-paramater search with Optuna","dateModified":"2020-06-22T00:00:00-05:00","datePublished":"2020-06-22T00:00:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://sambaiga.github.io/sambaiga/machine%20learning/deep%20learning/2020/06/22/hyper-search.html"},"image":"https://sambaiga.github.io/sambaiga/images/post/search.jpg","url":"https://sambaiga.github.io/sambaiga/machine%20learning/deep%20learning/2020/06/22/hyper-search.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://sambaiga.github.io/sambaiga/feed.xml" title="sambaiga" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/sambaiga/">sambaiga</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/sambaiga/about/">About</a><a class="page-link" href="/sambaiga/project/">Projects</a><a class="page-link" href="/sambaiga/resources.html">Resources</a><a class="page-link" href="/sambaiga/search/">Search</a><a class="page-link" href="/sambaiga/categories/">Tags</a><a class="page-link" href="/sambaiga/talks/">Talk</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
   <div class="wrapper">
    <h1 class="post-title p-name" itemprop="name headline">Super-charge Deep learning hyper-paramater search with Optuna</h1><p class="page-description">Learn how to perform hyper-paramater search using Optuna</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-06-22T00:00:00-05:00" itemprop="datePublished">
        Jun 22, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Anthony Faustine</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/sambaiga/categories/#Machine learning">Machine learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/sambaiga/categories/#Deep learning">Deep learning</a>
        
      
      </p>
    

    </div>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h2 id="introduction">Introduction</h2>
<p>Training machine learning sometimes involves various hyperparameter settings. Performing a hyperparameter search is an integral element in building machine learning models. It consists of attuning different sets of parameters to find the best settings for best model performance. It should be remarked that deep neural networks can involve many hyperparameter settings. Getting the best set parameters for such a high dimensional space might a challenging task. Opportunely, different strategies and tools can be used to simplify the process. This post will guide you on how to use Optuna for a hyper-parameter search using <a href="https://pytorch.org/">PyTorch</a> and <a href="https://github.com/PyTorchLightning/pytorch-lightning">PyTorch lightning</a> framework.
The notebook with all the code for this post can be found on this <a href="https://colab.research.google.com/drive/1QVST56bq3zNyIYx9595HVcq5fwFNH44x?usp=sharing">colab link</a>.</p>

<h3 id="optuna">Optuna</h3>
<p><a href="https://optuna.org/">Optuna</a> is an open-source hyperparameter optimization framework. It automates the process of searching for optimal hyperparameter using Python conditionals, loops, and syntax. The optuna library offers efficiently hyper-parameter search in large spaces while pruning unpromising trials for faster results. It is also possible to run a hyperparameter search over multiple processes without modifying code.
For a brief introduction of optuna, you can watch this video</p>

<center>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/J_aymk4YXhg" frameborder="0" allowfullscreen=""></iframe>
</center>

<p>The optuna optimization problem consists of three main building blocks; <strong>objective function</strong>, <strong>trial</strong>, and <strong>study</strong>. Let consider a simple optimisation problem: <em>Suppose a rectangular garden is to be constructed using a rock wall as one side of the garden and wire fencing for the other three sides as shown in figure below (taken from this <a href="https://math.libretexts.org/Bookshelves/Calculus/Map%3A_Calculus_-_Early_Transcendentals_(Stewart)/04%3A_Applications_of_Differentiation/4.07%3A_Optimization_Problems">link</a>). Given 500m of wire fencing, determine the dimensions that would create a garden of maximum area. What is the maximum area?</em>
<img src="/sambaiga/images/optuna/optuna_one.png" alt="" /></p>

<p>Let $x$ denote the side of the garden’s side perpendicular to the rock wall, and $y$ indicates the side parallel to the rock wall. Then the area of the garden $A= x \cdot y$. We want to find the maximum possible area subject to the constraint that the total fencing is 500m. The total amount of fencing used will be $2x+y$. Therefore, the constraint equation is 
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mn>500</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>2</mn><mi>x</mi><mo>+</mo><mi>y</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>y</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>500</mn><mo>−</mo><mn>2</mn><mi>x</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>A</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>x</mi><mo>⋅</mo><mo stretchy="false">(</mo><mn>500</mn><mo>−</mo><mn>2</mn><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mn>500</mn><mi>x</mi><mo>−</mo><mn>2</mn><msup><mi>x</mi><mn>2</mn></msup></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
500 &amp; = 2x +y \\
y &amp; = 500-2x\\
A(x) &amp;= x \cdot (500-2x) = 500x - 2x^2
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.524108em;vertical-align:-2.012054em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.512054em;"><span style="top:-4.672054em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">5</span><span class="mord">0</span><span class="mord">0</span></span></span><span style="top:-3.1720539999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-1.6479460000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">A</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.012054em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.512054em;"><span style="top:-4.672054em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">2</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3.1720539999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">5</span><span class="mord">0</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">2</span><span class="mord mathdefault">x</span></span></span><span style="top:-1.6479460000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">5</span><span class="mord">0</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">2</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">5</span><span class="mord">0</span><span class="mord">0</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">2</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.012054em;"><span></span></span></span></span></span></span></span></span></span></span></p>

<p>From equation above, $A(x) = 500x - 2x^2$ is an <strong>objective function</strong>, the function to be optimized. To maximize this function, we need to determine optimization constraints. We know that to construct a rectangular garden, we certainly need the lengths of both sides to be positive $y&gt;0$, and $x&gt;0$. Since $500 = 2x +y$ and $y&gt;0$ then $x&lt;250$. Therefore, we will try to determine the maximum value of A(x) for x over the open interval (0,50).</p>

<p>Optuna <a href="https://optuna.readthedocs.io/en/stable/reference/trial.html"><strong>trial</strong></a> corresponds to a single execution of the <strong>objective function</strong> and is internally instantiated upon each invocation of the function. 
To obtain the parameters for each trial within a provided <em>constraints</em> the [<strong>suggest</strong>] method (https://optuna.readthedocs.io/en/stable/reference/trial.html) is used.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trial</span><span class="o">.</span><span class="n">suggest_uniform</span><span class="p">(</span><span class="s">'x'</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">250</span><span class="p">)</span>
</code></pre></div></div>

<p>We can now code the objective function that be optimized for our problem.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gardent_area</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
 <span class="n">x</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_uniform</span><span class="p">(</span><span class="s">'x'</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">250</span><span class="p">)</span>
 <span class="k">return</span> <span class="p">(</span><span class="mi">500</span><span class="o">*</span><span class="n">x</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span> 
</code></pre></div></div>

<p>Once the objective function has been defined, the <a href="">study object</a> is used to start the optimization.  The <strong>study</strong> is an optimization session, a set of trials. Optuna provide different <a href="https://optuna.readthedocs.io/en/latest/reference/samplers.html">sampler strategies</a> such as Random Sampler and <a href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf">Tree-structured Parzen Estimator (TPE)</a> sampler. A sampler has the responsibility to determine the parameter values to be evaluated in a trial. By default, Optuna uses <a href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf">TPE</a> sampler, which is a form of Bayesian Optimization. The TPE provides a more efficient search than a random sampler search by choosing points closer to past good results. It possible to add a custom sampler as described in this <a href="https://optuna.readthedocs.io/en/latest/tutorial/sampler.html#overview-of-sampler">link</a>
We can now create a study and start the optimization process.</p>
<noscript><pre>400: Invalid request</pre></noscript>
<script src="https://gist.github.com/4975107146ea19cf0dff730516c1f933.js"> </script>

<p>Once the study is completed, you can get the best parameters using <code class="highlighter-rouge">study.best_params</code> and <code class="highlighter-rouge">study.best_value</code> will give you the best value.</p>

<h2 id="hyper-param-search-for-deep-neural-net">Hyper-param search for deep neural net</h2>

<p>Suppose we want to build MLP classifier to recognize handwritten digits using the MNIST dataset. We will first build a pytorch MLP model with the following default parameters</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hparams</span> <span class="o">=</span> <span class="p">{</span><span class="s">"in_size"</span><span class="p">:</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="s">"hidden_size"</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span> <span class="s">"out_size"</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span> <span class="s">"layer_size"</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="s">"dropout"</span><span class="p">:</span><span class="mf">0.2</span><span class="p">}</span>
</code></pre></div></div>
<noscript><pre>400: Invalid request</pre></noscript>
<script src="https://gist.github.com/1056337e11a4887008a5b95d0f12a026.js"> </script>

<p>For the above MLP model, we need to specify the following parameters <em>hidden size, dropout, and number of linear layers</em>. The critical question is, how do we pick these parameters. We will use optuna to search for optimal parameters that will give us an excellent performance. First, we will create a PyTorch lightning model that will provide the structure for organizing the fundamentals component of any machine learning project. These elements include the data, architecture or model, optimizer, loss function, training, and evaluation step. Since we fine defined our MLP, we go ahead and create a PyTorch lightning module.
The complete code with all the component mentioned above can be found on <a href="https://gist.github.com/sambaiga/b835ab905d0b8199a859eae2ff7adfe6">gist link</a>
To learn the parameters of the MLP we will use Stochastic Gradient Descent Optimizer (SGD)  optimizer. The SGD has several other hper-parameters such as learning rate just we can also optimize.</p>
<pre><code class="language-pyhon"> optimizer = torch.optim.SGD(self.model.parameters(), 
 lr=self.hparams['learning_rate'], 
 momentum=self.hparams['momentum'], 
 nesterov=self.hparams['nesterov'],
 weight_decay=self.hparams['weight_decay']) 
</code></pre>

<p>Thus the SGD optimizer will add four additional parameters. We can also treat the batch size as hyper-parameter to optimize. We will have the following set of parameters to optimizers.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">default_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">"in_size"</span><span class="p">:</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="s">"hidden_size"</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span> <span class="s">"out_size"</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span> 
 <span class="s">"layer_size"</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="s">"dropout"</span><span class="p">:</span><span class="mf">0.2</span><span class="p">,</span> <span class="s">"batch_size"</span><span class="p">:</span><span class="mi">32</span><span class="p">,</span>
 <span class="s">'learning_rate'</span><span class="p">:</span><span class="mf">1e-3</span><span class="p">,</span> <span class="s">'momentum'</span><span class="p">:</span><span class="mf">0.9</span><span class="p">,</span> <span class="s">'nesterov'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
 <span class="s">'weight_decay'</span><span class="p">:</span><span class="mf">1e-5</span><span class="p">,</span>
 <span class="s">'epochs'</span><span class="p">:</span><span class="mi">2</span><span class="p">}</span>
</code></pre></div></div>

<h3 id="defining-the-hyperparameters-and-objective-function-to-be-optimized">Defining the hyperparameters and objective function to be optimized</h3>
<p>Since we know all the parameters that we want to optimize, we will use the optuna <strong>suggest</strong> to define a search space for each hyperparameter that we want to tune. Optuna supports a variety of suggests which can be used to optimize floats, integers, or discrete categorical values. Numerical values such as learning rate can be suggested using a logarithmic scale.</p>
<noscript><pre>400: Invalid request</pre></noscript>
<script src="https://gist.github.com/b0c5dfe55d15cbdf2fc1983132a5ee03.js"> </script>

<p>To create an objective function, we use the trainer module within PyTorch lightning with the default TensorBoard logger. The trainer will return the validation score. Optuna will use this score to evaluate the performance of the hyperparameters and decide where to sample in upcoming trials.
In addition to sampling strategies, Optuna provides a mechanism to automatically stops unpromising trials at the early stages of the training. This allows computing time to be used for tests that show more potential. This feature is called <a href="https://optuna.readthedocs.io/en/stable/tutorial/pruning.html"><strong>pruning</strong></a>, and it is a form of automated early-stopping. The <a href="https://optuna.readthedocs.io/en/stable/reference/integration.html">PyTorchLightingPruningCallBack</a> provides integration Optuna pruning  function to PyTorch lightning</p>

<noscript><pre>400: Invalid request</pre></noscript>
<script src="https://gist.github.com/64c756606d04c1ab2f300f6b0ae9236d.js"> </script>

<p>To start the optimization, we create a study object and pass the objective function to method optimize() as follows.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">run_study</span><span class="p">(</span><span class="n">num_trials</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
 <span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s">'maximize'</span><span class="p">)</span>
 <span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="n">num_trials</span><span class="p">)</span>
 <span class="k">return</span> <span class="n">study</span>
</code></pre></div></div>

<p>After the study is completed, we can export trials as a pandas data frame. This provides various features to analyze studies. It is also useful to draw a histogram of objective values and to export trials as a CSV file.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">study</span><span class="o">.</span><span class="n">trials_dataframe</span><span class="p">()</span>
</code></pre></div></div>

<p>The notebook with all the code for this post can be found on this <a href="https://colab.research.google.com/drive/1QVST56bq3zNyIYx9595HVcq5fwFNH44x?usp=sharing">colab link</a></p>
<h2 id="references">References</h2>

<ul>
  <li><a href="https://medium.com/optuna/using-optuna-to-optimize-pytorch-lightning-hyperparameters-d9e04a481585">Using Optuna to Optimize PyTorch Lightning Hyperparameters</a></li>
  <li><a href="https://optuna.readthedocs.io/en/stable/index.html">Optuna documentation</a></li>
  <li><a href="https://github.com/optuna/optuna/blob/master/examples/pytorch_lightning_simple.py">Pytorch-lightning example</a></li>
</ul>


  </div><a class="u-url" href="/sambaiga/machine%20learning/deep%20learning/2020/06/22/hyper-search.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer">

  <div class="wrapper">
<div class="wrapper">
     Copyright 2020 
    
    
    : sambaiga@gmail.com
  </div>

  </div>
</footer>


<script src="/assets/js/katex_init.js"></script>


<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>
<script src="/assets/js/common.js"></script>

<script>
  $("script[type='math/tex']").replaceWith(function() {
      var tex = $(this).text();
      return katex.renderToString(tex.replace(/%.*/g, ''), {displayMode: false});
  });

  $("script[type='math/tex; mode=display']").replaceWith(function() {
      var tex = $(this).html();
      return katex.renderToString(tex.replace(/%.*/g, ''), {displayMode: true});
  });
</script>


</body>

</html>
