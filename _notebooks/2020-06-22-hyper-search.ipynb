{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super-charge hyper-paramater search with Optuna\n",
    "> Learn how to perform hyper-paramater search using Optuna\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Anthony Faustine\n",
    "- show_tags: true\n",
    "- categories: [Machine learning, Deep learning]\n",
    "- image: images/post/search.jpg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Training machine learning sometimes involves various hyperparameter settings. Performing a hyperparameter search is an integral element in building machine learning models. It consists of attuning different sets of parameters to find the best settings for excellent model performance. It should be remarked that deep neural networks can involve many hyperparameter settings. Getting the best set parameters for such a high dimensional space might a challenging task. Opportunely, different strategies and tools can be used to simplify the process. This post will guide you on how to use Optuna for a hyper-parameter search using [PyTorch](https://pytorch.org/) and [PyTorch lightning](https://github.com/PyTorchLightning/pytorch-lightning) framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install these packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "pip install -U optuna\n",
    "pip install -U torch torchvision\n",
    "pip install -U pytorch-lightning\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Optuna\n",
    "[Optuna](https://optuna.org/) is an open-source hyperparameter optimization framework.  It automates the process of searching for optimal hyperparameter using Python conditionals, loops, and syntax. The optuna library offers efficiently hyper-parameter search in large spaces while pruning unpromising trials for faster results. Using optuna it is possible to parallelize hyperparameter searches over multiple threads or processes without modifying code.\n",
    "The optuna optimization problem consists of three main building blocks; **objective function**, **trial** and **study**. Let consider a simple optimisation problem: *Suppose a rectangular garden is to be constructed using a rock wall as one side of the garden and wire fencing for the other three sides as shown in figure belwo. Given  500m of wire fencing, determine the dimensions that would create a garden of maximum area. What is the maximum area?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let  $x$ denote the length of the side of the garden perpendicular to the rock wall and  $y$  denote the length of the side parallel to the rock wall. Then the area of the garden $A= x \\cdot y$. We want to find the maximum possible area subject to the constraint that the total fencing is 500m. The total amount of fencing used will be  $2x+y$.  Therefore, the constraint equation is \n",
    "\\begin{align}\n",
    "500 & = 2x +y \\\\\n",
    "y  & = 500-2x\\\\\n",
    "A(x) &= x \\cdot (500-2x) =  500x - 2x^2\n",
    "\\end{align}\n",
    "\n",
    "From equation above, $A(x) = 500x - 2x^2$ is an **objective function**, the function to be optimized. To maximize this function, we need to determine optimization constraints. We know that to construct a rectangular garden, we certainly need the lengths of both sides to be positive $y>0$, and  $x>0$. Since $500  = 2x +y$ and $y>0$ then $x<250$. Therefore, we will try to determine the maximum value of A(x) for x over the open interval (0,50).\n",
    "\n",
    "Optuna [**trial**](https://optuna.readthedocs.io/en/stable/reference/trial.html)  corresponds to a single execution of the **objective function** and is internally instantiated upon each invocation of the function. To obtain the parameters for each trial within a provided *contsrtainst* the [**suggest**](https://optuna.readthedocs.io/en/stable/reference/trial.html) is used. \n",
    "\n",
    "```python\n",
    "trial.suggest_uniform('x', 0, 250)\n",
    "```\n",
    "\n",
    "We can now code the objective function that be optimized for our problem.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gardent_area(trial):\n",
    "    x = trial.suggest_uniform('x', 0, 250)\n",
    "    return (500*x - 2*x**2 ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Once the objective function has been defined, the [**study object**]() is used to start the optimization. Thus optuna **trial** is a single call of the objective function whereas **study** is  an optimization session, which is a set of trials. We can now create a study and start the optimisation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-06-21 09:21:59,460]\u001b[0m Finished trial#0 with value: 30192.883232182987 with parameters: {'x': 102.00960235427611}. Best is trial#0 with value: 30192.883232182987.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:21:59,525]\u001b[0m Finished trial#1 with value: 11665.34358605057 with parameters: {'x': 223.956193373506}. Best is trial#0 with value: 30192.883232182987.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:21:59,587]\u001b[0m Finished trial#2 with value: 29967.46342643536 with parameters: {'x': 150.32327559345987}. Best is trial#0 with value: 30192.883232182987.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:21:59,670]\u001b[0m Finished trial#3 with value: 30132.313125645393 with parameters: {'x': 148.63986965229094}. Best is trial#0 with value: 30192.883232182987.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:21:59,731]\u001b[0m Finished trial#4 with value: 26891.79238720805 with parameters: {'x': 171.68087195410956}. Best is trial#0 with value: 30192.883232182987.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:21:59,791]\u001b[0m Finished trial#5 with value: 25917.313521440778 with parameters: {'x': 73.36335371773636}. Best is trial#0 with value: 30192.883232182987.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:21:59,848]\u001b[0m Finished trial#6 with value: 30918.40566786742 with parameters: {'x': 112.12377516248301}. Best is trial#6 with value: 30918.40566786742.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:21:59,937]\u001b[0m Finished trial#7 with value: 30464.28049218819 with parameters: {'x': 105.17930995384103}. Best is trial#6 with value: 30918.40566786742.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:21:59,984]\u001b[0m Finished trial#8 with value: 10359.360983968212 with parameters: {'x': 22.79765409729631}. Best is trial#6 with value: 30918.40566786742.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:22:00,050]\u001b[0m Finished trial#9 with value: 30362.939942726232 with parameters: {'x': 103.9398473738464}. Best is trial#6 with value: 30918.40566786742.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:22:00,120]\u001b[0m Finished trial#10 with value: 1948.2286498883193 with parameters: {'x': 3.959156996260802}. Best is trial#6 with value: 30918.40566786742.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:22:00,195]\u001b[0m Finished trial#11 with value: 22169.977206566673 with parameters: {'x': 57.62039331729025}. Best is trial#6 with value: 30918.40566786742.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:22:00,259]\u001b[0m Finished trial#12 with value: 22518.027165398147 with parameters: {'x': 191.07561136532092}. Best is trial#6 with value: 30918.40566786742.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:22:00,323]\u001b[0m Finished trial#13 with value: 22596.755353896893 with parameters: {'x': 59.22293467285459}. Best is trial#6 with value: 30918.40566786742.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:22:00,376]\u001b[0m Finished trial#14 with value: 31135.23373151821 with parameters: {'x': 117.42483437534882}. Best is trial#14 with value: 31135.23373151821.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:22:00,413]\u001b[0m Finished trial#15 with value: 30565.092057209593 with parameters: {'x': 143.50551191929594}. Best is trial#14 with value: 31135.23373151821.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:22:00,476]\u001b[0m Finished trial#16 with value: 18976.533391319535 with parameters: {'x': 203.33730467880696}. Best is trial#14 with value: 31135.23373151821.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:22:00,553]\u001b[0m Finished trial#17 with value: 31248.552104334674 with parameters: {'x': 125.85085124003193}. Best is trial#17 with value: 31248.552104334674.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:22:00,590]\u001b[0m Finished trial#18 with value: 26334.324397390694 with parameters: {'x': 75.42341478777855}. Best is trial#17 with value: 31248.552104334674.\u001b[0m\n",
      "\u001b[32m[I 2020-06-21 09:22:00,648]\u001b[0m Finished trial#19 with value: 31134.297753574312 with parameters: {'x': 132.60599258564204}. Best is trial#17 with value: 31248.552104334674.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "study = optuna.create_study(study_name=\"garden\", direction=\"maximize\")\n",
    "study.optimize(gardent_area, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Once the study is completed you can get the best parameters as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 125.85085124003193}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31248.552104334674"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-param search for  deep neural net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP model\n",
    "\n",
    "Suppose we want to build MLP classifier to recognize handwritten digits using the MNIST dataset. We will first build a pytorch MLP model with the following default parameters\n",
    "```python\n",
    "hparams = {\"in_size\": 28*28, \"hidden_size\":128, \"out_size\":10, \"layer_size\":5, \"dropout\":0.2}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        layers = [hparams['in_size'], hparams['hidden_size']]+[hparams['hidden_size']*2**i  for i in range(hparams['layer_size']-1)] \n",
    "        self.layers = []\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            layer = nn.Linear(layers[i], layers[i+1])\n",
    "            self.layers.append(layer) \n",
    "            self.layers.append(nn.ReLU())\n",
    "            if i!=0:\n",
    "                self.layers.append(nn.Dropout(hparams['dropout']))\n",
    "                \n",
    "        out_layer = nn.Linear(layers[-1], hparams['out_size'])\n",
    "        self.layers.append(out_layer)\n",
    "        \n",
    "        ##initilize weights\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "        self.mlp =  nn.Sequential(*self.layers)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.2, inplace=False)\n",
       "    (5): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Dropout(p=0.2, inplace=False)\n",
       "    (11): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (12): ReLU()\n",
       "    (13): Dropout(p=0.2, inplace=False)\n",
       "    (14): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = {\"in_size\": 28*28, \"hidden_size\":128, \"out_size\":10, \"layer_size\":5, \"dropout\":0.2}\n",
    "model = MLP(hparams)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch lightning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key question is how do we pick these parameters. We will use optuna to search optimal parameters that will give us good performance. First we will create a pytorch lightning model which will provides the structure on how to organize the fundamemtal component of any machine learning project. These elements include the arcnitecture or model, data (train, val and test set), model building (train and val step) and evalutaion (test-step). Since we fine defined our MLP, we go ahead and define the data that we will use for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "import pytorch_lightning as pl\n",
    "import  pytorch_lightning.metrics.functional as metrics\n",
    "\n",
    "class MLPIL(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        self.model = MLP(hparams)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x.flatten(1, 3))\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc  = metrics.accuracy(torch.max(logits, 1)[1], y)\n",
    "        \n",
    "        logs = {'loss': loss, \"tra_acc\":acc}\n",
    "        return {'loss': loss, 'log': logs}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x.flatten(1, 3))\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc  = metrics.accuracy(torch.max(logits, 1)[1], y)\n",
    "        \n",
    "        logs = {'val_loss': loss, \"val_acc\":acc}\n",
    "        return logs\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        logs = {'avg_val_loss': avg_loss, \"avg_val_acc\":avg_acc}\n",
    "        return {'val_loss': avg_loss, 'val_acc':avg_acc, 'log': logs}\n",
    "\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        # REQUIRED\n",
    "        return DataLoader(MNIST(os.getcwd(), train=True, download=True, \n",
    "                                transform=transforms.ToTensor()), \n",
    "                                batch_size=self.hparams[\"batch_size\"])\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(MNIST(os.getcwd(), train=True, download=True, \n",
    "                                transform=transforms.ToTensor()),\n",
    "                                batch_size=self.hparams[\"batch_size\"])\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        optimizer =  torch.optim.SGD(self.model.parameters(), \n",
    "                                         lr=self.hparams['learning_rate'], \n",
    "                                         momentum=self.hparams['momentum'], \n",
    "                                         nesterov=self.hparams['nesterov'],\n",
    "                                         weight_decay=self.hparams['weight_decay'])    \n",
    "        \n",
    "        return optimizer\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictLogger(pl.loggers.TensorBoardLogger):\n",
    "    \"\"\"PyTorch Lightning `dict` logger.\"\"\"\n",
    "    # see https://github.com/PyTorchLightning/pytorch-lightning/blob/50881c0b31/pytorch_lightning/logging/base.py\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.metrics = [] \n",
    "\n",
    "    def log_metrics(self, metrics, step=None):\n",
    "        super().log_metrics(metrics, step=step)\n",
    "        self.metrics.append(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now run `tensorboard --logdir /Users/sambaiga/Documents/sambaiga/_notebooks/MLP\n"
     ]
    }
   ],
   "source": [
    "## Prepare directory\n",
    "from pathlib import Path\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "DIR = Path(os.getcwd())\n",
    "MODEL_DIR = DIR/ \"MLP\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"now run `tensorboard --logdir {MODEL_DIR}\")\n",
    "\n",
    "class DictLogger(pl.loggers.TensorBoardLogger):\n",
    "    \"\"\"PyTorch Lightning `dict` logger.\"\"\"\n",
    "    # see https://github.com/PyTorchLightning/pytorch-lightning/blob/50881c0b31/pytorch_lightning/logging/base.py\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.metrics = [] \n",
    "\n",
    "    def log_metrics(self, metrics, step=None):\n",
    "        super().log_metrics(metrics, step=step)\n",
    "        self.metrics.append(metrics)\n",
    "\n",
    "default_params = {\"in_size\": 28*28, \"hidden_size\":128, \"out_size\":10, \n",
    "           \"layer_size\":5, \"dropout\":0.2, \"batch_size\":32,\n",
    "          'learning_rate':1e-3, 'momentum':0.9, 'nesterov': True,\n",
    "          'weight_decay':1e-5,\n",
    "          'epochs':50}\n",
    "\n",
    "def objective(trial=None):\n",
    "    \n",
    "    if trial is not None:\n",
    "        lr_param = {'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)}\n",
    "        default_params.update(lr_param)\n",
    "        wdecay_param = {'weight_decay': trial.suggest_loguniform('weight_decay', 1e-5, 1e-1)}\n",
    "        default_params.update(wdecay_param)\n",
    "        hidden_size_param={'hidden_size': trial.suggest_categorical(\"hidden_size\", [8*2**i for i in range(6)])}\n",
    "        default_params.update(hidden_size_param)\n",
    "        batch_size_param={'hidden_size': trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])}\n",
    "        default_params.update(hidden_size_param)\n",
    "        layer_size_param={\"layer_size\": trial.suggest_int(\"layer_size\", 2, 5)}\n",
    "        default_params.update(layer_size_param)\n",
    "        dropout_param={\"dropout\": trial.suggest_float('dropout', 0.0, 1.0)}\n",
    "        default_params.update(dropout_param)\n",
    "        momentum_param = {'momentum': trial.suggest_float('momentum', 0.0, 1.0)}\n",
    "        default_params.update(momentum_param)\n",
    "        nest_param={'nesterov':trial.suggest_categorical(\"nesterov\", [False, True])}\n",
    "        default_params.update(nest_param)\n",
    "        early_stopping = PyTorchLightningPruningCallback(trial, monitor='val_acc')\n",
    "        checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        os.path.join(MODEL_DIR, \"trial_{}\".format(trial.number)), monitor=\"val_acc\"\n",
    "    )\n",
    "        logger = DictLogger(MODEL_DIR,  version=trial.number)\n",
    "    else: \n",
    "        early_stopping = pl.callbacks.EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=20, mode=\"max\")  \n",
    "        logger = DictLogger(MODEL_DIR)\n",
    "    trainer = pl.Trainer(\n",
    "                    logger = logger,\n",
    "                    checkpoint_callback=checkpoint_callback,\n",
    "                    max_epochs=default_params['epochs'],\n",
    "                    gpus=[0] if torch.cuda.is_available() else None,\n",
    "                    early_stop_callback=early_stopping,\n",
    "                    accumulate_grad_batches=1,\n",
    "                     benchmark=True)\n",
    "    \n",
    "    model = MLPIL(default_params)\n",
    "    trainer.fit(model)\n",
    "    if trial is not None:\n",
    "        return logger.metrics[-1]['val_acc']\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "def run_study(num_trials=2):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=num_trials)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | MLP  | 3 M   \n",
      "/usr/local/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d732d854896487e852b1d37046897fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\u001b[33m[W 2020-06-21 11:52:45,679]\u001b[0m Setting status of trial#0 as TrialState.FAIL because of the following error: KeyError('val_acc')\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/optuna/study.py\", line 732, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-47-7c6150fb2720>\", line 66, in objective\n",
      "    return logger.metrics[-1]['val_acc']\n",
      "KeyError: 'val_acc'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-24f479b1d5cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-07ccf7fd8392>\u001b[0m in \u001b[0;36mrun_study\u001b[0;34m(num_trials)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 self._optimize_sequential(\n\u001b[0;32m--> 334\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                 )\n\u001b[1;32m    336\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    675\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             message = \"Setting status of trial#{} as {}. {}\".format(\n",
      "\u001b[0;32m<ipython-input-47-7c6150fb2720>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
     ]
    }
   ],
   "source": [
    "study = run_study(num_trials=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPIL(default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(model.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 784])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
